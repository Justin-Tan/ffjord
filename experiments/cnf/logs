/Users/justin.tian/github/ffjord/pie.md
/Users/justin.tian/github/ffjord/train_toy.py
/Users/justin.tian/github/ffjord/train_toy.py
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

import argparse
import os
import time

import torch
import torch.optim as optim

import lib.toy_data as toy_data
import lib.utils as utils
from lib.visualize_flow import visualize_transform
import lib.layers.odefunc as odefunc

from train_misc import standard_normal_logprob
from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time
from train_misc import add_spectral_norm, spectral_norm_power_iteration
from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log
from train_misc import build_model_tabular

from diagnostics.viz_toy import save_trajectory, trajectory_to_video

SOLVERS = ["dopri5", "bdf", "rk4", "midpoint", 'adams', 'explicit_adams', 'fixed_adams']
parser = argparse.ArgumentParser('Continuous Normalizing Flow')
parser.add_argument(
    '--data', choices=['swissroll', '8gaussians', 'pinwheel', 'circles', 'moons', '2spirals', 'checkerboard', 'rings'],
    type=str, default='pinwheel'
)
parser.add_argument(
    "--layer_type", type=str, default="concatsquash",
    choices=["ignore", "concat", "concat_v2", "squash", "concatsquash", "concatcoord", "hyper", "blend"]
)
parser.add_argument('--dims', type=str, default='64-64-64')
parser.add_argument("--num_blocks", type=int, default=1, help='Number of stacked CNFs.')
parser.add_argument('--time_length', type=float, default=0.5)
parser.add_argument('--train_T', type=eval, default=True)
parser.add_argument("--divergence_fn", type=str, default="brute_force", choices=["brute_force", "approximate"])
parser.add_argument("--nonlinearity", type=str, default="tanh", choices=odefunc.NONLINEARITIES)

parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)
parser.add_argument('--atol', type=float, default=1e-5)
parser.add_argument('--rtol', type=float, default=1e-5)
parser.add_argument("--step_size", type=float, default=None, help="Optional fixed step size.")

parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])
parser.add_argument('--test_atol', type=float, default=None)
parser.add_argument('--test_rtol', type=float, default=None)

parser.add_argument('--residual', type=eval, default=False, choices=[True, False])
parser.add_argument('--rademacher', type=eval, default=False, choices=[True, False])
parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])
parser.add_argument('--batch_norm', type=eval, default=False, choices=[True, False])
parser.add_argument('--bn_lag', type=float, default=0)

parser.add_argument('--niters', type=int, default=10000)
parser.add_argument('--batch_size', type=int, default=100)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--lr', type=float, default=1e-3)
parser.add_argument('--weight_decay', type=float, default=1e-5)

# Track quantities
parser.add_argument('--l1int', type=float, default=None, help="int_t ||f||_1")
parser.add_argument('--l2int', type=float, default=None, help="int_t ||f||_2")
parser.add_argument('--dl2int', type=float, default=None, help="int_t ||f^T df/dt||_2")
parser.add_argument('--JFrobint', type=float, default=None, help="int_t ||df/dx||_F")
parser.add_argument('--JdiagFrobint', type=float, default=None, help="int_t ||df_i/dx_i||_F")
parser.add_argument('--JoffdiagFrobint', type=float, default=None, help="int_t ||df/dx - df_i/dx_i||_F")

parser.add_argument('--save', type=str, default='experiments/cnf')
parser.add_argument('--viz_freq', type=int, default=100)
parser.add_argument('--val_freq', type=int, default=100)
parser.add_argument('--log_freq', type=int, default=10)
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

# logger
utils.makedirs(args.save)
logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))

if args.layer_type == "blend":
    logger.info("!! Setting time_length from None to 1.0 due to use of Blend layers.")
    args.time_length = 1.0

logger.info(args)

device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')


def get_transforms(model):

    def sample_fn(z, logpz=None):
        if logpz is not None:
            return model(z, logpz, reverse=True)
        else:
            return model(z, reverse=True)

    def density_fn(x, logpx=None):
        if logpx is not None:
            return model(x, logpx, reverse=False)
        else:
            return model(x, reverse=False)

    return sample_fn, density_fn


def compute_loss(args, model, batch_size=None):
    if batch_size is None: batch_size = args.batch_size

    # load data
    x = toy_data.inf_train_gen(args.data, batch_size=batch_size)
    x = torch.from_numpy(x).type(torch.float32).to(device)
    zero = torch.zeros(x.shape[0], 1).to(x)

    # transform to z
    z, delta_logp = model(x, zero)

    # compute log q(z)
    logpz = standard_normal_logprob(z).sum(1, keepdim=True)

    logpx = logpz - delta_logp
    loss = -torch.mean(logpx)
    return loss


if __name__ == '__main__':

    regularization_fns, regularization_coeffs = create_regularization_fns(args)
    model = build_model_tabular(args, 2, regularization_fns).to(device)
    if args.spectral_norm: add_spectral_norm(model)
    set_cnf_options(args, model)

    logger.info(model)
    logger.info("Number of trainable parameters: {}".format(count_parameters(model)))

    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

    time_meter = utils.RunningAverageMeter(0.93)
    loss_meter = utils.RunningAverageMeter(0.93)
    nfef_meter = utils.RunningAverageMeter(0.93)
    nfeb_meter = utils.RunningAverageMeter(0.93)
    tt_meter = utils.RunningAverageMeter(0.93)

    end = time.time()
    best_loss = float('inf')
    model.train()
    for itr in range(1, args.niters + 1):
        optimizer.zero_grad()
        if args.spectral_norm: spectral_norm_power_iteration(model, 1)

        loss = compute_loss(args, model)
        loss_meter.update(loss.item())

        if len(regularization_coeffs) > 0:
            reg_states = get_regularization(model, regularization_coeffs)
            reg_loss = sum(
                reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0
            )
            loss = loss + reg_loss

        total_time = count_total_time(model)
        nfe_forward = count_nfe(model)

        loss.backward()
        optimizer.step()

        nfe_total = count_nfe(model)
        nfe_backward = nfe_total - nfe_forward
        nfef_meter.update(nfe_forward)
        nfeb_meter.update(nfe_backward)

        time_meter.update(time.time() - end)
        tt_meter.update(total_time)

        log_message = (
            'Iter {:04d} | Time {:.4f}({:.4f}) | Loss {:.6f}({:.6f}) | NFE Forward {:.0f}({:.1f})'
            ' | NFE Backward {:.0f}({:.1f}) | CNF Time {:.4f}({:.4f})'.format(
                itr, time_meter.val, time_meter.avg, loss_meter.val, loss_meter.avg, nfef_meter.val, nfef_meter.avg,
                nfeb_meter.val, nfeb_meter.avg, tt_meter.val, tt_meter.avg
            )
        )
        if len(regularization_coeffs) > 0:
            log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)

        logger.info(log_message)

        if itr % args.val_freq == 0 or itr == args.niters:
            with torch.no_grad():
                model.eval()
                test_loss = compute_loss(args, model, batch_size=args.test_batch_size)
                test_nfe = count_nfe(model)
                log_message = '[TEST] Iter {:04d} | Test Loss {:.6f} | NFE {:.0f}'.format(itr, test_loss, test_nfe)
                logger.info(log_message)

                if test_loss.item() < best_loss:
                    best_loss = test_loss.item()
                    utils.makedirs(args.save)
                    torch.save({
                        'args': args,
                        'state_dict': model.state_dict(),
                    }, os.path.join(args.save, 'checkpt.pth'))
                model.train()

        if itr % args.viz_freq == 0:
            with torch.no_grad():
                model.eval()
                p_samples = toy_data.inf_train_gen(args.data, batch_size=2000)

                sample_fn, density_fn = get_transforms(model)

                plt.figure(figsize=(9, 3))
                visualize_transform(
                    p_samples, torch.randn, standard_normal_logprob, transform=sample_fn, inverse_transform=density_fn,
                    samples=True, npts=800, device=device
                )
                fig_filename = os.path.join(args.save, 'figs', '{:04d}.jpg'.format(itr))
                utils.makedirs(os.path.dirname(fig_filename))
                plt.savefig(fig_filename)
                plt.close()
                model.train()

        end = time.time()

    logger.info('Training has finished.')

    save_traj_dir = os.path.join(args.save, 'trajectory')
    logger.info('Plotting trajectory to {}'.format(save_traj_dir))
    data_samples = toy_data.inf_train_gen(args.data, batch_size=2000)
    save_trajectory(model, data_samples, save_traj_dir, device=device)
    trajectory_to_video(save_traj_dir)

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

import argparse
import os
import time

import torch
import torch.optim as optim

import lib.toy_data as toy_data
import lib.utils as utils
from lib.visualize_flow import visualize_transform
import lib.layers.odefunc as odefunc

from train_misc import standard_normal_logprob
from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time
from train_misc import add_spectral_norm, spectral_norm_power_iteration
from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log
from train_misc import build_model_tabular

from diagnostics.viz_toy import save_trajectory, trajectory_to_video

SOLVERS = ["dopri5", "bdf", "rk4", "midpoint", 'adams', 'explicit_adams', 'fixed_adams']
parser = argparse.ArgumentParser('Continuous Normalizing Flow')
parser.add_argument(
    '--data', choices=['swissroll', '8gaussians', 'pinwheel', 'circles', 'moons', '2spirals', 'checkerboard', 'rings'],
    type=str, default='pinwheel'
)
parser.add_argument(
    "--layer_type", type=str, default="concatsquash",
    choices=["ignore", "concat", "concat_v2", "squash", "concatsquash", "concatcoord", "hyper", "blend"]
)
parser.add_argument('--dims', type=str, default='64-64-64')
parser.add_argument("--num_blocks", type=int, default=1, help='Number of stacked CNFs.')
parser.add_argument('--time_length', type=float, default=0.5)
parser.add_argument('--train_T', type=eval, default=True)
parser.add_argument("--divergence_fn", type=str, default="brute_force", choices=["brute_force", "approximate"])
parser.add_argument("--nonlinearity", type=str, default="tanh", choices=odefunc.NONLINEARITIES)

parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)
parser.add_argument('--atol', type=float, default=1e-5)
parser.add_argument('--rtol', type=float, default=1e-5)
parser.add_argument("--step_size", type=float, default=None, help="Optional fixed step size.")

parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])
parser.add_argument('--test_atol', type=float, default=None)
parser.add_argument('--test_rtol', type=float, default=None)

parser.add_argument('--residual', type=eval, default=False, choices=[True, False])
parser.add_argument('--rademacher', type=eval, default=False, choices=[True, False])
parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])
parser.add_argument('--batch_norm', type=eval, default=False, choices=[True, False])
parser.add_argument('--bn_lag', type=float, default=0)

parser.add_argument('--niters', type=int, default=10000)
parser.add_argument('--batch_size', type=int, default=100)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--lr', type=float, default=1e-3)
parser.add_argument('--weight_decay', type=float, default=1e-5)

# Track quantities
parser.add_argument('--l1int', type=float, default=None, help="int_t ||f||_1")
parser.add_argument('--l2int', type=float, default=None, help="int_t ||f||_2")
parser.add_argument('--dl2int', type=float, default=None, help="int_t ||f^T df/dt||_2")
parser.add_argument('--JFrobint', type=float, default=None, help="int_t ||df/dx||_F")
parser.add_argument('--JdiagFrobint', type=float, default=None, help="int_t ||df_i/dx_i||_F")
parser.add_argument('--JoffdiagFrobint', type=float, default=None, help="int_t ||df/dx - df_i/dx_i||_F")

parser.add_argument('--save', type=str, default='experiments/cnf')
parser.add_argument('--viz_freq', type=int, default=100)
parser.add_argument('--val_freq', type=int, default=100)
parser.add_argument('--log_freq', type=int, default=10)
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

# logger
utils.makedirs(args.save)
logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))

if args.layer_type == "blend":
    logger.info("!! Setting time_length from None to 1.0 due to use of Blend layers.")
    args.time_length = 1.0

logger.info(args)

device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')


def get_transforms(model):

    def sample_fn(z, logpz=None):
        if logpz is not None:
            return model(z, logpz, reverse=True)
        else:
            return model(z, reverse=True)

    def density_fn(x, logpx=None):
        if logpx is not None:
            return model(x, logpx, reverse=False)
        else:
            return model(x, reverse=False)

    return sample_fn, density_fn


def compute_loss(args, model, batch_size=None):
    if batch_size is None: batch_size = args.batch_size

    # load data
    x = toy_data.inf_train_gen(args.data, batch_size=batch_size)
    x = torch.from_numpy(x).type(torch.float32).to(device)
    zero = torch.zeros(x.shape[0], 1).to(x)

    # transform to z
    z, delta_logp = model(x, zero)

    # compute log q(z)
    logpz = standard_normal_logprob(z).sum(1, keepdim=True)

    logpx = logpz - delta_logp
    loss = -torch.mean(logpx)
    return loss


if __name__ == '__main__':

    regularization_fns, regularization_coeffs = create_regularization_fns(args)
    model = build_model_tabular(args, 2, regularization_fns).to(device)
    if args.spectral_norm: add_spectral_norm(model)
    set_cnf_options(args, model)

    logger.info(model)
    logger.info("Number of trainable parameters: {}".format(count_parameters(model)))

    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

    time_meter = utils.RunningAverageMeter(0.93)
    loss_meter = utils.RunningAverageMeter(0.93)
    nfef_meter = utils.RunningAverageMeter(0.93)
    nfeb_meter = utils.RunningAverageMeter(0.93)
    tt_meter = utils.RunningAverageMeter(0.93)

    end = time.time()
    best_loss = float('inf')
    model.train()
    for itr in range(1, args.niters + 1):
        optimizer.zero_grad()
        if args.spectral_norm: spectral_norm_power_iteration(model, 1)

        loss = compute_loss(args, model)
        loss_meter.update(loss.item())

        if len(regularization_coeffs) > 0:
            reg_states = get_regularization(model, regularization_coeffs)
            reg_loss = sum(
                reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0
            )
            loss = loss + reg_loss

        total_time = count_total_time(model)
        nfe_forward = count_nfe(model)

        loss.backward()
        optimizer.step()

        nfe_total = count_nfe(model)
        nfe_backward = nfe_total - nfe_forward
        nfef_meter.update(nfe_forward)
        nfeb_meter.update(nfe_backward)

        time_meter.update(time.time() - end)
        tt_meter.update(total_time)

        log_message = (
            'Iter {:04d} | Time {:.4f}({:.4f}) | Loss {:.6f}({:.6f}) | NFE Forward {:.0f}({:.1f})'
            ' | NFE Backward {:.0f}({:.1f}) | CNF Time {:.4f}({:.4f})'.format(
                itr, time_meter.val, time_meter.avg, loss_meter.val, loss_meter.avg, nfef_meter.val, nfef_meter.avg,
                nfeb_meter.val, nfeb_meter.avg, tt_meter.val, tt_meter.avg
            )
        )
        if len(regularization_coeffs) > 0:
            log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)

        logger.info(log_message)

        if itr % args.val_freq == 0 or itr == args.niters:
            with torch.no_grad():
                model.eval()
                test_loss = compute_loss(args, model, batch_size=args.test_batch_size)
                test_nfe = count_nfe(model)
                log_message = '[TEST] Iter {:04d} | Test Loss {:.6f} | NFE {:.0f}'.format(itr, test_loss, test_nfe)
                logger.info(log_message)

                if test_loss.item() < best_loss:
                    best_loss = test_loss.item()
                    utils.makedirs(args.save)
                    torch.save({
                        'args': args,
                        'state_dict': model.state_dict(),
                    }, os.path.join(args.save, 'checkpt.pth'))
                model.train()

        if itr % args.viz_freq == 0:
            with torch.no_grad():
                model.eval()
                p_samples = toy_data.inf_train_gen(args.data, batch_size=2000)

                sample_fn, density_fn = get_transforms(model)

                plt.figure(figsize=(9, 3))
                visualize_transform(
                    p_samples, torch.randn, standard_normal_logprob, transform=sample_fn, inverse_transform=density_fn,
                    samples=True, npts=800, device=device
                )
                fig_filename = os.path.join(args.save, 'figs', '{:04d}.jpg'.format(itr))
                utils.makedirs(os.path.dirname(fig_filename))
                plt.savefig(fig_filename)
                plt.close()
                model.train()

        end = time.time()

    logger.info('Training has finished.')

    save_traj_dir = os.path.join(args.save, 'trajectory')
    logger.info('Plotting trajectory to {}'.format(save_traj_dir))
    data_samples = toy_data.inf_train_gen(args.data, batch_size=2000)
    save_trajectory(model, data_samples, save_traj_dir, device=device)
    trajectory_to_video(save_traj_dir)

Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

import argparse
import os
import time

import torch
import torch.optim as optim

import lib.toy_data as toy_data
import lib.utils as utils
from lib.visualize_flow import visualize_transform
import lib.layers.odefunc as odefunc

from train_misc import standard_normal_logprob
from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time
from train_misc import add_spectral_norm, spectral_norm_power_iteration
from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log
from train_misc import build_model_tabular

from diagnostics.viz_toy import save_trajectory, trajectory_to_video

SOLVERS = ["dopri5", "bdf", "rk4", "midpoint", 'adams', 'explicit_adams', 'fixed_adams']
parser = argparse.ArgumentParser('Continuous Normalizing Flow')
parser.add_argument(
    '--data', choices=['swissroll', '8gaussians', 'pinwheel', 'circles', 'moons', '2spirals', 'checkerboard', 'rings'],
    type=str, default='pinwheel'
)
parser.add_argument(
    "--layer_type", type=str, default="concatsquash",
    choices=["ignore", "concat", "concat_v2", "squash", "concatsquash", "concatcoord", "hyper", "blend"]
)
parser.add_argument('--dims', type=str, default='64-64-64')
parser.add_argument("--num_blocks", type=int, default=1, help='Number of stacked CNFs.')
parser.add_argument('--time_length', type=float, default=0.5)
parser.add_argument('--train_T', type=eval, default=True)
parser.add_argument("--divergence_fn", type=str, default="brute_force", choices=["brute_force", "approximate"])
parser.add_argument("--nonlinearity", type=str, default="tanh", choices=odefunc.NONLINEARITIES)

parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)
parser.add_argument('--atol', type=float, default=1e-5)
parser.add_argument('--rtol', type=float, default=1e-5)
parser.add_argument("--step_size", type=float, default=None, help="Optional fixed step size.")

parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])
parser.add_argument('--test_atol', type=float, default=None)
parser.add_argument('--test_rtol', type=float, default=None)

parser.add_argument('--residual', type=eval, default=False, choices=[True, False])
parser.add_argument('--rademacher', type=eval, default=False, choices=[True, False])
parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])
parser.add_argument('--batch_norm', type=eval, default=False, choices=[True, False])
parser.add_argument('--bn_lag', type=float, default=0)

parser.add_argument('--niters', type=int, default=10000)
parser.add_argument('--batch_size', type=int, default=100)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--lr', type=float, default=1e-3)
parser.add_argument('--weight_decay', type=float, default=1e-5)

# Track quantities
parser.add_argument('--l1int', type=float, default=None, help="int_t ||f||_1")
parser.add_argument('--l2int', type=float, default=None, help="int_t ||f||_2")
parser.add_argument('--dl2int', type=float, default=None, help="int_t ||f^T df/dt||_2")
parser.add_argument('--JFrobint', type=float, default=None, help="int_t ||df/dx||_F")
parser.add_argument('--JdiagFrobint', type=float, default=None, help="int_t ||df_i/dx_i||_F")
parser.add_argument('--JoffdiagFrobint', type=float, default=None, help="int_t ||df/dx - df_i/dx_i||_F")

parser.add_argument('--save', type=str, default='experiments/cnf')
parser.add_argument('--viz_freq', type=int, default=100)
parser.add_argument('--val_freq', type=int, default=100)
parser.add_argument('--log_freq', type=int, default=10)
parser.add_argument('--gpu', type=int, default=0)
args = parser.parse_args()

# logger
utils.makedirs(args.save)
logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))

if args.layer_type == "blend":
    logger.info("!! Setting time_length from None to 1.0 due to use of Blend layers.")
    args.time_length = 1.0

logger.info(args)

def compute_loss(args, model, batch_size=None):
    if batch_size is None: batch_size = args.batch_size

    # load data
    # x = toy_data.inf_train_gen(args.data, batch_size=batch_size)
    x = sklearn.datasets.make_moons(n_samples=256, noise=.05)[0].astype(np.float32)
    x = torch.from_numpy(x).type(torch.float32).to(device)
    zero = torch.zeros(x.shape[0], 1).to(x)

    # transform to z
    z, delta_logp = model(x, zero)

    # compute log q(z)
    logpz = standard_normal_logprob(z).sum(1, keepdim=True)

    logpx = logpz - delta_logp
    loss = -torch.mean(logpx)
    return loss

def get_regularization_loss(model, regularization_fns, regularization_coeffs):
    if len(regularization_coeffs) > 0:
        reg_states = get_regularization(model, regularization_coeffs)
        reg_loss = sum(
            reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0
        )

    return reg_loss

def train_moons_ffjord(model, optimizer, device, logger, iterations=8000):
    print('Using device', device)

    for idx in trange(iterations, desc='Itr'):
        optimizer.zero_grad()
        if args.spectral_norm: spectral_norm_power_iteration(model, 1)

        loss = compute_loss(args, model)
        loss_meter.update(loss.item())

        reg_loss = get_regularization_loss(model, regularization_fns, regularization_coeffs)

        loss = loss + reg_loss

        total_time = count_total_time(model)
        nfe_forward = count_nfe(model)

        loss.backward()
        optimizer.step()

        nfe_total = count_nfe(model)
        nfe_backward = nfe_total - nfe_forward
        nfef_meter.update(nfe_forward)
        nfeb_meter.update(nfe_backward)
        time_meter.update(time.time() - end)
        tt_meter.update(total_time)

        log_message = (
            'Iter {:04d} | Time {:.4f}({:.4f}) | Loss {:.6f}({:.6f}) | NFE Forward {:.0f}({:.1f})'
            ' | NFE Backward {:.0f}({:.1f}) | CNF Time {:.4f}({:.4f})'.format(
                itr, time_meter.val, time_meter.avg, loss_meter.val, loss_meter.avg, nfef_meter.val, nfef_meter.avg,
                nfeb_meter.val, nfeb_meter.avg, tt_meter.val, tt_meter.avg
            )
        )

        if len(regularization_coeffs) > 0:
            log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)

        logger.info(log_message)

        if itr % args.val_freq == 0 or itr == args.niters:
            with torch.no_grad():
                model.eval()
                test_loss = compute_loss(args, model, batch_size=args.test_batch_size)
                test_nfe = count_nfe(model)
                log_message = '[TEST] Iter {:04d} | Test Loss {:.6f} | NFE {:.0f}'.format(itr, test_loss, test_nfe)
                logger.info(log_message)

        end = time.time()

    logger.info('Training has finished.')


if __name__ == '__main__':

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')
    regularization_fns, regularization_coeffs = create_regularization_fns(args)
    model = build_model_tabular(args, 2, regularization_fns).to(device)
    if args.spectral_norm: add_spectral_norm(model)
    set_cnf_options(args, model)

    logger.info(model)
    logger.info("Number of trainable parameters: {}".format(count_parameters(model)))
    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

    time_meter = utils.RunningAverageMeter(0.93)
    loss_meter = utils.RunningAverageMeter(0.93)
    nfef_meter = utils.RunningAverageMeter(0.93)
    nfeb_meter = utils.RunningAverageMeter(0.93)
    tt_meter = utils.RunningAverageMeter(0.93)

    train_moons_ffjord(model, optimizer, device, logger, iterations=8000)
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=2, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=2, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=2, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=2, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Number of trainable parameters: 9225
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=2, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=2, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=2, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=2, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Number of trainable parameters: 9225
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=2, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=2, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=2, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=2, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Number of trainable parameters: 9225
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=2, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=2, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=2, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=2, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Number of trainable parameters: 9225
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=2, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=2, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=2, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=2, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Number of trainable parameters: 9225
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=2, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=2, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=2, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=2, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Number of trainable parameters: 9225
Iter 0000 | Time 0.5285(0.5285) | Loss 2.529887(2.529887) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 0000 | Test Loss 2.530318 | NFE 20 [*]
Iter 0001 | Time 0.2413(0.5084) | Loss 2.531453(2.529997) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0002 | Time 0.2423(0.4898) | Loss 2.523504(2.529542) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0003 | Time 0.2425(0.4724) | Loss 2.522538(2.529052) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0004 | Time 0.2419(0.4563) | Loss 2.515671(2.528115) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0005 | Time 0.2453(0.4415) | Loss 2.512060(2.526991) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0006 | Time 0.2421(0.4276) | Loss 2.510421(2.525831) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0007 | Time 0.2447(0.4148) | Loss 2.506812(2.524500) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0008 | Time 0.2416(0.4027) | Loss 2.504354(2.523090) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0009 | Time 0.2423(0.3914) | Loss 2.500045(2.521477) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0010 | Time 0.2415(0.3809) | Loss 2.487307(2.519085) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0011 | Time 0.2430(0.3713) | Loss 2.485399(2.516727) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0012 | Time 0.2415(0.3622) | Loss 2.489984(2.514855) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0013 | Time 0.2417(0.3538) | Loss 2.479564(2.512384) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0014 | Time 0.2435(0.3460) | Loss 2.480891(2.510180) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0015 | Time 0.2419(0.3388) | Loss 2.467859(2.507217) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0016 | Time 0.2446(0.3322) | Loss 2.461203(2.503996) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0017 | Time 0.2444(0.3260) | Loss 2.465131(2.501276) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0018 | Time 0.2879(0.3233) | Loss 2.456325(2.498129) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0019 | Time 0.2415(0.3176) | Loss 2.447223(2.494566) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0020 | Time 0.2416(0.3123) | Loss 2.445011(2.491097) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0021 | Time 0.2419(0.3074) | Loss 2.436202(2.487254) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0022 | Time 0.2432(0.3029) | Loss 2.431407(2.483345) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0023 | Time 0.2412(0.2986) | Loss 2.421261(2.478999) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0024 | Time 0.2417(0.2946) | Loss 2.415736(2.474571) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0025 | Time 0.2410(0.2908) | Loss 2.412327(2.470214) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0026 | Time 0.2415(0.2874) | Loss 2.405075(2.465654) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0027 | Time 0.2436(0.2843) | Loss 2.394198(2.460652) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0028 | Time 0.2410(0.2813) | Loss 2.389838(2.455695) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0029 | Time 0.2409(0.2785) | Loss 2.374143(2.449986) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0030 | Time 0.2411(0.2758) | Loss 2.365455(2.444069) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0031 | Time 0.2410(0.2734) | Loss 2.353949(2.437761) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0032 | Time 0.2402(0.2711) | Loss 2.343343(2.431152) | NFE Forward 20(20.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
Iter 0033 | Time 0.3027(0.2733) | Loss 2.333784(2.424336) | NFE Forward 20(20.0) | NFE Backward 21(15.4) | CNF Time 0.5000(0.5000)
Iter 0034 | Time 0.2994(0.2751) | Loss 2.328620(2.417636) | NFE Forward 20(20.0) | NFE Backward 21(15.8) | CNF Time 0.5000(0.5000)
Iter 0035 | Time 0.2404(0.2727) | Loss 2.308554(2.410000) | NFE Forward 20(20.0) | NFE Backward 15(15.8) | CNF Time 0.5000(0.5000)
Iter 0036 | Time 0.2420(0.2705) | Loss 2.299116(2.402238) | NFE Forward 20(20.0) | NFE Backward 15(15.7) | CNF Time 0.5000(0.5000)
Iter 0037 | Time 0.3017(0.2727) | Loss 2.285582(2.394072) | NFE Forward 20(20.0) | NFE Backward 21(16.1) | CNF Time 0.5000(0.5000)
Iter 0038 | Time 0.2413(0.2705) | Loss 2.273083(2.385603) | NFE Forward 20(20.0) | NFE Backward 15(16.0) | CNF Time 0.5000(0.5000)
Iter 0039 | Time 0.3050(0.2729) | Loss 2.258676(2.376718) | NFE Forward 20(20.0) | NFE Backward 21(16.3) | CNF Time 0.5000(0.5000)
Iter 0040 | Time 0.3017(0.2749) | Loss 2.246043(2.367571) | NFE Forward 20(20.0) | NFE Backward 21(16.7) | CNF Time 0.5000(0.5000)
Iter 0041 | Time 0.3009(0.2768) | Loss 2.224101(2.357528) | NFE Forward 20(20.0) | NFE Backward 21(17.0) | CNF Time 0.5000(0.5000)
Iter 0042 | Time 0.3042(0.2787) | Loss 2.216291(2.347641) | NFE Forward 20(20.0) | NFE Backward 21(17.3) | CNF Time 0.5000(0.5000)
Iter 0043 | Time 0.3002(0.2802) | Loss 2.206149(2.337737) | NFE Forward 20(20.0) | NFE Backward 21(17.5) | CNF Time 0.5000(0.5000)
Iter 0044 | Time 0.3005(0.2816) | Loss 2.191983(2.327534) | NFE Forward 20(20.0) | NFE Backward 21(17.8) | CNF Time 0.5000(0.5000)
Iter 0045 | Time 0.3034(0.2831) | Loss 2.174825(2.316844) | NFE Forward 20(20.0) | NFE Backward 21(18.0) | CNF Time 0.5000(0.5000)
Iter 0046 | Time 0.3017(0.2844) | Loss 2.157798(2.305711) | NFE Forward 20(20.0) | NFE Backward 21(18.2) | CNF Time 0.5000(0.5000)
Iter 0047 | Time 0.3012(0.2856) | Loss 2.142013(2.294252) | NFE Forward 20(20.0) | NFE Backward 21(18.4) | CNF Time 0.5000(0.5000)
Iter 0048 | Time 0.3031(0.2868) | Loss 2.134097(2.283041) | NFE Forward 20(20.0) | NFE Backward 21(18.6) | CNF Time 0.5000(0.5000)
Iter 0049 | Time 0.3006(0.2878) | Loss 2.112658(2.271115) | NFE Forward 20(20.0) | NFE Backward 21(18.7) | CNF Time 0.5000(0.5000)
Iter 0050 | Time 0.3011(0.2887) | Loss 2.094386(2.258744) | NFE Forward 20(20.0) | NFE Backward 21(18.9) | CNF Time 0.5000(0.5000)
Iter 0051 | Time 0.3014(0.2896) | Loss 2.083880(2.246503) | NFE Forward 20(20.0) | NFE Backward 21(19.1) | CNF Time 0.5000(0.5000)
Iter 0052 | Time 0.3008(0.2904) | Loss 2.064995(2.233798) | NFE Forward 20(20.0) | NFE Backward 21(19.2) | CNF Time 0.5000(0.5000)
Iter 0053 | Time 0.3003(0.2911) | Loss 2.049453(2.220893) | NFE Forward 20(20.0) | NFE Backward 21(19.3) | CNF Time 0.5000(0.5000)
Iter 0054 | Time 0.3003(0.2917) | Loss 2.054235(2.209227) | NFE Forward 20(20.0) | NFE Backward 21(19.4) | CNF Time 0.5000(0.5000)
Iter 0055 | Time 0.3006(0.2924) | Loss 2.048623(2.197985) | NFE Forward 20(20.0) | NFE Backward 21(19.5) | CNF Time 0.5000(0.5000)
Iter 0056 | Time 0.3030(0.2931) | Loss 2.026219(2.185961) | NFE Forward 20(20.0) | NFE Backward 21(19.6) | CNF Time 0.5000(0.5000)
Iter 0057 | Time 0.3012(0.2937) | Loss 2.014956(2.173991) | NFE Forward 20(20.0) | NFE Backward 21(19.7) | CNF Time 0.5000(0.5000)
Iter 0058 | Time 0.3004(0.2942) | Loss 2.015733(2.162913) | NFE Forward 20(20.0) | NFE Backward 21(19.8) | CNF Time 0.5000(0.5000)
Iter 0059 | Time 0.3010(0.2946) | Loss 2.014957(2.152556) | NFE Forward 20(20.0) | NFE Backward 21(19.9) | CNF Time 0.5000(0.5000)
Iter 0060 | Time 0.3000(0.2950) | Loss 2.009418(2.142536) | NFE Forward 20(20.0) | NFE Backward 21(20.0) | CNF Time 0.5000(0.5000)
Iter 0061 | Time 0.3516(0.2990) | Loss 2.008560(2.133158) | NFE Forward 20(20.0) | NFE Backward 27(20.5) | CNF Time 0.5000(0.5000)
Iter 0062 | Time 0.3521(0.3027) | Loss 2.013568(2.124787) | NFE Forward 20(20.0) | NFE Backward 27(20.9) | CNF Time 0.5000(0.5000)
Iter 0063 | Time 0.3527(0.3062) | Loss 2.013913(2.117025) | NFE Forward 20(20.0) | NFE Backward 27(21.4) | CNF Time 0.5000(0.5000)
Iter 0064 | Time 0.3511(0.3093) | Loss 2.001564(2.108943) | NFE Forward 20(20.0) | NFE Backward 27(21.8) | CNF Time 0.5000(0.5000)
Iter 0065 | Time 0.3506(0.3122) | Loss 1.992359(2.100782) | NFE Forward 20(20.0) | NFE Backward 27(22.1) | CNF Time 0.5000(0.5000)
Iter 0066 | Time 0.4043(0.3187) | Loss 1.985300(2.092699) | NFE Forward 20(20.0) | NFE Backward 33(22.9) | CNF Time 0.5000(0.5000)
Iter 0067 | Time 0.3532(0.3211) | Loss 1.985532(2.085197) | NFE Forward 20(20.0) | NFE Backward 27(23.2) | CNF Time 0.5000(0.5000)
Iter 0068 | Time 0.3531(0.3233) | Loss 1.991361(2.078628) | NFE Forward 20(20.0) | NFE Backward 27(23.4) | CNF Time 0.5000(0.5000)
Iter 0069 | Time 0.3531(0.3254) | Loss 1.985844(2.072133) | NFE Forward 20(20.0) | NFE Backward 27(23.7) | CNF Time 0.5000(0.5000)
Iter 0070 | Time 0.4056(0.3310) | Loss 1.976867(2.065465) | NFE Forward 20(20.0) | NFE Backward 33(24.3) | CNF Time 0.5000(0.5000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=2, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=2, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=2, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=2, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Number of trainable parameters: 9225
Iter 0000 | Time 0.5008(0.5008) | Loss 2.469780(2.469780) | NFE Forward 14(14.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 0000 | Test Loss 2.452884 | NFE 14 [*]
Iter 0100 | Time 0.3052(0.3097) | Loss 1.917452(1.931272) | NFE Forward 20(20.6) | NFE Backward 21(21.4) | CNF Time 0.5000(0.5000)
[TEST] Iter 0100 | Test Loss 1.937900 | NFE 20 [*]
Iter 0200 | Time 0.4678(0.4504) | Loss 1.795152(1.838358) | NFE Forward 32(27.0) | NFE Backward 33(33.3) | CNF Time 0.5000(0.5000)
[TEST] Iter 0200 | Test Loss 1.800927 | NFE 32 [*]
Iter 0300 | Time 0.4999(0.4858) | Loss 1.487526(1.513265) | NFE Forward 38(33.6) | NFE Backward 33(33.4) | CNF Time 0.5000(0.5000)
[TEST] Iter 0300 | Test Loss 1.496343 | NFE 32 [*]
Iter 0400 | Time 0.5867(0.5681) | Loss 1.084885(1.180337) | NFE Forward 44(39.6) | NFE Backward 39(39.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 0400 | Test Loss 1.097025 | NFE 38 [*]
Iter 0500 | Time 0.6756(0.6110) | Loss 0.975273(0.915310) | NFE Forward 50(44.6) | NFE Backward 45(40.9) | CNF Time 0.5000(0.5000)
[TEST] Iter 0500 | Test Loss 0.863249 | NFE 44 [*]
Iter 0600 | Time 0.6746(0.6716) | Loss 0.757830(0.746493) | NFE Forward 50(49.1) | NFE Backward 45(45.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 0600 | Test Loss 0.746526 | NFE 50 [*]
Iter 0700 | Time 0.7304(0.6847) | Loss 0.576282(0.631269) | NFE Forward 62(50.5) | NFE Backward 45(45.5) | CNF Time 0.5000(0.5000)
[TEST] Iter 0700 | Test Loss 0.588902 | NFE 50 [*]
Iter 0800 | Time 0.6748(0.6886) | Loss 0.553892(0.585663) | NFE Forward 50(47.3) | NFE Backward 45(47.9) | CNF Time 0.5000(0.5000)
[TEST] Iter 0800 | Test Loss 0.568080 | NFE 50 [*]
Iter 0900 | Time 0.6997(0.6785) | Loss 0.482927(0.517353) | NFE Forward 44(43.2) | NFE Backward 51(48.7) | CNF Time 0.5000(0.5000)
[TEST] Iter 0900 | Test Loss 0.459123 | NFE 44 [*]
Iter 1000 | Time 0.6782(0.6895) | Loss 0.490808(0.504459) | NFE Forward 38(42.2) | NFE Backward 51(50.1) | CNF Time 0.5000(0.5000)
[TEST] Iter 1000 | Test Loss 0.434010 | NFE 50 [*]
Iter 1100 | Time 0.7034(0.6906) | Loss 0.497605(0.492266) | NFE Forward 44(44.5) | NFE Backward 51(49.2) | CNF Time 0.5000(0.5000)
[TEST] Iter 1100 | Test Loss 0.579045 | NFE 44 []
Iter 1200 | Time 0.6748(0.7148) | Loss 0.469059(0.458977) | NFE Forward 50(48.1) | NFE Backward 45(50.1) | CNF Time 0.5000(0.5000)
[TEST] Iter 1200 | Test Loss 0.458606 | NFE 50 []
Iter 1300 | Time 0.7300(0.7299) | Loss 0.517400(0.433563) | NFE Forward 50(49.9) | NFE Backward 51(50.8) | CNF Time 0.5000(0.5000)
[TEST] Iter 1300 | Test Loss 0.405325 | NFE 50 [*]
Iter 1400 | Time 0.7384(0.7454) | Loss 0.514947(0.419845) | NFE Forward 50(50.5) | NFE Backward 51(51.9) | CNF Time 0.5000(0.5000)
[TEST] Iter 1400 | Test Loss 0.427990 | NFE 50 []
Iter 1500 | Time 0.8451(0.8190) | Loss 0.399838(0.410558) | NFE Forward 50(58.5) | NFE Backward 63(56.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 1500 | Test Loss 0.372821 | NFE 50 [*]
Iter 1600 | Time 0.7852(0.8376) | Loss 0.379835(0.405688) | NFE Forward 62(63.0) | NFE Backward 51(55.6) | CNF Time 0.5000(0.5000)
[TEST] Iter 1600 | Test Loss 0.448948 | NFE 56 []
Iter 1700 | Time 0.8420(0.8342) | Loss 0.368198(0.415085) | NFE Forward 62(58.3) | NFE Backward 57(57.8) | CNF Time 0.5000(0.5000)
[TEST] Iter 1700 | Test Loss 0.544957 | NFE 56 []
Iter 1800 | Time 0.8174(0.8431) | Loss 0.387623(0.393520) | NFE Forward 68(60.5) | NFE Backward 51(57.6) | CNF Time 0.5000(0.5000)
[TEST] Iter 1800 | Test Loss 0.340418 | NFE 56 [*]
Iter 1900 | Time 0.9304(0.8849) | Loss 0.447501(0.416336) | NFE Forward 68(65.4) | NFE Backward 63(59.8) | CNF Time 0.5000(0.5000)
[TEST] Iter 1900 | Test Loss 0.389085 | NFE 68 []
Iter 2000 | Time 0.8666(0.9104) | Loss 0.361523(0.384973) | NFE Forward 68(67.3) | NFE Backward 57(61.7) | CNF Time 0.5000(0.5000)
[TEST] Iter 2000 | Test Loss 0.391658 | NFE 62 []
Iter 2100 | Time 0.9553(0.9442) | Loss 0.353809(0.377240) | NFE Forward 62(65.8) | NFE Backward 69(65.6) | CNF Time 0.5000(0.5000)
[TEST] Iter 2100 | Test Loss 0.407855 | NFE 68 []
Iter 2200 | Time 0.9349(0.9778) | Loss 0.303890(0.359295) | NFE Forward 56(72.2) | NFE Backward 69(65.9) | CNF Time 0.5000(0.5000)
[TEST] Iter 2200 | Test Loss 0.404291 | NFE 80 []
Iter 2300 | Time 1.0704(1.0169) | Loss 0.410951(0.379417) | NFE Forward 74(72.8) | NFE Backward 75(69.6) | CNF Time 0.5000(0.5000)
[TEST] Iter 2300 | Test Loss 0.332684 | NFE 68 [*]
Iter 2400 | Time 1.1572(1.0627) | Loss 0.409081(0.363397) | NFE Forward 80(76.5) | NFE Backward 81(72.5) | CNF Time 0.5000(0.5000)
[TEST] Iter 2400 | Test Loss 0.318408 | NFE 74 [*]
Iter 2500 | Time 1.0460(1.1000) | Loss 0.369229(0.353485) | NFE Forward 80(81.8) | NFE Backward 69(74.1) | CNF Time 0.5000(0.5000)
[TEST] Iter 2500 | Test Loss 0.347938 | NFE 86 []
Iter 2600 | Time 1.2631(1.1353) | Loss 0.378309(0.369365) | NFE Forward 92(85.5) | NFE Backward 87(76.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 2600 | Test Loss 0.341991 | NFE 86 []
Iter 2700 | Time 1.2873(1.1489) | Loss 0.452595(0.355739) | NFE Forward 98(82.9) | NFE Backward 87(79.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 2700 | Test Loss 0.297260 | NFE 74 [*]
Iter 2800 | Time 1.1353(1.2127) | Loss 0.284135(0.345332) | NFE Forward 74(89.5) | NFE Backward 81(82.5) | CNF Time 0.5000(0.5000)
[TEST] Iter 2800 | Test Loss 0.246111 | NFE 92 [*]
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, gpu=0, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, val_freq=100, viz_freq=100, weight_decay=1e-05)
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=2, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=64, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=64, out_features=2, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=2, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=2, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 9225
Iter 2900 | Time 1.1841(1.2392) | Loss 0.391748(0.359735) | NFE Forward 86(91.2) | NFE Backward 81(84.5) | CNF Time 0.5000(0.5000)
[TEST] Iter 2900 | Test Loss 0.328515 | NFE 86 []
Iter 0000 | Time 13.3330(13.3330) | Loss 2.472296(2.472296) | NFE Forward 14(14.0) | NFE Backward 15(15.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 0000 | Test Loss 2.468206 | NFE 14 [*]
Iter 0100 | Time 0.5793(0.5768) | Loss 1.953905(1.963094) | NFE Forward 20(20.0) | NFE Backward 27(24.0) | CNF Time 0.3718(0.3875)
[TEST] Iter 0100 | Test Loss 1.938514 | NFE 20 [*]
Iter 3000 | Time 1.1841(1.2475) | Loss 0.309775(0.343123) | NFE Forward 86(91.0) | NFE Backward 81(85.0) | CNF Time 0.5000(0.5000)
[TEST] Iter 3000 | Test Loss 0.286439 | NFE 86 []
711232) | NFE Forward 32(27.5) | NFE Backward 27(28.0) | CNF Time 0.2700(0.2823)
[TEST] Iter 0200 | Test Loss 1.678164 | NFE 32 [*]
Iter 0300 | Time 0.8276(0.8286) | Loss 1.647888(1.658862) | NFE Forward 32(33.3) | NFE Backward 33(32.2) | CNF Time 0.1911(0.2006)
[TEST] Iter 0300 | Test Loss 1.659026 | NFE 32 [*]
Iter 3100 | Time 1.3514(1.2584) | Loss 0.334107(0.339101) | NFE Forward 110(90.4) | NFE Backward 87(86.6) | CNF Time 0.5000(0.5000)
[TEST] Iter 3100 | Test Loss 0.340733 | NFE 86 []
Iter 0400 | Time 0.8470(0.7451) | Loss 1.557732(1.546442) | NFE Forward 26(29.5) | NFE Backward 27(27.8) | CNF Time 0.1315(0.1386)
[TEST] Iter 0400 | Test Loss 1.516204 | NFE 26 [*]
Iter 0500 | Time 0.9707(0.9004) | Loss 1.462154(1.461540) | NFE Forward 32(34.0) | NFE Backward 45(37.1) | CNF Time 0.0877(0.0929)
[TEST] Iter 0500 | Test Loss 1.464257 | NFE 32 [*]
Iter 3200 | Time 1.2994(1.3073) | Loss 0.349894(0.336291) | NFE Forward 98(95.0) | NFE Backward 87(89.4) | CNF Time 0.5000(0.5000)
[TEST] Iter 3200 | Test Loss 0.328823 | NFE 92 []
Iter 0600 | Time 0.9645(0.9382) | Loss 1.427234(1.424265) | NFE Forward 32(32.9) | NFE Backward 51(40.8) | CNF Time 0.0566(0.0602)
[TEST] Iter 0600 | Test Loss 1.435738 | NFE 32 [*]
Iter 0700 | Time 0.8156(0.8626) | Loss 1.489052(1.465974) | NFE Forward 32(32.1) | NFE Backward 33(36.3) | CNF Time 0.0351(0.0376)
[TEST] Iter 0700 | Test Loss 1.480816 | NFE 32 []
Iter 0800 | Time 0.8550(0.8637) | Loss 1.633553(1.597260) | NFE Forward 32(34.0) | NFE Backward 39(36.6) | CNF Time 0.0210(0.0226)
[TEST] Iter 0800 | Test Loss 1.619815 | NFE 32 []
Iter 0900 | Time 0.7294(0.7438) | Loss 1.794463(1.767338) | NFE Forward 26(27.3) | NFE Backward 33(32.1) | CNF Time 0.0120(0.0130)
[TEST] Iter 0900 | Test Loss 1.780951 | NFE 26 []
Iter 1000 | Time 0.6834(0.7092) | Loss 1.967809(1.958237) | NFE Forward 26(24.6) | NFE Backward 33(32.1) | CNF Time 0.0066(0.0072)
[TEST] Iter 1000 | Test Loss 1.971731 | NFE 32 []
Iter 1100 | Time 0.6471(0.6330) | Loss 2.177160(2.144080) | NFE Forward 26(24.4) | NFE Backward 27(27.8) | CNF Time 0.0034(0.0038)
[TEST] Iter 1100 | Test Loss 2.167290 | NFE 26 []
Iter 1200 | Time 0.4660(0.4734) | Loss 2.299521(2.291272) | NFE Forward 20(19.6) | NFE Backward 21(21.2) | CNF Time 0.0017(0.0019)
[TEST] Iter 1200 | Test Loss 2.307953 | NFE 20 []
Iter 1300 | Time 0.4640(0.4840) | Loss 2.393080(2.386598) | NFE Forward 20(19.6) | NFE Backward 21(21.4) | CNF Time 0.0008(0.0009)
[TEST] Iter 1300 | Test Loss 2.399638 | NFE 20 []
Iter 1400 | Time 0.5234(0.5036) | Loss 2.444135(2.443631) | NFE Forward 20(19.8) | NFE Backward 27(22.6) | CNF Time 0.0004(0.0004)
[TEST] Iter 1400 | Test Loss 2.448762 | NFE 20 []
Iter 1500 | Time 0.4788(0.5122) | Loss 2.475831(2.472499) | NFE Forward 20(20.0) | NFE Backward 21(22.2) | CNF Time 0.0001(0.0002)
[TEST] Iter 1500 | Test Loss 2.482075 | NFE 20 []
Iter 1600 | Time 0.5144(0.5138) | Loss 2.483870(2.486377) | NFE Forward 20(20.0) | NFE Backward 21(23.1) | CNF Time 0.0001(0.0001)
[TEST] Iter 1600 | Test Loss 2.483017 | NFE 20 []
Iter 1700 | Time 0.5290(0.5150) | Loss 2.494584(2.491416) | NFE Forward 20(20.0) | NFE Backward 21(22.2) | CNF Time 0.0000(0.0000)
[TEST] Iter 1700 | Test Loss 2.492851 | NFE 20 []
Iter 1800 | Time 0.4613(0.5091) | Loss 2.492468(2.494266) | NFE Forward 14(19.5) | NFE Backward 21(22.3) | CNF Time 0.0000(0.0000)
[TEST] Iter 1800 | Test Loss 2.496845 | NFE 20 []
Iter 1900 | Time 0.5275(0.5082) | Loss 2.498943(2.494890) | NFE Forward 20(19.7) | NFE Backward 21(22.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 1900 | Test Loss 2.493134 | NFE 20 []
Iter 2000 | Time 0.5119(0.5049) | Loss 2.496050(2.494190) | NFE Forward 20(20.0) | NFE Backward 21(21.8) | CNF Time 0.0000(0.0000)
[TEST] Iter 2000 | Test Loss 2.495107 | NFE 20 []
Iter 2100 | Time 0.5178(0.5125) | Loss 2.494964(2.495183) | NFE Forward 20(19.8) | NFE Backward 27(22.8) | CNF Time 0.0000(0.0000)
[TEST] Iter 2100 | Test Loss 2.493013 | NFE 20 []
Iter 2200 | Time 0.5266(0.5145) | Loss 2.502920(2.495570) | NFE Forward 20(19.9) | NFE Backward 27(22.8) | CNF Time 0.0000(0.0000)
[TEST] Iter 2200 | Test Loss 2.496040 | NFE 20 []
Iter 2300 | Time 0.4693(0.5054) | Loss 2.496576(2.495017) | NFE Forward 20(20.0) | NFE Backward 21(22.4) | CNF Time 0.0000(0.0000)
[TEST] Iter 2300 | Test Loss 2.498814 | NFE 20 []
Iter 2400 | Time 0.5113(0.4964) | Loss 2.493896(2.495772) | NFE Forward 20(19.6) | NFE Backward 27(21.9) | CNF Time 0.0000(0.0000)
[TEST] Iter 2400 | Test Loss 2.495577 | NFE 20 []
Iter 2500 | Time 0.5187(0.4903) | Loss 2.493290(2.496126) | NFE Forward 20(19.8) | NFE Backward 21(21.3) | CNF Time 0.0000(0.0000)
[TEST] Iter 2500 | Test Loss 2.492198 | NFE 20 []
Iter 2600 | Time 0.4759(0.4908) | Loss 2.500962(2.494525) | NFE Forward 20(19.8) | NFE Backward 21(21.3) | CNF Time 0.0000(0.0000)
[TEST] Iter 2600 | Test Loss 2.499933 | NFE 20 []
Iter 2700 | Time 0.5138(0.4936) | Loss 2.495091(2.494939) | NFE Forward 20(19.6) | NFE Backward 27(21.9) | CNF Time 0.0000(0.0000)
[TEST] Iter 2700 | Test Loss 2.496485 | NFE 20 []
Iter 2800 | Time 0.4549(0.4780) | Loss 2.493398(2.495473) | NFE Forward 20(19.9) | NFE Backward 21(21.1) | CNF Time 0.0000(0.0000)
[TEST] Iter 2800 | Test Loss 2.495195 | NFE 20 []
Iter 2900 | Time 0.4865(0.4846) | Loss 2.494968(2.494226) | NFE Forward 20(20.0) | NFE Backward 21(21.2) | CNF Time 0.0000(0.0000)
[TEST] Iter 2900 | Test Loss 2.499285 | NFE 20 []
Iter 3000 | Time 0.4720(0.4830) | Loss 2.492375(2.495747) | NFE Forward 20(19.5) | NFE Backward 21(21.4) | CNF Time 0.0000(0.0000)
[TEST] Iter 3000 | Test Loss 2.494009 | NFE 20 []
Iter 3100 | Time 0.4770(0.4765) | Loss 2.492125(2.494765) | NFE Forward 20(19.9) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 3100 | Test Loss 2.496904 | NFE 20 []
Iter 3200 | Time 0.4722(0.4719) | Loss 2.498013(2.495791) | NFE Forward 20(19.9) | NFE Backward 21(21.1) | CNF Time 0.0000(0.0000)
[TEST] Iter 3200 | Test Loss 2.500115 | NFE 20 []
Iter 3300 | Time 0.4645(0.4762) | Loss 2.493996(2.495684) | NFE Forward 20(19.9) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 3300 | Test Loss 2.493217 | NFE 20 []
Iter 3400 | Time 0.4601(0.4729) | Loss 2.493412(2.494732) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 3400 | Test Loss 2.498284 | NFE 20 []
Iter 3500 | Time 0.4738(0.4723) | Loss 2.499558(2.495707) | NFE Forward 20(19.8) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 3500 | Test Loss 2.490129 | NFE 20 []
Iter 3600 | Time 0.4654(0.4713) | Loss 2.496874(2.494065) | NFE Forward 20(19.7) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 3600 | Test Loss 2.487099 | NFE 20 []
Iter 3700 | Time 0.5205(0.4725) | Loss 2.493303(2.495602) | NFE Forward 20(19.7) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 3700 | Test Loss 2.490753 | NFE 20 []
Iter 3800 | Time 0.4793(0.4742) | Loss 2.495382(2.496024) | NFE Forward 20(19.8) | NFE Backward 21(21.3) | CNF Time 0.0000(0.0000)
[TEST] Iter 3800 | Test Loss 2.500959 | NFE 20 []
Iter 3900 | Time 0.4653(0.4686) | Loss 2.499078(2.495543) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 3900 | Test Loss 2.507476 | NFE 20 []
Iter 4000 | Time 0.4778(0.4733) | Loss 2.491665(2.494958) | NFE Forward 20(19.4) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 4000 | Test Loss 2.500544 | NFE 20 []
Iter 4100 | Time 0.4626(0.4673) | Loss 2.498121(2.494442) | NFE Forward 20(19.3) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 4100 | Test Loss 2.488545 | NFE 20 []
Iter 4200 | Time 0.4795(0.4708) | Loss 2.502789(2.494762) | NFE Forward 20(19.9) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 4200 | Test Loss 2.498373 | NFE 20 []
Iter 4300 | Time 0.4603(0.4680) | Loss 2.495788(2.495353) | NFE Forward 20(19.5) | NFE Backward 21(21.1) | CNF Time 0.0000(0.0000)
[TEST] Iter 4300 | Test Loss 2.497100 | NFE 20 []
Iter 4400 | Time 0.4758(0.4687) | Loss 2.498219(2.494946) | NFE Forward 14(19.2) | NFE Backward 21(21.1) | CNF Time 0.0000(0.0000)
[TEST] Iter 4400 | Test Loss 2.487953 | NFE 14 []
Iter 4500 | Time 0.4652(0.4685) | Loss 2.500176(2.496339) | NFE Forward 20(18.9) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 4500 | Test Loss 2.494857 | NFE 20 []
Iter 4600 | Time 0.4590(0.4667) | Loss 2.498913(2.494632) | NFE Forward 14(18.1) | NFE Backward 21(21.0) | CNF Time 0.0000(0.0000)
[TEST] Iter 4600 | Test Loss 2.495548 | NFE 20 []
Iter 4700 | Time 0.4574(0.4732) | Loss 2.498049(2.494440) | NFE Forward 20(18.8) | NFE Backward 21(21.1) | CNF Time 0.0000(0.0000)
[TEST] Iter 4700 | Test Loss 2.493306 | NFE 20 []
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, data='pinwheel', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, nhidden=1, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='hep', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, nhidden=1, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='hep', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, nhidden=1, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, nhidden=1, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, nhidden=1, niters=10000, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 00 | Iter 0000 | Time 3.2759(3.2759) | Loss 37.758087(37.758087) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.0000(1.0000)
[VAL] Epoch 00 | Val Loss 37.188291 | NFE 20 | NoImproveEpochs 01/16
Epoch 00 | Iter 0010 | Time 2.5974(3.2231) | Loss 35.672089(37.201101) | NFE Forward 20(20.0) | NFE Backward 27(22.5) | CNF Time 1.0000(1.0000)
Epoch 00 | Iter 0020 | Time 2.8299(3.0710) | Loss 34.791130(36.516213) | NFE Forward 26(21.5) | NFE Backward 27(24.0) | CNF Time 1.0000(1.0000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 00 | Iter 0000 | Time 3.084(3.084) | Loss 37.604(37.604) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss 37.147 | NFE 20 | NoImproveEpochs 01/16
Epoch 00 | Iter 0010 | Time 2.646(3.126) | Loss 35.558(37.078) | NFE Forward 20(20.0) | NFE Backward 27(22.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0020 | Time 3.307(3.045) | Loss 34.832(36.430) | NFE Forward 26(21.7) | NFE Backward 33(24.4) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 00 | Iter 0000 | Time 3.701(3.701) | Loss 37.248(37.248) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss 36.849 | NFE 20 | NoImproveEpochs 01/16
Epoch 00 | Iter 0010 | Time 2.630(3.518) | Loss 35.556(36.819) | NFE Forward 20(20.0) | NFE Backward 27(22.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0020 | Time 2.862(3.260) | Loss 34.724(36.233) | NFE Forward 26(21.1) | NFE Backward 27(24.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0030 | Time 2.850(3.138) | Loss 32.284(35.300) | NFE Forward 26(22.7) | NFE Backward 27(25.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0040 | Time 3.115(3.043) | Loss 26.670(33.274) | NFE Forward 32(24.1) | NFE Backward 27(25.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0050 | Time 4.747(3.397) | Loss 20.107(29.741) | NFE Forward 32(26.7) | NFE Backward 51(30.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0060 | Time 4.369(3.801) | Loss 14.261(25.383) | NFE Forward 32(28.5) | NFE Backward 45(36.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0070 | Time 4.974(4.181) | Loss 8.804(20.597) | NFE Forward 38(31.9) | NFE Backward 51(41.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0080 | Time 5.434(4.531) | Loss 3.744(15.668) | NFE Forward 38(33.9) | NFE Backward 57(45.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0090 | Time 5.795(4.901) | Loss 0.243(10.889) | NFE Forward 50(37.7) | NFE Backward 57(49.3) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0100 | Time 5.905(5.206) | Loss -2.300(6.630) | NFE Forward 50(41.8) | NFE Backward 57(51.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0110 | Time 5.810(5.412) | Loss -5.423(2.896) | NFE Forward 50(44.6) | NFE Backward 57(53.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0120 | Time 5.818(5.557) | Loss -8.032(-0.313) | NFE Forward 50(46.4) | NFE Backward 57(54.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0130 | Time 6.267(5.745) | Loss -10.240(-3.226) | NFE Forward 50(47.6) | NFE Backward 63(57.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0140 | Time 6.286(5.887) | Loss -12.078(-5.775) | NFE Forward 50(48.4) | NFE Backward 63(58.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0150 | Time 6.280(6.009) | Loss -13.574(-8.101) | NFE Forward 50(48.9) | NFE Backward 63(60.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0160 | Time 6.299(6.099) | Loss -14.400(-9.973) | NFE Forward 50(49.3) | NFE Backward 63(61.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0170 | Time 6.273(6.148) | Loss -16.007(-11.757) | NFE Forward 50(49.5) | NFE Backward 63(61.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0180 | Time 6.284(6.193) | Loss -17.085(-13.259) | NFE Forward 50(49.7) | NFE Backward 63(62.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0190 | Time 6.223(6.210) | Loss -18.526(-14.897) | NFE Forward 50(49.8) | NFE Backward 63(62.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0200 | Time 6.236(6.237) | Loss -19.509(-16.340) | NFE Forward 50(50.3) | NFE Backward 63(62.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0210 | Time 6.156(6.265) | Loss -18.951(-17.723) | NFE Forward 50(50.6) | NFE Backward 63(63.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0220 | Time 6.228(6.270) | Loss -21.716(-18.809) | NFE Forward 50(50.8) | NFE Backward 63(63.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0230 | Time 6.242(6.260) | Loss -23.859(-20.033) | NFE Forward 50(50.5) | NFE Backward 63(63.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0240 | Time 6.212(6.271) | Loss -24.197(-21.260) | NFE Forward 50(51.1) | NFE Backward 63(63.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0250 | Time 6.184(6.384) | Loss -23.783(-21.873) | NFE Forward 50(52.7) | NFE Backward 63(63.9) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -23.722 | NFE 50 | NoImproveEpochs 02/16
Epoch 00 | Iter 0260 | Time 6.208(6.991) | Loss -25.176(-22.670) | NFE Forward 50(52.1) | NFE Backward 63(63.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0270 | Time 6.537(6.762) | Loss -24.883(-23.588) | NFE Forward 62(52.6) | NFE Backward 63(63.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0280 | Time 7.388(6.743) | Loss -24.936(-24.294) | NFE Forward 62(54.5) | NFE Backward 75(64.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0290 | Time 6.636(6.701) | Loss -26.334(-25.013) | NFE Forward 62(55.8) | NFE Backward 63(64.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0300 | Time 6.435(6.590) | Loss -28.351(-25.824) | NFE Forward 56(55.7) | NFE Backward 63(64.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0310 | Time 7.015(6.656) | Loss -27.936(-26.575) | NFE Forward 62(56.2) | NFE Backward 69(65.3) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0320 | Time 7.454(6.727) | Loss -27.315(-27.097) | NFE Forward 62(57.2) | NFE Backward 75(66.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0330 | Time 6.811(6.723) | Loss -30.145(-27.839) | NFE Forward 56(57.3) | NFE Backward 69(66.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0340 | Time 6.825(6.746) | Loss -30.561(-28.609) | NFE Forward 56(57.1) | NFE Backward 69(66.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0350 | Time 7.056(6.812) | Loss -30.233(-29.128) | NFE Forward 62(57.6) | NFE Backward 69(67.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0360 | Time 7.067(6.829) | Loss -30.475(-29.628) | NFE Forward 62(57.9) | NFE Backward 69(67.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0370 | Time 6.766(6.816) | Loss -31.957(-30.240) | NFE Forward 56(57.2) | NFE Backward 69(68.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0380 | Time 6.849(6.820) | Loss -31.420(-30.676) | NFE Forward 56(56.8) | NFE Backward 69(68.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0390 | Time 6.827(6.854) | Loss -32.143(-30.993) | NFE Forward 56(57.2) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0400 | Time 6.866(6.838) | Loss -32.743(-31.494) | NFE Forward 56(56.8) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0410 | Time 6.688(6.828) | Loss -33.117(-31.930) | NFE Forward 56(56.5) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0420 | Time 6.881(6.829) | Loss -33.091(-32.275) | NFE Forward 56(56.3) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0430 | Time 7.184(6.869) | Loss -32.048(-32.450) | NFE Forward 56(56.2) | NFE Backward 75(69.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0440 | Time 6.696(6.847) | Loss -33.126(-32.642) | NFE Forward 56(56.2) | NFE Backward 69(69.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0450 | Time 6.849(6.843) | Loss -33.879(-33.029) | NFE Forward 56(56.1) | NFE Backward 69(69.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0460 | Time 6.823(6.865) | Loss -33.687(-33.280) | NFE Forward 56(56.1) | NFE Backward 69(69.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0470 | Time 6.835(6.859) | Loss -33.410(-33.493) | NFE Forward 56(56.0) | NFE Backward 69(69.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0480 | Time 6.961(6.865) | Loss -34.537(-33.695) | NFE Forward 56(56.0) | NFE Backward 69(69.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0490 | Time 6.841(6.851) | Loss -33.715(-33.900) | NFE Forward 56(56.0) | NFE Backward 69(69.3) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0500 | Time 6.679(6.826) | Loss -35.103(-34.092) | NFE Forward 56(56.0) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0510 | Time 6.717(6.830) | Loss -34.696(-34.222) | NFE Forward 56(56.0) | NFE Backward 69(69.3) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -34.059 | NFE 56 | NoImproveEpochs 03/16
Epoch 00 | Iter 0520 | Time 6.862(7.488) | Loss -34.759(-34.336) | NFE Forward 56(56.0) | NFE Backward 69(69.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0530 | Time 6.741(7.284) | Loss -34.726(-34.483) | NFE Forward 56(56.0) | NFE Backward 69(70.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0540 | Time 6.711(7.154) | Loss -34.744(-34.562) | NFE Forward 56(56.0) | NFE Backward 69(70.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0550 | Time 6.879(7.047) | Loss -35.054(-34.911) | NFE Forward 56(56.0) | NFE Backward 69(69.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0560 | Time 6.763(7.014) | Loss -35.720(-35.194) | NFE Forward 56(56.0) | NFE Backward 69(70.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0570 | Time 7.248(7.063) | Loss -34.662(-34.984) | NFE Forward 56(56.0) | NFE Backward 75(71.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0580 | Time 6.853(7.040) | Loss -35.160(-35.112) | NFE Forward 56(56.0) | NFE Backward 69(71.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0590 | Time 6.846(7.011) | Loss -36.218(-35.391) | NFE Forward 56(56.0) | NFE Backward 69(71.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0600 | Time 6.842(6.965) | Loss -36.005(-35.624) | NFE Forward 56(56.0) | NFE Backward 69(70.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0610 | Time 6.852(6.972) | Loss -36.454(-35.833) | NFE Forward 56(56.0) | NFE Backward 69(70.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0620 | Time 7.275(6.994) | Loss -35.952(-35.953) | NFE Forward 56(56.0) | NFE Backward 75(71.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0630 | Time 7.187(7.029) | Loss -36.548(-36.109) | NFE Forward 56(56.0) | NFE Backward 75(71.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0640 | Time 7.251(6.997) | Loss -35.861(-36.379) | NFE Forward 56(56.0) | NFE Backward 75(71.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0650 | Time 7.228(7.002) | Loss -35.289(-36.442) | NFE Forward 56(56.0) | NFE Backward 75(71.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0660 | Time 7.124(7.069) | Loss -36.136(-36.285) | NFE Forward 56(56.0) | NFE Backward 75(72.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0670 | Time 7.127(7.083) | Loss -36.952(-36.308) | NFE Forward 56(56.0) | NFE Backward 75(73.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0680 | Time 7.284(7.117) | Loss -37.379(-36.526) | NFE Forward 56(56.0) | NFE Backward 75(73.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0690 | Time 6.871(7.101) | Loss -37.204(-36.720) | NFE Forward 56(56.0) | NFE Backward 69(73.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0700 | Time 7.210(7.051) | Loss -35.527(-36.873) | NFE Forward 56(56.0) | NFE Backward 75(72.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0710 | Time 7.178(7.116) | Loss -35.640(-36.615) | NFE Forward 56(56.2) | NFE Backward 75(73.3) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0720 | Time 7.245(7.145) | Loss -37.448(-36.839) | NFE Forward 56(56.1) | NFE Backward 75(73.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0730 | Time 6.766(7.061) | Loss -37.315(-37.180) | NFE Forward 56(56.1) | NFE Backward 69(72.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0740 | Time 7.219(7.058) | Loss -38.507(-37.400) | NFE Forward 56(56.3) | NFE Backward 75(72.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0750 | Time 7.205(7.084) | Loss -38.183(-37.524) | NFE Forward 56(56.4) | NFE Backward 75(72.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0760 | Time 7.237(7.145) | Loss -38.213(-37.510) | NFE Forward 56(57.1) | NFE Backward 75(73.3) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -38.095 | NFE 56 | NoImproveEpochs 04/16
Epoch 00 | Iter 0770 | Time 6.857(7.945) | Loss -37.958(-37.596) | NFE Forward 56(57.5) | NFE Backward 69(73.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0780 | Time 7.198(7.711) | Loss -37.750(-37.559) | NFE Forward 56(57.8) | NFE Backward 75(73.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0790 | Time 7.336(7.551) | Loss -38.133(-37.742) | NFE Forward 62(57.6) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0800 | Time 7.449(7.415) | Loss -38.843(-38.006) | NFE Forward 62(57.5) | NFE Backward 75(73.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0810 | Time 7.215(7.379) | Loss -39.231(-38.152) | NFE Forward 56(58.0) | NFE Backward 75(74.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0820 | Time 7.332(7.378) | Loss -37.943(-38.148) | NFE Forward 62(58.9) | NFE Backward 75(74.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0830 | Time 7.433(7.391) | Loss -37.945(-38.219) | NFE Forward 62(59.8) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0840 | Time 7.846(7.420) | Loss -38.917(-38.435) | NFE Forward 62(60.5) | NFE Backward 81(75.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0850 | Time 7.439(7.384) | Loss -38.516(-38.520) | NFE Forward 62(60.4) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0860 | Time 7.397(7.392) | Loss -38.112(-38.349) | NFE Forward 62(61.0) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0870 | Time 7.436(7.400) | Loss -39.208(-38.480) | NFE Forward 62(61.1) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0880 | Time 7.323(7.385) | Loss -39.551(-38.683) | NFE Forward 62(61.2) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0890 | Time 7.420(7.366) | Loss -39.581(-38.880) | NFE Forward 62(60.9) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0900 | Time 7.461(7.389) | Loss -38.531(-38.904) | NFE Forward 62(61.2) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0910 | Time 7.428(7.396) | Loss -38.594(-38.818) | NFE Forward 62(61.3) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0920 | Time 7.438(7.423) | Loss -39.642(-38.732) | NFE Forward 62(61.5) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0930 | Time 7.393(7.427) | Loss -38.930(-38.828) | NFE Forward 62(61.7) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0940 | Time 7.822(7.473) | Loss -39.643(-39.192) | NFE Forward 62(61.6) | NFE Backward 81(75.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0950 | Time 7.424(7.471) | Loss -39.175(-39.242) | NFE Forward 62(61.7) | NFE Backward 75(75.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0960 | Time 7.901(7.467) | Loss -39.325(-39.517) | NFE Forward 62(61.6) | NFE Backward 81(75.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0970 | Time 7.429(7.500) | Loss -38.306(-39.351) | NFE Forward 62(61.8) | NFE Backward 75(76.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0980 | Time 7.377(7.490) | Loss -40.501(-39.364) | NFE Forward 62(61.8) | NFE Backward 75(75.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 0990 | Time 7.387(7.484) | Loss -39.177(-39.464) | NFE Forward 62(61.9) | NFE Backward 75(75.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1000 | Time 7.456(7.467) | Loss -40.765(-39.579) | NFE Forward 62(61.9) | NFE Backward 75(75.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1010 | Time 7.773(7.495) | Loss -40.841(-39.800) | NFE Forward 62(62.0) | NFE Backward 81(76.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1020 | Time 7.884(7.547) | Loss -39.696(-39.770) | NFE Forward 62(62.0) | NFE Backward 81(76.7) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -39.813 | NFE 62 | NoImproveEpochs 05/16
Epoch 00 | Iter 1030 | Time 7.874(8.328) | Loss -40.243(-39.780) | NFE Forward 62(62.0) | NFE Backward 81(77.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1040 | Time 7.832(8.059) | Loss -40.266(-39.887) | NFE Forward 62(62.0) | NFE Backward 81(77.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1050 | Time 7.423(7.879) | Loss -40.135(-39.957) | NFE Forward 62(62.0) | NFE Backward 75(76.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1060 | Time 7.859(7.823) | Loss -40.282(-40.035) | NFE Forward 62(62.0) | NFE Backward 81(77.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1070 | Time 7.036(7.752) | Loss -41.090(-40.124) | NFE Forward 62(62.0) | NFE Backward 69(77.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1080 | Time 7.358(7.723) | Loss -40.247(-40.248) | NFE Forward 62(62.0) | NFE Backward 75(77.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1090 | Time 7.891(7.695) | Loss -40.756(-40.480) | NFE Forward 62(62.0) | NFE Backward 81(77.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1100 | Time 7.817(7.722) | Loss -40.055(-40.539) | NFE Forward 62(62.0) | NFE Backward 81(78.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1110 | Time 7.868(7.736) | Loss -40.666(-40.596) | NFE Forward 62(62.0) | NFE Backward 81(79.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1120 | Time 7.843(7.728) | Loss -40.735(-40.633) | NFE Forward 62(62.0) | NFE Backward 81(79.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1130 | Time 7.824(7.742) | Loss -41.216(-40.646) | NFE Forward 62(62.0) | NFE Backward 81(79.3) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1140 | Time 7.839(7.711) | Loss -40.494(-40.677) | NFE Forward 62(62.0) | NFE Backward 81(78.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1150 | Time 7.436(7.730) | Loss -40.563(-40.783) | NFE Forward 62(62.0) | NFE Backward 75(79.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1160 | Time 7.892(7.750) | Loss -41.158(-40.793) | NFE Forward 62(62.0) | NFE Backward 81(79.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1170 | Time 7.827(7.754) | Loss -41.262(-41.080) | NFE Forward 62(62.0) | NFE Backward 81(79.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1180 | Time 7.900(7.779) | Loss -41.931(-41.133) | NFE Forward 62(62.0) | NFE Backward 81(80.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1190 | Time 7.802(7.752) | Loss -41.304(-41.063) | NFE Forward 62(62.0) | NFE Backward 81(79.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1200 | Time 7.858(7.788) | Loss -40.665(-41.137) | NFE Forward 62(62.0) | NFE Backward 81(80.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1210 | Time 7.924(7.813) | Loss -41.763(-41.254) | NFE Forward 62(62.0) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1220 | Time 7.890(7.785) | Loss -41.823(-41.305) | NFE Forward 62(62.0) | NFE Backward 81(80.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1230 | Time 7.855(7.780) | Loss -41.739(-41.289) | NFE Forward 62(62.0) | NFE Backward 81(80.1) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1240 | Time 7.916(7.807) | Loss -42.477(-41.438) | NFE Forward 62(62.0) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1250 | Time 7.471(7.779) | Loss -41.084(-41.617) | NFE Forward 62(62.0) | NFE Backward 75(80.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1260 | Time 7.850(7.799) | Loss -42.862(-41.753) | NFE Forward 62(62.0) | NFE Backward 81(80.3) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1270 | Time 7.864(7.799) | Loss -40.073(-41.677) | NFE Forward 62(62.0) | NFE Backward 81(80.3) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1280 | Time 7.484(7.778) | Loss -42.500(-41.789) | NFE Forward 62(62.0) | NFE Backward 75(80.1) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -41.529 | NFE 62 | NoImproveEpochs 06/16
Epoch 00 | Iter 1290 | Time 7.479(8.414) | Loss -42.332(-41.834) | NFE Forward 62(62.0) | NFE Backward 75(80.2) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1300 | Time 7.855(8.230) | Loss -42.480(-41.827) | NFE Forward 62(62.0) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1310 | Time 7.918(8.113) | Loss -42.510(-42.045) | NFE Forward 62(62.0) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1320 | Time 7.872(8.011) | Loss -42.542(-42.213) | NFE Forward 62(62.0) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1330 | Time 7.917(7.939) | Loss -42.114(-42.060) | NFE Forward 62(62.0) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1340 | Time 7.870(7.884) | Loss -43.244(-42.206) | NFE Forward 62(62.0) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1350 | Time 7.822(7.850) | Loss -42.696(-42.401) | NFE Forward 62(62.0) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1360 | Time 7.917(7.841) | Loss -41.582(-42.629) | NFE Forward 62(62.0) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1370 | Time 7.929(7.835) | Loss -43.018(-42.608) | NFE Forward 62(62.0) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1380 | Time 7.844(7.824) | Loss -42.704(-42.661) | NFE Forward 62(62.0) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1390 | Time 7.830(7.826) | Loss -43.326(-42.843) | NFE Forward 62(62.0) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1400 | Time 7.852(7.816) | Loss -42.419(-42.704) | NFE Forward 62(62.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1410 | Time 7.758(7.825) | Loss -41.978(-42.645) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1420 | Time 7.835(7.826) | Loss -42.986(-42.761) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1430 | Time 7.908(7.845) | Loss -42.929(-42.901) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1440 | Time 7.756(7.857) | Loss -43.431(-42.926) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1450 | Time 7.790(7.861) | Loss -43.672(-43.059) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1460 | Time 7.923(7.869) | Loss -42.404(-42.971) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1470 | Time 7.905(7.878) | Loss -43.998(-42.981) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1480 | Time 7.857(7.872) | Loss -43.225(-43.150) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1490 | Time 7.854(7.851) | Loss -42.726(-43.109) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1500 | Time 7.926(7.855) | Loss -43.870(-43.034) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1510 | Time 7.912(7.840) | Loss -44.201(-43.148) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1520 | Time 7.933(7.859) | Loss -43.188(-43.213) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1530 | Time 7.742(7.853) | Loss -43.952(-43.454) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -43.629 | NFE 62 | NoImproveEpochs 07/16
Epoch 00 | Iter 1540 | Time 7.754(8.655) | Loss -42.436(-43.474) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1550 | Time 7.894(8.370) | Loss -44.168(-43.585) | NFE Forward 62(62.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1560 | Time 7.922(8.174) | Loss -43.792(-43.632) | NFE Forward 62(62.0) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1570 | Time 7.896(8.069) | Loss -44.330(-43.635) | NFE Forward 62(62.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1580 | Time 7.783(7.999) | Loss -44.679(-43.828) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1590 | Time 7.777(7.954) | Loss -42.570(-43.908) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1600 | Time 7.761(7.916) | Loss -43.760(-43.903) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1610 | Time 7.873(7.894) | Loss -44.140(-43.814) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1620 | Time 7.770(7.876) | Loss -44.350(-43.840) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1630 | Time 7.891(7.875) | Loss -43.684(-43.967) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1640 | Time 7.933(7.867) | Loss -43.747(-44.118) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1650 | Time 7.906(7.857) | Loss -44.670(-44.157) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1660 | Time 7.896(7.850) | Loss -43.799(-44.233) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1670 | Time 7.887(7.862) | Loss -44.515(-44.381) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1680 | Time 7.713(7.848) | Loss -44.524(-44.440) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1690 | Time 7.949(7.842) | Loss -45.310(-44.473) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1700 | Time 7.882(7.838) | Loss -44.260(-44.661) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1710 | Time 7.886(7.835) | Loss -45.134(-44.756) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1720 | Time 7.862(7.840) | Loss -44.088(-44.560) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1730 | Time 7.838(7.839) | Loss -44.523(-44.441) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1740 | Time 7.883(7.844) | Loss -44.379(-44.492) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1750 | Time 7.913(7.857) | Loss -44.737(-44.569) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1760 | Time 7.770(7.853) | Loss -44.537(-44.700) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1770 | Time 7.926(7.861) | Loss -44.806(-44.730) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1780 | Time 7.753(7.856) | Loss -44.824(-44.674) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1790 | Time 7.841(7.851) | Loss -46.007(-44.930) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -45.474 | NFE 62 | NoImproveEpochs 08/16
Epoch 00 | Iter 1800 | Time 7.704(8.528) | Loss -45.975(-45.182) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1810 | Time 7.880(8.287) | Loss -45.930(-45.425) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1820 | Time 7.776(8.130) | Loss -44.962(-45.317) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1830 | Time 7.816(8.031) | Loss -45.593(-45.328) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1840 | Time 7.875(7.973) | Loss -45.424(-45.318) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1850 | Time 7.941(7.926) | Loss -44.880(-45.367) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1860 | Time 7.832(7.897) | Loss -45.261(-45.469) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1870 | Time 7.906(7.892) | Loss -45.767(-45.487) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1880 | Time 7.915(7.882) | Loss -46.205(-45.610) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1890 | Time 7.919(7.872) | Loss -44.421(-45.716) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1900 | Time 7.920(7.865) | Loss -45.696(-45.560) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1910 | Time 7.877(7.850) | Loss -45.263(-45.429) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1920 | Time 7.830(7.844) | Loss -47.102(-45.633) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1930 | Time 7.749(7.842) | Loss -45.536(-45.943) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1940 | Time 7.846(7.840) | Loss -46.316(-46.034) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1950 | Time 7.824(7.842) | Loss -46.258(-46.022) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1960 | Time 7.896(7.860) | Loss -46.437(-46.116) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1970 | Time 7.854(7.866) | Loss -47.173(-46.298) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1980 | Time 7.900(7.861) | Loss -46.136(-46.318) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 1990 | Time 7.914(7.860) | Loss -45.486(-46.257) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2000 | Time 7.822(7.854) | Loss -45.891(-46.187) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2010 | Time 7.938(7.852) | Loss -47.195(-46.317) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2020 | Time 7.902(7.865) | Loss -46.091(-46.354) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2030 | Time 7.886(7.857) | Loss -47.320(-46.438) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2040 | Time 7.823(7.860) | Loss -45.998(-46.571) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -45.611 | NFE 62 | NoImproveEpochs 09/16
Epoch 00 | Iter 2050 | Time 7.972(8.726) | Loss -45.718(-46.394) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2060 | Time 7.905(8.439) | Loss -46.776(-46.484) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2070 | Time 7.872(8.243) | Loss -47.774(-46.638) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2080 | Time 7.929(8.120) | Loss -46.033(-46.845) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2090 | Time 7.894(8.038) | Loss -47.580(-46.919) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2100 | Time 7.923(7.986) | Loss -46.448(-46.918) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2110 | Time 7.881(7.945) | Loss -46.323(-46.720) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2120 | Time 7.895(7.918) | Loss -46.109(-46.745) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2130 | Time 7.820(7.901) | Loss -46.700(-46.784) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2140 | Time 7.853(7.885) | Loss -46.403(-46.753) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2150 | Time 7.897(7.871) | Loss -47.696(-47.078) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2160 | Time 7.830(7.863) | Loss -48.184(-47.340) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2170 | Time 7.869(7.857) | Loss -46.876(-47.404) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2180 | Time 7.867(7.857) | Loss -46.950(-47.457) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2190 | Time 7.942(7.863) | Loss -47.137(-47.264) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2200 | Time 7.864(7.869) | Loss -47.189(-47.323) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2210 | Time 7.906(7.877) | Loss -48.451(-47.518) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2220 | Time 7.917(7.873) | Loss -47.011(-47.358) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2230 | Time 7.959(7.875) | Loss -48.135(-47.405) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2240 | Time 7.826(7.865) | Loss -49.265(-47.555) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2250 | Time 7.725(7.863) | Loss -48.459(-47.521) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2260 | Time 7.745(7.853) | Loss -47.452(-47.715) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2270 | Time 7.781(7.848) | Loss -48.730(-47.938) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2280 | Time 7.845(7.846) | Loss -48.095(-48.013) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2290 | Time 7.823(7.840) | Loss -46.277(-47.932) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2300 | Time 7.755(7.841) | Loss -48.040(-47.885) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -46.574 | NFE 62 | NoImproveEpochs 10/16
Epoch 00 | Iter 2310 | Time 7.809(8.589) | Loss -47.439(-47.731) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2320 | Time 7.870(8.345) | Loss -49.087(-47.901) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2330 | Time 7.934(8.192) | Loss -48.306(-48.010) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2340 | Time 7.812(8.085) | Loss -49.154(-48.145) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2350 | Time 7.886(8.018) | Loss -48.785(-48.279) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2360 | Time 7.887(7.963) | Loss -48.155(-48.171) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2370 | Time 7.839(7.923) | Loss -48.667(-48.301) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2380 | Time 7.844(7.906) | Loss -48.899(-48.431) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2390 | Time 7.919(7.894) | Loss -48.423(-48.613) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2400 | Time 7.867(7.889) | Loss -49.171(-48.587) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2410 | Time 7.785(7.878) | Loss -47.908(-48.319) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2420 | Time 7.896(7.879) | Loss -48.405(-48.369) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2430 | Time 7.857(7.877) | Loss -49.249(-48.412) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2440 | Time 7.926(7.879) | Loss -49.520(-48.536) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2450 | Time 7.930(7.882) | Loss -49.009(-48.756) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2460 | Time 7.895(7.889) | Loss -48.852(-48.765) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2470 | Time 7.840(7.878) | Loss -50.284(-48.964) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2480 | Time 7.915(7.875) | Loss -49.328(-49.023) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2490 | Time 7.878(7.861) | Loss -49.251(-49.009) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2500 | Time 7.864(7.848) | Loss -48.596(-48.961) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2510 | Time 7.732(7.842) | Loss -48.935(-48.891) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2520 | Time 7.869(7.836) | Loss -47.740(-49.059) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2530 | Time 7.722(7.826) | Loss -49.245(-49.059) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2540 | Time 7.822(7.833) | Loss -49.817(-48.994) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2550 | Time 7.860(7.847) | Loss -48.981(-49.126) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2560 | Time 7.895(7.849) | Loss -50.088(-49.142) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -48.283 | NFE 62 | NoImproveEpochs 11/16
Epoch 00 | Iter 2570 | Time 7.812(8.481) | Loss -49.752(-49.393) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2580 | Time 7.889(8.270) | Loss -48.924(-49.239) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2590 | Time 7.877(8.121) | Loss -49.810(-49.173) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2600 | Time 7.845(8.025) | Loss -48.715(-49.140) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2610 | Time 7.840(7.955) | Loss -50.038(-49.304) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2620 | Time 7.852(7.919) | Loss -49.829(-49.530) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2630 | Time 7.793(7.883) | Loss -50.737(-49.757) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2640 | Time 7.838(7.862) | Loss -50.323(-49.893) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2650 | Time 7.823(7.852) | Loss -49.758(-50.026) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2660 | Time 7.834(7.846) | Loss -50.778(-49.972) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2670 | Time 7.848(7.844) | Loss -49.237(-49.986) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2680 | Time 7.856(7.842) | Loss -49.439(-49.754) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2690 | Time 7.824(7.831) | Loss -50.623(-49.865) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2700 | Time 7.802(7.826) | Loss -49.265(-49.749) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2710 | Time 7.864(7.833) | Loss -50.085(-49.811) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2720 | Time 7.803(7.835) | Loss -51.011(-49.847) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2730 | Time 7.881(7.828) | Loss -49.869(-49.786) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2740 | Time 7.893(7.826) | Loss -50.536(-49.963) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2750 | Time 7.879(7.826) | Loss -51.170(-50.229) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2760 | Time 7.944(7.833) | Loss -51.552(-50.263) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2770 | Time 7.855(7.832) | Loss -50.280(-50.230) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2780 | Time 7.777(7.835) | Loss -50.182(-50.027) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2790 | Time 7.857(7.836) | Loss -50.854(-50.056) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2800 | Time 7.828(7.827) | Loss -49.843(-50.145) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2810 | Time 7.883(7.837) | Loss -50.351(-50.081) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -50.503 | NFE 62 | NoImproveEpochs 12/16
Epoch 00 | Iter 2820 | Time 7.859(8.629) | Loss -50.800(-50.384) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2830 | Time 7.832(8.366) | Loss -50.281(-50.554) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2840 | Time 7.863(8.193) | Loss -49.482(-50.433) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2850 | Time 7.831(8.060) | Loss -50.404(-50.389) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2860 | Time 7.890(7.982) | Loss -49.416(-50.468) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2870 | Time 7.805(7.929) | Loss -50.780(-50.518) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2880 | Time 7.786(7.900) | Loss -50.603(-50.573) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2890 | Time 7.824(7.879) | Loss -52.063(-50.762) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2900 | Time 7.763(7.864) | Loss -50.839(-50.785) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2910 | Time 7.804(7.856) | Loss -51.275(-50.872) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2920 | Time 7.830(7.852) | Loss -50.774(-50.624) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2930 | Time 7.863(7.838) | Loss -51.300(-50.560) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2940 | Time 7.765(7.840) | Loss -49.581(-50.711) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2950 | Time 7.782(7.838) | Loss -51.643(-50.660) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2960 | Time 7.877(7.836) | Loss -50.837(-50.497) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2970 | Time 7.839(7.847) | Loss -51.075(-50.622) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2980 | Time 7.962(7.847) | Loss -52.568(-50.952) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 2990 | Time 7.797(7.850) | Loss -52.050(-51.118) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3000 | Time 7.928(7.850) | Loss -51.124(-51.047) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3010 | Time 7.889(7.859) | Loss -51.038(-51.156) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3020 | Time 7.787(7.854) | Loss -52.188(-51.178) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3030 | Time 7.806(7.846) | Loss -50.433(-51.190) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3040 | Time 7.868(7.850) | Loss -50.205(-50.856) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3050 | Time 7.870(7.832) | Loss -50.792(-50.833) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3060 | Time 7.854(7.826) | Loss -49.551(-51.010) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3070 | Time 7.873(7.833) | Loss -51.720(-51.275) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 00 | Val Loss -51.177 | NFE 62 | NoImproveEpochs 13/16
Epoch 00 | Iter 3080 | Time 7.830(8.527) | Loss -50.959(-51.223) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3090 | Time 7.787(8.298) | Loss -51.860(-51.170) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3100 | Time 7.828(8.139) | Loss -51.317(-51.357) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3110 | Time 7.863(8.049) | Loss -50.901(-51.328) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3120 | Time 7.833(7.979) | Loss -52.237(-51.508) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3130 | Time 7.832(7.930) | Loss -51.767(-51.315) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3140 | Time 7.867(7.909) | Loss -49.028(-50.996) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3150 | Time 7.868(7.892) | Loss -52.063(-51.005) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3160 | Time 7.860(7.874) | Loss -52.367(-51.425) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 00 | Iter 3170 | Time 7.870(7.855) | Loss -52.098(-51.593) | NFE Forward 62(61.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0000 | Time 8.111(7.862) | Loss -51.728(-51.638) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 01 | Val Loss -51.820 | NFE 62 | NoImproveEpochs 14/16
Epoch 01 | Iter 0010 | Time 7.882(8.483) | Loss -50.977(-51.459) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0020 | Time 7.883(8.274) | Loss -52.065(-51.251) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0030 | Time 7.749(8.120) | Loss -52.762(-51.550) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0040 | Time 7.832(8.038) | Loss -50.793(-51.445) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0050 | Time 7.864(7.981) | Loss -52.909(-51.470) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0060 | Time 7.663(7.923) | Loss -50.742(-51.458) | NFE Forward 56(61.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0070 | Time 7.612(7.891) | Loss -51.342(-51.661) | NFE Forward 56(61.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0080 | Time 7.851(7.878) | Loss -50.599(-51.759) | NFE Forward 62(61.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0090 | Time 7.825(7.861) | Loss -52.055(-51.737) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0100 | Time 7.894(7.857) | Loss -51.325(-51.653) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0110 | Time 7.838(7.834) | Loss -51.375(-51.618) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0120 | Time 7.814(7.835) | Loss -52.453(-51.712) | NFE Forward 62(61.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0130 | Time 7.789(7.835) | Loss -53.062(-51.818) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0140 | Time 7.811(7.841) | Loss -51.504(-51.952) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0150 | Time 7.900(7.852) | Loss -50.501(-51.758) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0160 | Time 7.668(7.857) | Loss -51.077(-51.539) | NFE Forward 56(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0170 | Time 7.810(7.836) | Loss -52.547(-51.781) | NFE Forward 62(61.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0180 | Time 7.860(7.827) | Loss -52.366(-52.087) | NFE Forward 62(60.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0190 | Time 7.740(7.827) | Loss -53.153(-52.194) | NFE Forward 56(60.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0200 | Time 7.822(7.811) | Loss -51.352(-52.247) | NFE Forward 62(60.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0210 | Time 7.849(7.824) | Loss -53.198(-52.229) | NFE Forward 62(61.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0220 | Time 7.874(7.829) | Loss -52.723(-52.298) | NFE Forward 62(61.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0230 | Time 7.872(7.832) | Loss -51.911(-52.232) | NFE Forward 62(61.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0240 | Time 7.945(7.817) | Loss -49.846(-52.068) | NFE Forward 62(61.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0250 | Time 7.910(7.821) | Loss -51.571(-51.888) | NFE Forward 62(61.4) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
[VAL] Epoch 01 | Val Loss -52.202 | NFE 56 | NoImproveEpochs 15/16
Epoch 01 | Iter 0260 | Time 7.579(8.533) | Loss -52.204(-52.002) | NFE Forward 56(60.7) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0270 | Time 7.221(8.250) | Loss -52.960(-52.221) | NFE Forward 56(60.3) | NFE Backward 75(80.7) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0280 | Time 7.904(8.084) | Loss -53.705(-52.510) | NFE Forward 62(59.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0290 | Time 7.888(8.004) | Loss -51.220(-52.460) | NFE Forward 62(60.4) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0300 | Time 7.880(7.945) | Loss -50.719(-52.306) | NFE Forward 62(60.9) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0310 | Time 7.501(7.867) | Loss -52.273(-52.300) | NFE Forward 56(60.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0320 | Time 7.743(7.828) | Loss -53.544(-52.288) | NFE Forward 62(60.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0330 | Time 7.829(7.798) | Loss -52.478(-52.376) | NFE Forward 62(59.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0340 | Time 7.823(7.791) | Loss -52.731(-52.468) | NFE Forward 62(60.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0350 | Time 7.838(7.781) | Loss -52.157(-52.483) | NFE Forward 62(60.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0360 | Time 7.906(7.783) | Loss -53.158(-52.657) | NFE Forward 62(60.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0370 | Time 7.909(7.786) | Loss -53.516(-52.796) | NFE Forward 62(60.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0380 | Time 7.889(7.774) | Loss -53.547(-53.012) | NFE Forward 62(59.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0390 | Time 7.870(7.779) | Loss -53.664(-53.041) | NFE Forward 62(60.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0400 | Time 7.816(7.794) | Loss -51.426(-52.768) | NFE Forward 62(60.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0410 | Time 7.674(7.792) | Loss -52.823(-52.704) | NFE Forward 56(60.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0420 | Time 7.755(7.777) | Loss -51.774(-52.682) | NFE Forward 62(60.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0430 | Time 7.604(7.748) | Loss -52.201(-52.614) | NFE Forward 56(59.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0440 | Time 7.571(7.721) | Loss -53.714(-52.935) | NFE Forward 56(59.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0450 | Time 7.555(7.675) | Loss -52.253(-52.912) | NFE Forward 56(58.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0460 | Time 7.632(7.688) | Loss -53.067(-52.784) | NFE Forward 56(58.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0470 | Time 7.668(7.693) | Loss -52.516(-52.906) | NFE Forward 56(58.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0480 | Time 7.868(7.723) | Loss -51.783(-52.780) | NFE Forward 62(59.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0490 | Time 7.910(7.728) | Loss -53.322(-52.847) | NFE Forward 62(59.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0500 | Time 7.633(7.717) | Loss -53.237(-52.860) | NFE Forward 56(59.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0510 | Time 7.522(7.712) | Loss -53.237(-52.919) | NFE Forward 56(58.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 01 | Val Loss -51.868 | NFE 61 | NoImproveEpochs 16/16
Epoch 01 | Iter 0520 | Time 7.901(8.395) | Loss -52.968(-53.099) | NFE Forward 62(58.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0530 | Time 7.880(8.187) | Loss -52.740(-52.973) | NFE Forward 62(59.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0540 | Time 7.633(8.027) | Loss -52.883(-53.030) | NFE Forward 56(58.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0550 | Time 7.842(7.923) | Loss -53.468(-53.003) | NFE Forward 62(58.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0560 | Time 7.722(7.836) | Loss -53.629(-53.069) | NFE Forward 56(58.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0570 | Time 7.823(7.780) | Loss -53.416(-53.140) | NFE Forward 62(57.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0580 | Time 7.828(7.758) | Loss -52.882(-52.992) | NFE Forward 62(58.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0590 | Time 7.909(7.753) | Loss -53.038(-53.020) | NFE Forward 62(58.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0600 | Time 7.601(7.724) | Loss -53.873(-52.929) | NFE Forward 56(57.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0610 | Time 7.567(7.699) | Loss -54.335(-53.223) | NFE Forward 56(57.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0620 | Time 7.689(7.678) | Loss -53.114(-53.407) | NFE Forward 56(57.4) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0630 | Time 7.675(7.678) | Loss -53.529(-53.390) | NFE Forward 56(57.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0640 | Time 7.658(7.683) | Loss -53.463(-53.426) | NFE Forward 56(57.4) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0650 | Time 7.638(7.701) | Loss -53.557(-53.277) | NFE Forward 56(57.7) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0660 | Time 7.554(7.677) | Loss -53.485(-53.369) | NFE Forward 56(57.8) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0670 | Time 7.803(7.686) | Loss -53.348(-53.269) | NFE Forward 62(58.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0680 | Time 7.892(7.691) | Loss -54.114(-53.430) | NFE Forward 62(58.2) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0690 | Time 7.641(7.674) | Loss -54.467(-53.592) | NFE Forward 56(57.6) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0700 | Time 7.657(7.656) | Loss -54.396(-53.784) | NFE Forward 56(57.1) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0710 | Time 7.685(7.671) | Loss -53.908(-53.763) | NFE Forward 56(57.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0720 | Time 7.628(7.645) | Loss -53.210(-53.595) | NFE Forward 56(57.1) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0730 | Time 7.583(7.670) | Loss -53.170(-53.543) | NFE Forward 56(57.5) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0740 | Time 7.529(7.671) | Loss -53.077(-53.381) | NFE Forward 56(57.6) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0750 | Time 7.669(7.646) | Loss -55.006(-53.660) | NFE Forward 56(57.3) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 01 | Iter 0760 | Time 7.140(7.618) | Loss -54.435(-53.970) | NFE Forward 56(57.5) | NFE Backward 75(80.2) | CNF Time 1.000(1.000)
[VAL] Epoch 01 | Val Loss -53.316 | NFE 56 | NoImproveEpochs 17/16
Training has finished.
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 5.457(5.457) | Loss 36.816(36.816) | NFE Forward 20(20.0) | NFE Backward 27(27.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss 36.481 | NFE 20 | NoImproveEpochs 01/16
Epoch 0 | Iter 10 | Time 2.669(4.681) | Loss 35.457(36.471) | NFE Forward 20(20.0) | NFE Backward 27(26.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 2.880(4.059) | Loss 34.363(35.937) | NFE Forward 26(21.5) | NFE Backward 27(26.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 2.889(3.667) | Loss 31.376(34.909) | NFE Forward 26(23.0) | NFE Backward 27(26.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 3.111(3.400) | Loss 25.299(32.600) | NFE Forward 32(24.5) | NFE Backward 27(26.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 50 | Time 5.057(3.699) | Loss 18.647(28.779) | NFE Forward 38(27.2) | NFE Backward 51(32.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 60 | Time 4.626(4.027) | Loss 13.493(24.402) | NFE Forward 38(30.2) | NFE Backward 45(36.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 70 | Time 4.626(4.240) | Loss 8.402(19.791) | NFE Forward 38(32.7) | NFE Backward 45(39.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 80 | Time 5.490(4.649) | Loss 3.573(15.082) | NFE Forward 38(35.2) | NFE Backward 57(45.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 90 | Time 5.688(4.999) | Loss -0.692(10.458) | NFE Forward 44(38.0) | NFE Backward 57(49.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 100 | Time 5.828(5.239) | Loss -4.205(6.066) | NFE Forward 50(41.0) | NFE Backward 57(51.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 110 | Time 5.782(5.418) | Loss -7.885(1.863) | NFE Forward 50(43.7) | NFE Backward 57(53.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 120 | Time 5.800(5.580) | Loss -10.243(-1.728) | NFE Forward 50(45.8) | NFE Backward 57(55.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 130 | Time 6.203(5.708) | Loss -11.101(-4.594) | NFE Forward 50(47.2) | NFE Backward 63(56.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 140 | Time 6.249(5.810) | Loss -13.149(-7.242) | NFE Forward 50(48.1) | NFE Backward 63(57.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 150 | Time 6.273(5.951) | Loss -14.205(-9.634) | NFE Forward 50(48.8) | NFE Backward 63(59.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 160 | Time 6.206(6.079) | Loss -15.790(-11.345) | NFE Forward 50(49.2) | NFE Backward 63(61.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 170 | Time 6.265(6.133) | Loss -17.298(-13.032) | NFE Forward 50(49.5) | NFE Backward 63(61.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 180 | Time 6.264(6.171) | Loss -18.660(-14.681) | NFE Forward 50(49.6) | NFE Backward 63(62.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 190 | Time 6.612(6.260) | Loss -17.874(-15.871) | NFE Forward 62(50.9) | NFE Backward 63(62.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 200 | Time 6.647(6.253) | Loss -20.096(-17.195) | NFE Forward 62(51.1) | NFE Backward 63(62.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 210 | Time 6.161(6.241) | Loss -21.085(-18.320) | NFE Forward 50(51.0) | NFE Backward 63(63.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 220 | Time 6.172(6.226) | Loss -21.727(-19.544) | NFE Forward 50(50.9) | NFE Backward 63(63.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 230 | Time 6.215(6.312) | Loss -22.236(-20.440) | NFE Forward 50(53.0) | NFE Backward 63(63.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 240 | Time 6.184(6.299) | Loss -23.326(-21.392) | NFE Forward 50(52.8) | NFE Backward 63(63.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 250 | Time 6.739(6.360) | Loss -23.431(-22.344) | NFE Forward 62(53.5) | NFE Backward 63(63.5) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -24.967 | NFE 51 | NoImproveEpochs 02/16
Epoch 0 | Iter 260 | Time 6.246(6.995) | Loss -25.529(-23.280) | NFE Forward 50(53.2) | NFE Backward 63(63.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 270 | Time 6.438(6.860) | Loss -26.051(-24.109) | NFE Forward 56(55.9) | NFE Backward 63(63.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 280 | Time 6.656(6.769) | Loss -27.116(-24.931) | NFE Forward 62(57.6) | NFE Backward 63(63.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 290 | Time 6.619(6.720) | Loss -28.518(-25.934) | NFE Forward 62(59.0) | NFE Backward 63(63.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 300 | Time 6.629(6.782) | Loss -26.513(-26.711) | NFE Forward 62(60.0) | NFE Backward 63(64.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 310 | Time 7.062(6.850) | Loss -28.876(-27.130) | NFE Forward 62(60.7) | NFE Backward 69(65.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 320 | Time 6.686(6.788) | Loss -29.513(-27.773) | NFE Forward 62(61.1) | NFE Backward 63(65.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 330 | Time 6.986(6.818) | Loss -31.186(-28.505) | NFE Forward 62(61.4) | NFE Backward 69(65.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 340 | Time 7.003(6.876) | Loss -30.261(-29.041) | NFE Forward 62(61.6) | NFE Backward 69(66.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 350 | Time 6.989(6.906) | Loss -30.842(-29.462) | NFE Forward 62(61.7) | NFE Backward 69(67.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 360 | Time 6.578(6.896) | Loss -31.793(-30.106) | NFE Forward 62(61.8) | NFE Backward 63(67.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 370 | Time 7.035(6.929) | Loss -33.320(-30.885) | NFE Forward 62(61.9) | NFE Backward 69(67.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 380 | Time 6.963(6.949) | Loss -33.203(-31.521) | NFE Forward 62(61.9) | NFE Backward 69(68.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 390 | Time 6.997(7.001) | Loss -31.975(-31.925) | NFE Forward 62(62.0) | NFE Backward 69(68.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 400 | Time 7.050(7.018) | Loss -32.617(-32.266) | NFE Forward 62(62.0) | NFE Backward 69(69.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 410 | Time 7.010(7.011) | Loss -33.487(-32.684) | NFE Forward 62(62.0) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 420 | Time 6.973(7.006) | Loss -34.678(-33.014) | NFE Forward 62(62.0) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 430 | Time 6.985(7.001) | Loss -34.977(-33.424) | NFE Forward 62(62.0) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 440 | Time 6.961(7.005) | Loss -34.070(-33.784) | NFE Forward 62(62.0) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 450 | Time 6.990(7.015) | Loss -34.858(-34.081) | NFE Forward 62(62.0) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 460 | Time 7.040(7.018) | Loss -35.970(-34.423) | NFE Forward 62(62.0) | NFE Backward 69(69.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 470 | Time 6.991(7.030) | Loss -35.828(-34.804) | NFE Forward 62(62.0) | NFE Backward 69(69.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 480 | Time 7.012(7.043) | Loss -35.264(-35.006) | NFE Forward 62(62.0) | NFE Backward 69(69.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 490 | Time 7.015(7.041) | Loss -35.351(-35.255) | NFE Forward 62(62.0) | NFE Backward 69(69.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 500 | Time 7.047(7.068) | Loss -35.497(-35.416) | NFE Forward 62(62.0) | NFE Backward 69(69.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 510 | Time 7.024(7.092) | Loss -35.548(-35.403) | NFE Forward 62(62.0) | NFE Backward 69(70.1) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -35.329 | NFE 62 | NoImproveEpochs 03/16
Epoch 0 | Iter 520 | Time 6.995(7.785) | Loss -36.167(-35.533) | NFE Forward 62(62.0) | NFE Backward 69(70.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 530 | Time 7.054(7.538) | Loss -36.283(-35.829) | NFE Forward 62(62.0) | NFE Backward 69(70.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 540 | Time 7.397(7.448) | Loss -36.154(-36.021) | NFE Forward 62(62.0) | NFE Backward 75(70.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 550 | Time 6.991(7.342) | Loss -36.639(-36.186) | NFE Forward 62(62.0) | NFE Backward 69(70.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 560 | Time 7.037(7.276) | Loss -36.656(-36.352) | NFE Forward 62(62.0) | NFE Backward 69(70.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 570 | Time 7.400(7.288) | Loss -36.482(-36.325) | NFE Forward 62(62.0) | NFE Backward 75(71.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 580 | Time 7.021(7.232) | Loss -36.420(-36.479) | NFE Forward 62(62.0) | NFE Backward 69(71.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 590 | Time 7.024(7.177) | Loss -35.942(-36.581) | NFE Forward 62(62.0) | NFE Backward 69(70.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 600 | Time 7.453(7.199) | Loss -36.162(-36.587) | NFE Forward 62(62.0) | NFE Backward 75(71.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 610 | Time 7.016(7.166) | Loss -37.504(-36.813) | NFE Forward 62(62.0) | NFE Backward 69(70.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 620 | Time 7.423(7.134) | Loss -36.496(-37.095) | NFE Forward 62(62.0) | NFE Backward 75(70.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 630 | Time 7.014(7.194) | Loss -37.743(-37.153) | NFE Forward 62(62.0) | NFE Backward 69(71.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 640 | Time 7.405(7.192) | Loss -37.872(-37.326) | NFE Forward 62(62.0) | NFE Backward 75(71.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 650 | Time 7.354(7.206) | Loss -37.162(-37.336) | NFE Forward 62(62.0) | NFE Backward 75(71.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 660 | Time 7.380(7.205) | Loss -36.765(-37.495) | NFE Forward 62(62.0) | NFE Backward 75(71.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 670 | Time 7.377(7.259) | Loss -38.350(-37.543) | NFE Forward 62(62.0) | NFE Backward 75(72.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 680 | Time 7.463(7.256) | Loss -37.470(-37.608) | NFE Forward 62(62.0) | NFE Backward 75(72.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 690 | Time 7.374(7.278) | Loss -37.450(-37.701) | NFE Forward 62(62.0) | NFE Backward 75(73.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 700 | Time 7.374(7.297) | Loss -38.274(-37.727) | NFE Forward 62(62.0) | NFE Backward 75(73.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 710 | Time 7.353(7.275) | Loss -38.044(-37.856) | NFE Forward 62(62.0) | NFE Backward 75(73.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 720 | Time 7.375(7.316) | Loss -37.747(-37.762) | NFE Forward 62(62.0) | NFE Backward 75(73.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 730 | Time 7.015(7.272) | Loss -38.595(-37.895) | NFE Forward 62(62.0) | NFE Backward 69(73.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 740 | Time 6.970(7.246) | Loss -38.906(-38.031) | NFE Forward 62(62.0) | NFE Backward 69(72.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 750 | Time 7.401(7.230) | Loss -37.484(-38.192) | NFE Forward 62(62.0) | NFE Backward 75(72.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 760 | Time 7.398(7.245) | Loss -38.974(-38.343) | NFE Forward 62(62.0) | NFE Backward 75(72.8) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -38.314 | NFE 62 | NoImproveEpochs 04/16
Epoch 0 | Iter 770 | Time 6.946(8.082) | Loss -38.401(-38.517) | NFE Forward 62(62.0) | NFE Backward 69(72.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 780 | Time 7.389(7.849) | Loss -38.805(-38.441) | NFE Forward 62(62.0) | NFE Backward 75(73.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 790 | Time 7.013(7.645) | Loss -39.159(-38.535) | NFE Forward 62(62.0) | NFE Backward 69(73.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 800 | Time 7.416(7.564) | Loss -39.419(-38.617) | NFE Forward 62(62.0) | NFE Backward 75(73.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 810 | Time 7.422(7.509) | Loss -38.441(-38.707) | NFE Forward 62(62.0) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 820 | Time 7.005(7.441) | Loss -39.445(-38.763) | NFE Forward 62(62.0) | NFE Backward 69(74.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 830 | Time 7.448(7.380) | Loss -39.782(-39.084) | NFE Forward 62(62.0) | NFE Backward 75(73.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 840 | Time 7.355(7.338) | Loss -38.417(-39.199) | NFE Forward 62(62.0) | NFE Backward 75(73.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 850 | Time 7.366(7.346) | Loss -38.127(-39.192) | NFE Forward 62(62.0) | NFE Backward 75(73.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 860 | Time 7.383(7.363) | Loss -39.538(-39.161) | NFE Forward 62(62.0) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 870 | Time 7.397(7.378) | Loss -38.604(-39.237) | NFE Forward 62(62.0) | NFE Backward 75(74.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 880 | Time 7.417(7.391) | Loss -39.087(-39.314) | NFE Forward 62(62.0) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 890 | Time 7.389(7.396) | Loss -38.855(-39.324) | NFE Forward 62(62.0) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 900 | Time 7.457(7.398) | Loss -39.958(-39.397) | NFE Forward 62(62.0) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 910 | Time 7.379(7.392) | Loss -39.504(-39.326) | NFE Forward 62(61.8) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 920 | Time 7.417(7.397) | Loss -39.656(-39.369) | NFE Forward 62(61.9) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=0.01, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 930 | Time 7.403(7.371) | Loss -39.898(-39.694) | NFE Forward 62(61.9) | NFE Backward 75(74.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 940 | Time 7.411(7.360) | Loss -40.026(-39.787) | NFE Forward 62(61.9) | NFE Backward 75(74.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 950 | Time 7.464(7.377) | Loss -40.212(-39.869) | NFE Forward 62(62.0) | NFE Backward 75(74.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 960 | Time 7.511(7.387) | Loss -40.031(-39.952) | NFE Forward 62(62.0) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 970 | Time 7.379(7.379) | Loss -39.431(-39.981) | NFE Forward 62(62.0) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 980 | Time 7.383(7.390) | Loss -39.189(-39.925) | NFE Forward 62(62.0) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 990 | Time 7.001(7.380) | Loss -39.903(-40.005) | NFE Forward 62(62.0) | NFE Backward 69(74.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1000 | Time 7.429(7.390) | Loss -39.882(-39.991) | NFE Forward 62(62.0) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1010 | Time 7.415(7.372) | Loss -41.058(-40.224) | NFE Forward 62(62.0) | NFE Backward 75(74.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1020 | Time 7.402(7.330) | Loss -40.274(-40.487) | NFE Forward 62(62.0) | NFE Backward 75(73.8) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -39.711 | NFE 62 | NoImproveEpochs 05/16
Epoch 0 | Iter 1030 | Time 7.385(8.084) | Loss -40.734(-40.515) | NFE Forward 62(62.0) | NFE Backward 75(74.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1040 | Time 7.420(7.857) | Loss -40.829(-40.599) | NFE Forward 62(62.0) | NFE Backward 75(74.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1050 | Time 7.432(7.709) | Loss -41.259(-40.682) | NFE Forward 62(62.0) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1060 | Time 7.455(7.612) | Loss -40.087(-40.667) | NFE Forward 62(62.0) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1070 | Time 7.370(7.539) | Loss -41.485(-40.793) | NFE Forward 62(62.0) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1080 | Time 7.381(7.495) | Loss -41.484(-40.831) | NFE Forward 62(62.0) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1090 | Time 7.421(7.470) | Loss -40.927(-40.973) | NFE Forward 62(62.0) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1100 | Time 7.367(7.443) | Loss -41.624(-40.969) | NFE Forward 62(62.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1110 | Time 7.416(7.431) | Loss -41.141(-40.924) | NFE Forward 62(62.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1120 | Time 7.460(7.429) | Loss -40.551(-41.015) | NFE Forward 62(62.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1130 | Time 7.377(7.437) | Loss -41.434(-41.125) | NFE Forward 62(62.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1140 | Time 7.387(7.429) | Loss -41.923(-41.113) | NFE Forward 62(62.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1150 | Time 7.390(7.417) | Loss -41.473(-41.262) | NFE Forward 62(62.1) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1160 | Time 7.429(7.440) | Loss -40.726(-41.170) | NFE Forward 62(62.7) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1170 | Time 7.503(7.437) | Loss -39.979(-41.100) | NFE Forward 62(62.6) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1180 | Time 7.402(7.425) | Loss -42.451(-41.380) | NFE Forward 62(62.4) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=0.01, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 6.592(6.592) | Loss 37.451(37.451) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000) | JFrobint: 0.00096351
Epoch 0 | Iter 1190 | Time 7.386(7.419) | Loss -41.306(-41.505) | NFE Forward 62(62.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1200 | Time 7.628(7.451) | Loss -41.188(-41.439) | NFE Forward 68(63.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1210 | Time 7.377(7.441) | Loss -41.727(-41.345) | NFE Forward 62(63.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1220 | Time 7.393(7.435) | Loss -41.222(-41.215) | NFE Forward 62(62.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1230 | Time 7.373(7.421) | Loss -41.786(-41.355) | NFE Forward 62(62.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1240 | Time 7.403(7.416) | Loss -42.332(-41.608) | NFE Forward 62(62.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=0.01, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 6.704(6.704) | Loss 37.833(37.833) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000) | JFrobint: 0.00114287
Epoch 0 | Iter 1250 | Time 7.360(7.399) | Loss -42.255(-41.684) | NFE Forward 62(62.3) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1260 | Time 7.367(7.408) | Loss -41.264(-41.609) | NFE Forward 62(62.4) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=0.01, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=1024, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1024, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 6.531(6.531) | Loss 37.552(37.552) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000) | JFrobint: 0.00106994
[VAL] Epoch 0 | Val Loss 37.125 | NFE 20 | NoImproveEpochs 01/16
Epoch 0 | Iter 1270 | Time 7.369(7.408) | Loss -41.697(-41.682) | NFE Forward 62(62.2) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1280 | Time 7.373(7.409) | Loss -42.148(-41.791) | NFE Forward 62(62.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -41.696 | NFE 62 | NoImproveEpochs 06/16
Epoch 0 | Iter 1290 | Time 7.363(8.032) | Loss -42.094(-41.983) | NFE Forward 62(62.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1300 | Time 7.428(7.837) | Loss -42.687(-42.020) | NFE Forward 62(62.4) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1310 | Time 7.981(7.727) | Loss -42.298(-42.247) | NFE Forward 68(62.9) | NFE Backward 81(75.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1320 | Time 7.571(7.648) | Loss -43.141(-42.352) | NFE Forward 68(63.4) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1330 | Time 7.567(7.604) | Loss -41.965(-42.337) | NFE Forward 68(63.8) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1340 | Time 7.399(7.558) | Loss -43.838(-42.408) | NFE Forward 62(63.8) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1350 | Time 7.416(7.559) | Loss -42.903(-42.480) | NFE Forward 62(63.8) | NFE Backward 75(75.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1360 | Time 7.602(7.547) | Loss -42.255(-42.457) | NFE Forward 68(64.0) | NFE Backward 75(75.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1370 | Time 7.449(7.505) | Loss -42.338(-42.533) | NFE Forward 62(63.3) | NFE Backward 75(75.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1380 | Time 7.579(7.493) | Loss -42.345(-42.614) | NFE Forward 68(63.5) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=0.01, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 5.580(5.580) | Loss 37.610(37.610) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000) | JFrobint: 0.00104062
[VAL] Epoch 0 | Val Loss 37.104 | NFE 20 | NoImproveEpochs 01/16
Epoch 0 | Iter 1390 | Time 7.497(7.497) | Loss -42.509(-42.638) | NFE Forward 62(63.8) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 10 | Time 4.979(5.551) | Loss 35.532(37.063) | NFE Forward 20(20.0) | NFE Backward 27(22.7) | CNF Time 1.000(1.000) | JFrobint: 0.00288682
Epoch 0 | Iter 1400 | Time 7.584(7.517) | Loss -42.310(-42.650) | NFE Forward 68(64.4) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 6.474(5.557) | Loss 34.650(36.401) | NFE Forward 26(22.0) | NFE Backward 33(24.4) | CNF Time 1.000(1.000) | JFrobint: 0.00926626
Epoch 0 | Iter 30 | Time 6.108(5.760) | Loss 32.449(35.445) | NFE Forward 26(23.3) | NFE Backward 33(27.3) | CNF Time 1.000(1.000) | JFrobint: 0.03150891
Epoch 0 | Iter 1410 | Time 7.419(7.521) | Loss -43.230(-42.657) | NFE Forward 62(64.8) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1420 | Time 7.412(7.514) | Loss -42.893(-42.720) | NFE Forward 62(64.7) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1430 | Time 8.079(7.510) | Loss -42.250(-42.800) | NFE Forward 68(64.2) | NFE Backward 81(75.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1440 | Time 7.473(7.500) | Loss -43.835(-42.949) | NFE Forward 62(64.5) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1450 | Time 7.434(7.490) | Loss -43.691(-43.231) | NFE Forward 62(64.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1460 | Time 7.384(7.509) | Loss -43.995(-43.353) | NFE Forward 62(64.1) | NFE Backward 75(75.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1470 | Time 7.604(7.568) | Loss -43.040(-43.315) | NFE Forward 68(64.6) | NFE Backward 75(76.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1480 | Time 7.354(7.637) | Loss -43.587(-43.350) | NFE Forward 62(65.1) | NFE Backward 75(76.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1490 | Time 7.410(7.644) | Loss -42.444(-43.198) | NFE Forward 62(65.2) | NFE Backward 75(76.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1500 | Time 8.035(7.629) | Loss -43.871(-43.275) | NFE Forward 68(65.6) | NFE Backward 81(76.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1510 | Time 7.668(7.612) | Loss -43.762(-43.323) | NFE Forward 68(65.3) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1520 | Time 7.379(7.578) | Loss -43.685(-43.569) | NFE Forward 62(64.6) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1530 | Time 7.588(7.564) | Loss -44.101(-43.672) | NFE Forward 68(64.7) | NFE Backward 75(76.1) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -43.226 | NFE 66 | NoImproveEpochs 07/16
Epoch 0 | Iter 1540 | Time 7.383(8.431) | Loss -44.565(-43.776) | NFE Forward 62(65.0) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1550 | Time 7.662(8.179) | Loss -43.192(-43.780) | NFE Forward 68(65.8) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1560 | Time 7.180(7.958) | Loss -43.702(-43.846) | NFE Forward 56(64.9) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1570 | Time 7.203(7.797) | Loss -44.390(-43.754) | NFE Forward 56(64.3) | NFE Backward 75(76.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1580 | Time 7.177(7.667) | Loss -44.906(-44.099) | NFE Forward 56(63.2) | NFE Backward 75(75.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1590 | Time 7.392(7.658) | Loss -43.817(-44.035) | NFE Forward 62(64.0) | NFE Backward 75(76.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1600 | Time 8.010(7.710) | Loss -43.179(-43.859) | NFE Forward 68(65.4) | NFE Backward 81(76.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1610 | Time 7.161(7.715) | Loss -43.817(-43.657) | NFE Forward 56(65.8) | NFE Backward 75(77.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1620 | Time 7.198(7.639) | Loss -44.062(-43.752) | NFE Forward 56(65.3) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1630 | Time 7.562(7.594) | Loss -43.292(-43.667) | NFE Forward 68(64.6) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1640 | Time 7.540(7.566) | Loss -43.478(-43.862) | NFE Forward 68(64.5) | NFE Backward 75(76.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1650 | Time 8.013(7.578) | Loss -44.227(-43.952) | NFE Forward 68(64.7) | NFE Backward 81(76.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1660 | Time 7.581(7.628) | Loss -44.405(-44.189) | NFE Forward 68(65.4) | NFE Backward 75(76.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1670 | Time 7.166(7.650) | Loss -44.246(-44.307) | NFE Forward 56(65.0) | NFE Backward 75(77.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1680 | Time 7.150(7.687) | Loss -44.319(-44.312) | NFE Forward 56(65.5) | NFE Backward 75(77.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1690 | Time 7.210(7.668) | Loss -44.971(-44.248) | NFE Forward 56(64.9) | NFE Backward 75(77.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1700 | Time 7.606(7.605) | Loss -44.515(-44.475) | NFE Forward 68(63.5) | NFE Backward 75(77.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1710 | Time 7.639(7.534) | Loss -44.360(-44.628) | NFE Forward 68(62.6) | NFE Backward 75(76.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1720 | Time 7.979(7.547) | Loss -45.119(-44.641) | NFE Forward 68(62.9) | NFE Backward 81(76.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1730 | Time 8.002(7.614) | Loss -44.795(-44.606) | NFE Forward 68(63.8) | NFE Backward 81(77.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1740 | Time 7.161(7.540) | Loss -45.420(-44.696) | NFE Forward 56(62.9) | NFE Backward 75(76.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1750 | Time 7.174(7.463) | Loss -45.484(-44.827) | NFE Forward 56(61.3) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1760 | Time 7.196(7.410) | Loss -45.690(-45.014) | NFE Forward 56(59.6) | NFE Backward 75(76.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1770 | Time 7.616(7.427) | Loss -46.464(-45.146) | NFE Forward 56(58.8) | NFE Backward 81(77.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1780 | Time 7.615(7.486) | Loss -44.439(-45.142) | NFE Forward 56(58.3) | NFE Backward 81(78.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1790 | Time 8.039(7.551) | Loss -45.107(-45.105) | NFE Forward 68(59.5) | NFE Backward 81(78.5) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -44.582 | NFE 62 | NoImproveEpochs 08/16
Epoch 0 | Iter 1800 | Time 7.635(8.187) | Loss -45.910(-45.139) | NFE Forward 56(58.7) | NFE Backward 81(78.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1810 | Time 7.568(7.950) | Loss -46.504(-45.318) | NFE Forward 56(58.6) | NFE Backward 81(78.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1820 | Time 7.131(7.788) | Loss -44.794(-45.314) | NFE Forward 56(57.9) | NFE Backward 75(78.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1830 | Time 7.577(7.749) | Loss -45.806(-45.408) | NFE Forward 56(58.4) | NFE Backward 81(79.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1840 | Time 7.587(7.697) | Loss -43.985(-45.371) | NFE Forward 68(58.9) | NFE Backward 75(79.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1850 | Time 7.197(7.595) | Loss -45.930(-45.145) | NFE Forward 56(59.1) | NFE Backward 75(78.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1860 | Time 7.997(7.612) | Loss -45.084(-45.125) | NFE Forward 68(60.4) | NFE Backward 81(78.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1870 | Time 7.206(7.538) | Loss -46.248(-45.185) | NFE Forward 56(60.1) | NFE Backward 75(77.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1880 | Time 7.192(7.471) | Loss -46.568(-45.352) | NFE Forward 56(59.1) | NFE Backward 75(77.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1890 | Time 7.591(7.459) | Loss -45.929(-45.569) | NFE Forward 56(58.1) | NFE Backward 81(77.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1900 | Time 7.595(7.510) | Loss -46.745(-45.640) | NFE Forward 56(57.8) | NFE Backward 81(78.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1910 | Time 7.623(7.499) | Loss -44.927(-45.585) | NFE Forward 56(57.5) | NFE Backward 81(78.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1920 | Time 7.239(7.493) | Loss -45.710(-45.748) | NFE Forward 56(57.0) | NFE Backward 75(78.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1930 | Time 7.576(7.486) | Loss -45.932(-45.862) | NFE Forward 56(56.7) | NFE Backward 81(78.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1940 | Time 7.588(7.500) | Loss -46.013(-45.965) | NFE Forward 56(57.2) | NFE Backward 81(78.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1950 | Time 7.582(7.502) | Loss -45.383(-46.019) | NFE Forward 56(57.0) | NFE Backward 81(79.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1960 | Time 8.007(7.570) | Loss -45.721(-45.916) | NFE Forward 68(57.9) | NFE Backward 81(79.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1970 | Time 7.819(7.613) | Loss -45.472(-45.793) | NFE Forward 62(58.6) | NFE Backward 81(79.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1980 | Time 7.607(7.577) | Loss -45.810(-46.015) | NFE Forward 56(57.9) | NFE Backward 81(79.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1990 | Time 7.188(7.550) | Loss -46.631(-46.237) | NFE Forward 56(57.3) | NFE Backward 75(79.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2000 | Time 7.609(7.555) | Loss -47.299(-46.249) | NFE Forward 56(56.8) | NFE Backward 81(79.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2010 | Time 7.623(7.575) | Loss -46.329(-46.358) | NFE Forward 56(57.0) | NFE Backward 81(80.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2020 | Time 7.809(7.601) | Loss -45.897(-46.435) | NFE Forward 62(57.0) | NFE Backward 81(80.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2030 | Time 7.599(7.634) | Loss -46.323(-46.356) | NFE Forward 56(57.5) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2040 | Time 7.615(7.599) | Loss -47.351(-46.303) | NFE Forward 56(58.0) | NFE Backward 81(79.9) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -45.701 | NFE 56 | NoImproveEpochs 09/16
Epoch 0 | Iter 2050 | Time 7.647(8.356) | Loss -47.094(-46.415) | NFE Forward 56(57.5) | NFE Backward 81(79.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2060 | Time 7.606(8.080) | Loss -47.302(-46.618) | NFE Forward 56(57.2) | NFE Backward 81(79.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2070 | Time 7.614(7.928) | Loss -46.230(-46.399) | NFE Forward 56(57.8) | NFE Backward 81(79.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2080 | Time 7.582(7.836) | Loss -47.385(-46.345) | NFE Forward 56(58.5) | NFE Backward 81(79.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2090 | Time 7.158(7.690) | Loss -47.358(-46.536) | NFE Forward 56(57.8) | NFE Backward 75(79.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2100 | Time 7.552(7.643) | Loss -46.553(-46.653) | NFE Forward 56(57.6) | NFE Backward 81(79.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2110 | Time 7.566(7.639) | Loss -45.330(-46.525) | NFE Forward 56(58.0) | NFE Backward 81(79.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2120 | Time 7.589(7.665) | Loss -47.313(-46.749) | NFE Forward 56(58.5) | NFE Backward 81(80.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2130 | Time 7.597(7.640) | Loss -46.839(-46.714) | NFE Forward 56(58.1) | NFE Backward 81(80.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2140 | Time 7.845(7.625) | Loss -47.047(-46.785) | NFE Forward 62(57.8) | NFE Backward 81(80.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2150 | Time 7.616(7.632) | Loss -46.731(-46.943) | NFE Forward 56(58.0) | NFE Backward 81(80.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2160 | Time 7.585(7.622) | Loss -47.010(-47.110) | NFE Forward 56(58.3) | NFE Backward 81(80.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2170 | Time 7.814(7.646) | Loss -46.926(-47.174) | NFE Forward 62(59.2) | NFE Backward 81(80.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2180 | Time 7.782(7.674) | Loss -47.790(-47.207) | NFE Forward 62(59.3) | NFE Backward 81(80.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2190 | Time 7.595(7.685) | Loss -46.860(-47.093) | NFE Forward 56(59.6) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2200 | Time 7.596(7.689) | Loss -47.480(-47.173) | NFE Forward 56(59.8) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2210 | Time 7.570(7.672) | Loss -47.501(-47.271) | NFE Forward 56(59.5) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2220 | Time 7.609(7.668) | Loss -47.703(-47.272) | NFE Forward 56(59.3) | NFE Backward 81(80.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2230 | Time 7.824(7.692) | Loss -47.151(-47.298) | NFE Forward 62(59.9) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2240 | Time 7.816(7.695) | Loss -48.321(-47.297) | NFE Forward 62(60.0) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2250 | Time 7.290(7.663) | Loss -47.184(-47.438) | NFE Forward 56(59.9) | NFE Backward 75(79.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2260 | Time 7.830(7.670) | Loss -47.702(-47.468) | NFE Forward 62(60.0) | NFE Backward 81(79.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2270 | Time 7.835(7.714) | Loss -47.482(-47.334) | NFE Forward 62(60.7) | NFE Backward 81(80.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2280 | Time 7.816(7.737) | Loss -47.875(-47.338) | NFE Forward 62(60.7) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2290 | Time 7.204(7.715) | Loss -47.385(-47.466) | NFE Forward 56(60.1) | NFE Backward 75(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2300 | Time 7.819(7.716) | Loss -48.539(-47.733) | NFE Forward 62(59.7) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -47.463 | NFE 62 | NoImproveEpochs 10/16
Epoch 0 | Iter 2310 | Time 7.595(8.465) | Loss -48.150(-47.917) | NFE Forward 56(59.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2320 | Time 7.801(8.234) | Loss -48.010(-47.752) | NFE Forward 62(60.2) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2330 | Time 7.794(8.075) | Loss -47.639(-47.805) | NFE Forward 62(60.4) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2340 | Time 7.779(7.960) | Loss -48.218(-47.737) | NFE Forward 62(60.6) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2350 | Time 7.814(7.900) | Loss -47.393(-47.712) | NFE Forward 62(60.8) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2360 | Time 7.851(7.828) | Loss -47.455(-47.789) | NFE Forward 62(60.6) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2370 | Time 7.628(7.799) | Loss -48.502(-47.892) | NFE Forward 56(60.5) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2380 | Time 7.771(7.796) | Loss -47.495(-47.883) | NFE Forward 62(60.8) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2390 | Time 7.593(7.790) | Loss -49.455(-47.974) | NFE Forward 56(61.0) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2400 | Time 7.801(7.764) | Loss -49.335(-48.175) | NFE Forward 62(60.7) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2410 | Time 7.837(7.775) | Loss -48.015(-48.264) | NFE Forward 62(61.0) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2420 | Time 7.831(7.776) | Loss -48.311(-48.277) | NFE Forward 62(60.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2430 | Time 7.794(7.788) | Loss -49.015(-48.279) | NFE Forward 62(61.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2440 | Time 7.797(7.789) | Loss -47.230(-48.243) | NFE Forward 62(61.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2450 | Time 7.432(7.786) | Loss -47.672(-48.312) | NFE Forward 62(61.5) | NFE Backward 75(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2460 | Time 7.801(7.766) | Loss -48.809(-48.240) | NFE Forward 62(61.7) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2470 | Time 7.871(7.749) | Loss -49.493(-48.327) | NFE Forward 62(61.6) | NFE Backward 81(80.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2480 | Time 7.786(7.767) | Loss -49.001(-48.572) | NFE Forward 62(61.6) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2490 | Time 7.830(7.777) | Loss -49.549(-48.737) | NFE Forward 62(61.5) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2500 | Time 7.803(7.786) | Loss -49.189(-48.583) | NFE Forward 62(61.7) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2510 | Time 7.842(7.798) | Loss -46.846(-48.392) | NFE Forward 62(61.8) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2520 | Time 7.812(7.802) | Loss -48.940(-48.504) | NFE Forward 62(61.9) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2530 | Time 7.806(7.812) | Loss -48.015(-48.457) | NFE Forward 62(61.9) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2540 | Time 7.834(7.815) | Loss -48.453(-48.537) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2550 | Time 7.852(7.818) | Loss -49.010(-48.714) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2560 | Time 7.839(7.814) | Loss -48.680(-48.721) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -48.069 | NFE 62 | NoImproveEpochs 11/16
Epoch 0 | Iter 2570 | Time 7.789(8.422) | Loss -48.000(-48.772) | NFE Forward 62(61.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2580 | Time 7.772(8.211) | Loss -49.127(-48.782) | NFE Forward 62(61.9) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2590 | Time 7.784(8.075) | Loss -49.430(-48.899) | NFE Forward 62(61.9) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2600 | Time 7.764(7.988) | Loss -48.895(-49.055) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2610 | Time 7.819(7.924) | Loss -50.400(-49.089) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2620 | Time 7.789(7.887) | Loss -49.802(-48.895) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2630 | Time 7.803(7.860) | Loss -49.784(-48.954) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2640 | Time 7.884(7.847) | Loss -49.414(-49.082) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2650 | Time 7.776(7.828) | Loss -48.459(-49.039) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2660 | Time 7.791(7.818) | Loss -50.113(-49.275) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2670 | Time 7.818(7.818) | Loss -48.614(-49.217) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2680 | Time 7.784(7.817) | Loss -49.805(-49.215) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2690 | Time 7.796(7.815) | Loss -48.518(-49.327) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2700 | Time 7.820(7.815) | Loss -48.886(-49.439) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2710 | Time 7.818(7.797) | Loss -49.679(-49.332) | NFE Forward 62(62.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2720 | Time 7.794(7.802) | Loss -49.662(-49.496) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2730 | Time 7.793(7.791) | Loss -49.181(-49.384) | NFE Forward 62(62.0) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2740 | Time 7.810(7.795) | Loss -50.233(-49.652) | NFE Forward 62(62.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2750 | Time 7.812(7.801) | Loss -49.616(-49.680) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2760 | Time 7.833(7.804) | Loss -49.676(-49.748) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2770 | Time 7.822(7.801) | Loss -50.013(-49.830) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2780 | Time 7.850(7.804) | Loss -49.379(-49.767) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2790 | Time 7.782(7.805) | Loss -50.568(-49.899) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2800 | Time 7.840(7.809) | Loss -50.592(-50.092) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2810 | Time 7.788(7.811) | Loss -50.240(-49.963) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -48.488 | NFE 62 | NoImproveEpochs 12/16
Epoch 0 | Iter 2820 | Time 7.819(8.600) | Loss -50.994(-49.925) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2830 | Time 7.804(8.326) | Loss -50.851(-49.995) | NFE Forward 62(62.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2840 | Time 7.774(8.145) | Loss -49.829(-49.950) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2850 | Time 7.794(8.031) | Loss -49.782(-49.897) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2860 | Time 7.812(7.954) | Loss -50.610(-50.128) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2870 | Time 7.806(7.901) | Loss -50.690(-50.263) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2880 | Time 7.802(7.871) | Loss -50.628(-50.400) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2890 | Time 7.784(7.844) | Loss -50.850(-50.454) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2900 | Time 7.800(7.829) | Loss -50.061(-50.383) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2910 | Time 7.811(7.823) | Loss -50.275(-50.460) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2920 | Time 7.794(7.816) | Loss -48.261(-50.254) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2930 | Time 7.779(7.814) | Loss -50.532(-50.037) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2940 | Time 7.873(7.811) | Loss -50.510(-49.955) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2950 | Time 7.819(7.808) | Loss -51.876(-50.165) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2960 | Time 7.817(7.804) | Loss -50.801(-50.298) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2970 | Time 7.813(7.802) | Loss -50.870(-50.419) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2980 | Time 7.804(7.808) | Loss -50.403(-50.409) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2990 | Time 7.801(7.805) | Loss -51.418(-50.542) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3000 | Time 7.888(7.806) | Loss -50.634(-50.604) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3010 | Time 7.777(7.802) | Loss -50.768(-50.591) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3020 | Time 7.817(7.804) | Loss -52.550(-50.804) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3030 | Time 7.809(7.804) | Loss -51.743(-50.924) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3040 | Time 7.787(7.802) | Loss -50.368(-50.902) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3050 | Time 7.765(7.802) | Loss -51.190(-50.998) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3060 | Time 7.797(7.803) | Loss -51.661(-51.221) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3070 | Time 7.782(7.803) | Loss -50.979(-51.106) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -49.108 | NFE 62 | NoImproveEpochs 13/16
Epoch 0 | Iter 3080 | Time 7.780(8.474) | Loss -50.351(-50.665) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3090 | Time 7.741(8.246) | Loss -51.290(-50.720) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3100 | Time 7.849(8.098) | Loss -51.626(-50.893) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3110 | Time 7.820(8.002) | Loss -50.732(-51.023) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3120 | Time 7.842(7.939) | Loss -49.354(-50.993) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3130 | Time 7.773(7.897) | Loss -50.970(-50.843) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3140 | Time 7.831(7.865) | Loss -50.637(-51.023) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3150 | Time 7.821(7.851) | Loss -50.657(-51.082) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3160 | Time 7.777(7.835) | Loss -51.929(-51.319) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3170 | Time 7.852(7.830) | Loss -52.156(-51.432) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 0 | Time 8.024(7.843) | Loss -51.240(-51.369) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -50.789 | NFE 62 | NoImproveEpochs 14/16
Epoch 1 | Iter 10 | Time 7.778(8.455) | Loss -51.439(-51.439) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 20 | Time 7.775(8.238) | Loss -52.142(-51.477) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 30 | Time 7.766(8.093) | Loss -52.844(-51.545) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 40 | Time 7.768(7.996) | Loss -50.569(-51.557) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 50 | Time 7.792(7.934) | Loss -52.549(-51.623) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 60 | Time 7.820(7.891) | Loss -51.891(-51.543) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 70 | Time 7.834(7.864) | Loss -49.955(-51.551) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 80 | Time 7.808(7.848) | Loss -51.148(-51.485) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 90 | Time 7.796(7.834) | Loss -51.417(-51.552) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 100 | Time 7.876(7.830) | Loss -51.503(-51.193) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 110 | Time 7.814(7.827) | Loss -53.132(-51.384) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 120 | Time 7.851(7.818) | Loss -51.531(-51.447) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 130 | Time 7.855(7.812) | Loss -52.676(-51.482) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 140 | Time 7.860(7.817) | Loss -53.528(-51.693) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 150 | Time 7.780(7.812) | Loss -52.486(-51.826) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 160 | Time 7.761(7.812) | Loss -52.324(-51.861) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 170 | Time 7.755(7.809) | Loss -52.193(-51.840) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 180 | Time 7.836(7.807) | Loss -51.288(-51.500) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 190 | Time 7.841(7.804) | Loss -51.472(-51.658) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 200 | Time 7.824(7.805) | Loss -52.163(-51.895) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 210 | Time 7.819(7.803) | Loss -52.069(-51.963) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 220 | Time 7.903(7.808) | Loss -51.751(-52.127) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 230 | Time 7.802(7.806) | Loss -52.753(-52.046) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 240 | Time 7.836(7.813) | Loss -51.464(-52.058) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 250 | Time 7.814(7.829) | Loss -52.110(-51.840) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -49.807 | NFE 62 | NoImproveEpochs 15/16
Epoch 1 | Iter 260 | Time 7.815(8.617) | Loss -52.189(-51.840) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 270 | Time 7.867(8.343) | Loss -52.879(-52.093) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 280 | Time 7.791(8.160) | Loss -51.995(-52.098) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 290 | Time 7.787(8.041) | Loss -53.282(-52.272) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 300 | Time 7.827(7.967) | Loss -52.681(-52.374) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 310 | Time 7.827(7.919) | Loss -53.074(-52.645) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 320 | Time 7.795(7.880) | Loss -50.931(-52.379) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 330 | Time 7.791(7.864) | Loss -52.150(-51.988) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 340 | Time 7.829(7.842) | Loss -52.571(-51.939) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 350 | Time 7.804(7.814) | Loss -53.143(-52.063) | NFE Forward 62(62.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 360 | Time 7.805(7.818) | Loss -52.721(-52.323) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 370 | Time 7.858(7.823) | Loss -52.411(-52.593) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 380 | Time 7.810(7.820) | Loss -52.312(-52.631) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 390 | Time 7.794(7.822) | Loss -54.181(-52.823) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 400 | Time 7.811(7.817) | Loss -53.775(-53.006) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 410 | Time 7.388(7.795) | Loss -51.958(-52.741) | NFE Forward 62(62.0) | NFE Backward 75(80.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 420 | Time 7.817(7.801) | Loss -52.769(-52.848) | NFE Forward 62(62.0) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 430 | Time 7.804(7.806) | Loss -52.652(-52.913) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 440 | Time 7.802(7.804) | Loss -52.274(-52.826) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 450 | Time 7.836(7.814) | Loss -51.764(-52.708) | NFE Forward 62(62.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 460 | Time 7.842(7.813) | Loss -53.208(-52.960) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 470 | Time 7.770(7.807) | Loss -52.476(-52.947) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 480 | Time 7.813(7.809) | Loss -52.700(-52.797) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 490 | Time 7.857(7.806) | Loss -52.846(-52.834) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 500 | Time 7.824(7.813) | Loss -52.781(-52.949) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 510 | Time 7.847(7.814) | Loss -53.698(-53.159) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -51.234 | NFE 62 | NoImproveEpochs 16/16
Epoch 1 | Iter 520 | Time 7.765(8.485) | Loss -52.771(-53.246) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 530 | Time 7.817(8.257) | Loss -53.126(-53.116) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 540 | Time 7.772(8.103) | Loss -54.022(-53.316) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 550 | Time 7.810(8.006) | Loss -53.443(-53.413) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 560 | Time 7.765(7.937) | Loss -51.420(-53.241) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 570 | Time 7.793(7.892) | Loss -52.541(-53.255) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 580 | Time 7.850(7.871) | Loss -53.351(-53.268) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 590 | Time 7.770(7.851) | Loss -53.011(-53.328) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 600 | Time 7.787(7.834) | Loss -52.834(-53.439) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 610 | Time 7.813(7.826) | Loss -52.494(-53.401) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 620 | Time 7.817(7.822) | Loss -53.299(-53.407) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 630 | Time 7.767(7.815) | Loss -53.591(-53.558) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 640 | Time 7.779(7.815) | Loss -54.098(-53.380) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 650 | Time 7.762(7.808) | Loss -52.970(-53.248) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 660 | Time 7.810(7.808) | Loss -52.959(-53.379) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 670 | Time 7.811(7.810) | Loss -52.664(-53.439) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 680 | Time 7.800(7.808) | Loss -53.777(-53.273) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 690 | Time 7.902(7.812) | Loss -54.372(-53.498) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 700 | Time 7.779(7.810) | Loss -53.863(-53.681) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 710 | Time 7.798(7.808) | Loss -55.036(-53.984) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 720 | Time 7.830(7.808) | Loss -53.591(-53.942) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 730 | Time 7.844(7.810) | Loss -54.605(-53.909) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 740 | Time 7.823(7.811) | Loss -53.401(-53.768) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 750 | Time 7.791(7.811) | Loss -53.027(-53.614) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 760 | Time 7.735(7.803) | Loss -53.632(-53.774) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -52.142 | NFE 62 | NoImproveEpochs 17/16
Training has finished.
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 5.601(5.601) | Loss 37.442(37.442) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss 37.061 | NFE 20 | NoImproveEpochs 00/16
Epoch 0 | Iter 10 | Time 2.510(4.758) | Loss 35.568(36.963) | NFE Forward 20(20.0) | NFE Backward 27(22.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 2.746(4.059) | Loss 34.711(36.339) | NFE Forward 26(21.5) | NFE Backward 27(24.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 3.101(3.718) | Loss 32.472(35.400) | NFE Forward 26(23.0) | NFE Backward 33(26.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 3.308(3.463) | Loss 27.359(33.494) | NFE Forward 32(24.5) | NFE Backward 33(27.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 50 | Time 3.716(3.552) | Loss 20.955(30.223) | NFE Forward 32(27.0) | NFE Backward 39(31.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 60 | Time 4.788(3.829) | Loss 14.040(25.766) | NFE Forward 38(29.1) | NFE Backward 51(37.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 70 | Time 4.797(4.155) | Loss 7.859(20.600) | NFE Forward 38(32.1) | NFE Backward 51(41.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 80 | Time 5.345(4.522) | Loss 3.828(15.555) | NFE Forward 44(35.0) | NFE Backward 57(46.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 90 | Time 5.648(4.851) | Loss 0.928(10.959) | NFE Forward 50(39.3) | NFE Backward 57(50.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 100 | Time 5.613(5.099) | Loss -2.195(6.835) | NFE Forward 50(42.5) | NFE Backward 57(52.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 110 | Time 5.620(5.294) | Loss -3.349(3.391) | NFE Forward 50(45.0) | NFE Backward 57(54.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 120 | Time 5.645(5.421) | Loss -5.854(0.369) | NFE Forward 50(46.7) | NFE Backward 57(55.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 130 | Time 6.017(5.611) | Loss -8.649(-2.356) | NFE Forward 50(47.8) | NFE Backward 63(57.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 140 | Time 5.981(5.741) | Loss -10.106(-4.689) | NFE Forward 50(48.5) | NFE Backward 63(59.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 150 | Time 5.992(5.794) | Loss -11.948(-6.746) | NFE Forward 50(49.0) | NFE Backward 63(60.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 160 | Time 5.968(5.856) | Loss -14.077(-8.743) | NFE Forward 50(49.4) | NFE Backward 63(61.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 170 | Time 5.979(5.910) | Loss -14.152(-10.585) | NFE Forward 50(49.6) | NFE Backward 63(62.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 180 | Time 5.972(5.961) | Loss -15.913(-11.984) | NFE Forward 50(49.7) | NFE Backward 63(62.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 190 | Time 5.963(5.962) | Loss -16.229(-13.457) | NFE Forward 50(49.8) | NFE Backward 63(62.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 200 | Time 6.357(5.980) | Loss -16.776(-14.862) | NFE Forward 50(49.9) | NFE Backward 69(63.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 210 | Time 6.339(6.045) | Loss -16.974(-15.815) | NFE Forward 50(49.9) | NFE Backward 69(64.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 220 | Time 5.976(6.017) | Loss -19.959(-16.929) | NFE Forward 50(49.9) | NFE Backward 63(63.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 230 | Time 5.953(5.998) | Loss -20.391(-18.106) | NFE Forward 50(50.0) | NFE Backward 63(63.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 240 | Time 7.203(6.163) | Loss -20.615(-19.078) | NFE Forward 62(51.3) | NFE Backward 75(65.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 250 | Time 5.948(6.115) | Loss -22.907(-19.946) | NFE Forward 50(50.9) | NFE Backward 63(64.9) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -21.335 | NFE 50 | NoImproveEpochs 00/16
Epoch 0 | Iter 260 | Time 5.877(6.782) | Loss -23.168(-20.576) | NFE Forward 50(51.1) | NFE Backward 63(65.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 270 | Time 5.871(6.479) | Loss -23.287(-21.561) | NFE Forward 50(50.7) | NFE Backward 63(64.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 280 | Time 6.302(6.357) | Loss -24.820(-22.265) | NFE Forward 62(51.6) | NFE Backward 63(64.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 290 | Time 5.893(6.209) | Loss -23.987(-22.936) | NFE Forward 50(51.1) | NFE Backward 63(64.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 300 | Time 6.246(6.112) | Loss -25.181(-23.713) | NFE Forward 50(50.7) | NFE Backward 69(64.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 310 | Time 7.059(6.142) | Loss -25.581(-24.417) | NFE Forward 62(52.0) | NFE Backward 75(64.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 320 | Time 5.846(6.301) | Loss -26.123(-24.776) | NFE Forward 50(53.3) | NFE Backward 63(66.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 330 | Time 6.607(6.321) | Loss -26.245(-25.247) | NFE Forward 56(53.2) | NFE Backward 69(66.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 340 | Time 5.999(6.299) | Loss -26.853(-25.751) | NFE Forward 50(52.8) | NFE Backward 63(66.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 350 | Time 6.186(6.237) | Loss -28.576(-26.521) | NFE Forward 56(53.4) | NFE Backward 63(65.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 360 | Time 7.194(6.416) | Loss -28.803(-27.148) | NFE Forward 62(56.1) | NFE Backward 75(66.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 370 | Time 7.224(6.556) | Loss -28.201(-27.555) | NFE Forward 62(57.7) | NFE Backward 75(67.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 380 | Time 6.415(6.568) | Loss -30.078(-28.137) | NFE Forward 62(58.2) | NFE Backward 63(67.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 390 | Time 7.170(6.610) | Loss -30.002(-28.608) | NFE Forward 62(58.9) | NFE Backward 75(67.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 400 | Time 6.407(6.622) | Loss -30.869(-29.186) | NFE Forward 62(59.7) | NFE Backward 63(67.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 410 | Time 6.209(6.645) | Loss -31.002(-29.640) | NFE Forward 56(59.5) | NFE Backward 63(68.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 420 | Time 6.996(6.790) | Loss -30.661(-29.884) | NFE Forward 56(59.7) | NFE Backward 75(70.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 430 | Time 6.604(6.856) | Loss -30.098(-30.142) | NFE Forward 56(58.7) | NFE Backward 69(71.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 440 | Time 7.197(6.848) | Loss -31.106(-30.406) | NFE Forward 62(58.4) | NFE Backward 75(71.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 450 | Time 6.395(6.796) | Loss -32.464(-30.882) | NFE Forward 62(58.5) | NFE Backward 63(70.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 460 | Time 7.066(6.867) | Loss -32.117(-31.351) | NFE Forward 62(59.3) | NFE Backward 75(71.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 470 | Time 6.986(6.886) | Loss -32.791(-31.684) | NFE Forward 56(58.6) | NFE Backward 75(72.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 480 | Time 7.013(6.774) | Loss -33.362(-32.166) | NFE Forward 56(58.3) | NFE Backward 75(70.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 490 | Time 6.866(6.870) | Loss -33.577(-32.448) | NFE Forward 56(58.7) | NFE Backward 75(72.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 500 | Time 6.805(6.918) | Loss -34.194(-32.843) | NFE Forward 62(59.3) | NFE Backward 69(72.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 510 | Time 6.807(6.947) | Loss -35.229(-33.277) | NFE Forward 62(59.2) | NFE Backward 69(73.1) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -34.644 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 520 | Time 6.953(7.629) | Loss -34.428(-33.592) | NFE Forward 56(59.1) | NFE Backward 75(73.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 530 | Time 7.063(7.431) | Loss -35.600(-33.963) | NFE Forward 62(59.3) | NFE Backward 75(73.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 540 | Time 6.854(7.268) | Loss -34.695(-34.354) | NFE Forward 56(59.4) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 550 | Time 7.084(7.165) | Loss -34.642(-34.670) | NFE Forward 62(59.1) | NFE Backward 75(74.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 560 | Time 7.059(7.108) | Loss -35.836(-34.970) | NFE Forward 62(59.3) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 570 | Time 7.078(7.057) | Loss -35.861(-35.074) | NFE Forward 62(59.1) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 580 | Time 6.993(7.014) | Loss -35.118(-35.039) | NFE Forward 56(58.4) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 590 | Time 6.607(6.996) | Loss -36.568(-35.222) | NFE Forward 56(57.6) | NFE Backward 69(74.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 600 | Time 6.833(7.028) | Loss -37.412(-35.562) | NFE Forward 62(58.3) | NFE Backward 69(74.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 610 | Time 7.017(7.033) | Loss -35.786(-35.815) | NFE Forward 56(57.9) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 620 | Time 7.000(7.048) | Loss -36.074(-35.955) | NFE Forward 56(58.1) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 630 | Time 7.285(7.051) | Loss -36.508(-36.145) | NFE Forward 62(58.0) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 640 | Time 6.991(7.048) | Loss -35.489(-36.300) | NFE Forward 56(57.9) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 650 | Time 6.996(7.071) | Loss -37.177(-36.462) | NFE Forward 56(58.5) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 660 | Time 6.971(7.079) | Loss -38.075(-36.610) | NFE Forward 56(58.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 670 | Time 6.958(7.068) | Loss -37.596(-36.916) | NFE Forward 56(58.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 680 | Time 7.014(7.063) | Loss -37.664(-37.003) | NFE Forward 56(58.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 690 | Time 6.987(7.062) | Loss -36.543(-37.022) | NFE Forward 56(58.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 700 | Time 7.229(7.099) | Loss -37.404(-36.998) | NFE Forward 62(59.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 710 | Time 7.164(7.089) | Loss -37.157(-36.965) | NFE Forward 62(59.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 720 | Time 6.944(7.048) | Loss -37.530(-37.180) | NFE Forward 56(58.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 730 | Time 6.956(7.044) | Loss -38.254(-37.333) | NFE Forward 56(58.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 740 | Time 7.085(7.075) | Loss -37.064(-37.126) | NFE Forward 62(59.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 750 | Time 6.968(7.024) | Loss -36.781(-37.036) | NFE Forward 56(58.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 760 | Time 6.976(7.013) | Loss -37.527(-37.122) | NFE Forward 56(57.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -37.736 | NFE 58 | NoImproveEpochs 00/16
Epoch 0 | Iter 770 | Time 6.973(7.786) | Loss -38.462(-37.340) | NFE Forward 56(57.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 780 | Time 7.170(7.560) | Loss -38.468(-37.672) | NFE Forward 62(58.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 790 | Time 7.163(7.425) | Loss -37.910(-37.893) | NFE Forward 62(59.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 800 | Time 7.198(7.324) | Loss -39.273(-37.961) | NFE Forward 62(59.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 810 | Time 6.843(7.194) | Loss -38.627(-38.148) | NFE Forward 56(58.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 820 | Time 7.059(7.097) | Loss -37.859(-38.100) | NFE Forward 62(58.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 830 | Time 6.855(7.051) | Loss -37.329(-38.039) | NFE Forward 56(58.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 840 | Time 6.830(7.007) | Loss -38.143(-38.088) | NFE Forward 56(58.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 850 | Time 6.967(6.962) | Loss -39.009(-38.305) | NFE Forward 56(57.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 860 | Time 7.166(6.981) | Loss -38.329(-38.511) | NFE Forward 62(57.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 870 | Time 7.212(7.030) | Loss -38.726(-38.503) | NFE Forward 62(58.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 880 | Time 7.070(7.036) | Loss -37.210(-38.273) | NFE Forward 62(59.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 890 | Time 6.978(7.024) | Loss -39.639(-38.396) | NFE Forward 56(58.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 900 | Time 6.961(7.014) | Loss -38.910(-38.626) | NFE Forward 56(57.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 910 | Time 6.984(7.022) | Loss -39.283(-38.843) | NFE Forward 56(57.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 920 | Time 6.969(7.035) | Loss -39.918(-38.940) | NFE Forward 56(58.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 930 | Time 6.981(7.028) | Loss -39.183(-39.153) | NFE Forward 56(57.8) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 940 | Time 6.882(6.994) | Loss -39.667(-39.123) | NFE Forward 56(57.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 950 | Time 7.004(7.004) | Loss -39.335(-39.284) | NFE Forward 56(57.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 960 | Time 6.971(6.999) | Loss -39.345(-39.397) | NFE Forward 56(57.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 970 | Time 6.906(6.993) | Loss -39.804(-39.467) | NFE Forward 56(57.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 980 | Time 6.932(6.970) | Loss -40.279(-39.447) | NFE Forward 56(57.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 990 | Time 6.953(6.961) | Loss -40.147(-39.593) | NFE Forward 56(56.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1000 | Time 6.974(6.972) | Loss -40.314(-39.658) | NFE Forward 56(56.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1010 | Time 6.978(6.979) | Loss -39.477(-39.749) | NFE Forward 56(56.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1020 | Time 6.969(6.979) | Loss -40.003(-39.752) | NFE Forward 56(56.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -39.912 | NFE 57 | NoImproveEpochs 00/16
Epoch 0 | Iter 1030 | Time 7.186(7.640) | Loss -40.360(-39.834) | NFE Forward 62(56.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1040 | Time 6.990(7.422) | Loss -40.343(-39.929) | NFE Forward 56(56.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1050 | Time 7.179(7.290) | Loss -40.531(-39.863) | NFE Forward 62(57.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1060 | Time 7.216(7.208) | Loss -40.267(-39.754) | NFE Forward 62(57.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1070 | Time 6.991(7.126) | Loss -39.634(-39.892) | NFE Forward 56(56.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1080 | Time 6.987(7.093) | Loss -40.079(-40.152) | NFE Forward 56(56.8) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1090 | Time 7.023(7.077) | Loss -39.478(-40.328) | NFE Forward 56(56.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1100 | Time 6.995(7.057) | Loss -41.247(-40.473) | NFE Forward 56(56.8) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1110 | Time 6.990(7.039) | Loss -39.988(-40.587) | NFE Forward 56(56.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1120 | Time 6.991(7.034) | Loss -41.319(-40.539) | NFE Forward 56(56.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1130 | Time 7.011(7.026) | Loss -40.590(-40.665) | NFE Forward 56(56.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1140 | Time 7.021(7.037) | Loss -40.809(-40.573) | NFE Forward 56(56.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1150 | Time 6.996(7.038) | Loss -41.039(-40.669) | NFE Forward 56(57.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1160 | Time 7.003(7.027) | Loss -41.116(-40.837) | NFE Forward 56(56.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1170 | Time 6.994(7.025) | Loss -41.226(-40.972) | NFE Forward 56(56.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1180 | Time 6.994(7.015) | Loss -41.310(-41.045) | NFE Forward 56(56.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1190 | Time 7.003(7.005) | Loss -41.201(-41.036) | NFE Forward 56(56.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1200 | Time 6.962(7.001) | Loss -40.462(-41.027) | NFE Forward 56(56.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1210 | Time 6.989(6.993) | Loss -42.140(-41.113) | NFE Forward 56(56.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1220 | Time 6.985(7.004) | Loss -41.621(-41.226) | NFE Forward 56(56.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1230 | Time 6.990(6.997) | Loss -41.215(-41.397) | NFE Forward 56(56.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1240 | Time 7.390(7.011) | Loss -40.460(-41.365) | NFE Forward 68(56.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1250 | Time 6.993(7.016) | Loss -41.862(-41.462) | NFE Forward 56(56.8) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1260 | Time 6.995(7.024) | Loss -41.032(-41.600) | NFE Forward 56(57.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1270 | Time 6.996(7.014) | Loss -41.326(-41.623) | NFE Forward 56(56.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1280 | Time 6.968(7.004) | Loss -41.582(-41.677) | NFE Forward 56(56.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -41.651 | NFE 56 | NoImproveEpochs 00/16
Epoch 0 | Iter 1290 | Time 6.997(7.544) | Loss -40.372(-41.604) | NFE Forward 56(56.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1300 | Time 6.976(7.356) | Loss -42.962(-41.665) | NFE Forward 56(56.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1310 | Time 6.999(7.231) | Loss -42.665(-41.883) | NFE Forward 56(56.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1320 | Time 6.984(7.131) | Loss -41.879(-41.927) | NFE Forward 56(56.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1330 | Time 7.001(7.087) | Loss -42.125(-42.033) | NFE Forward 56(56.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1340 | Time 6.996(7.057) | Loss -42.066(-42.086) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1350 | Time 6.986(7.033) | Loss -43.236(-42.127) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1360 | Time 6.985(7.016) | Loss -42.794(-42.235) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1370 | Time 6.975(7.010) | Loss -41.417(-42.268) | NFE Forward 56(56.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1380 | Time 7.001(7.006) | Loss -41.829(-42.163) | NFE Forward 56(56.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1390 | Time 6.984(7.017) | Loss -43.039(-42.167) | NFE Forward 56(56.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1400 | Time 6.964(6.998) | Loss -42.867(-42.170) | NFE Forward 56(56.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1410 | Time 6.950(6.992) | Loss -43.725(-42.464) | NFE Forward 56(56.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1420 | Time 7.037(7.014) | Loss -43.520(-42.655) | NFE Forward 56(56.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1430 | Time 7.005(7.033) | Loss -42.303(-42.543) | NFE Forward 56(57.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1440 | Time 6.986(7.036) | Loss -42.654(-42.574) | NFE Forward 56(57.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1450 | Time 6.867(7.023) | Loss -42.239(-42.676) | NFE Forward 56(57.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1460 | Time 6.976(6.976) | Loss -42.601(-42.759) | NFE Forward 56(56.8) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1470 | Time 7.005(6.982) | Loss -42.995(-42.838) | NFE Forward 56(56.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1480 | Time 7.080(7.002) | Loss -44.003(-43.075) | NFE Forward 62(57.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1490 | Time 7.095(7.009) | Loss -43.259(-43.214) | NFE Forward 62(58.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1500 | Time 6.930(7.010) | Loss -43.818(-43.363) | NFE Forward 56(58.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1510 | Time 7.508(7.044) | Loss -43.335(-43.409) | NFE Forward 62(59.1) | NFE Backward 81(75.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1520 | Time 7.185(7.070) | Loss -43.097(-43.314) | NFE Forward 62(59.8) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1530 | Time 7.144(7.084) | Loss -44.096(-43.410) | NFE Forward 62(59.9) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -43.401 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 1540 | Time 7.228(7.890) | Loss -43.935(-43.587) | NFE Forward 62(60.4) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1550 | Time 7.618(7.663) | Loss -44.385(-43.539) | NFE Forward 62(60.6) | NFE Backward 81(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1560 | Time 7.190(7.513) | Loss -42.054(-43.485) | NFE Forward 62(60.9) | NFE Backward 75(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1570 | Time 6.995(7.400) | Loss -43.238(-43.368) | NFE Forward 56(61.0) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1580 | Time 7.179(7.318) | Loss -43.864(-43.591) | NFE Forward 62(60.9) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1590 | Time 7.203(7.289) | Loss -42.392(-43.536) | NFE Forward 62(61.1) | NFE Backward 75(75.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1600 | Time 7.203(7.259) | Loss -43.512(-43.439) | NFE Forward 62(61.4) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1610 | Time 7.155(7.224) | Loss -43.953(-43.394) | NFE Forward 62(61.4) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1620 | Time 7.206(7.204) | Loss -41.815(-43.126) | NFE Forward 62(61.4) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1630 | Time 7.189(7.190) | Loss -43.231(-43.232) | NFE Forward 62(61.4) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1640 | Time 7.141(7.147) | Loss -44.674(-43.591) | NFE Forward 62(61.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1650 | Time 7.106(7.138) | Loss -45.000(-43.928) | NFE Forward 62(61.1) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1660 | Time 7.208(7.160) | Loss -43.930(-44.177) | NFE Forward 62(61.4) | NFE Backward 75(75.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1670 | Time 7.071(7.162) | Loss -44.268(-44.209) | NFE Forward 62(61.6) | NFE Backward 75(75.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1680 | Time 7.059(7.182) | Loss -43.572(-44.314) | NFE Forward 62(61.7) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1690 | Time 7.564(7.249) | Loss -44.218(-44.343) | NFE Forward 62(61.8) | NFE Backward 81(76.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1700 | Time 7.105(7.271) | Loss -43.374(-44.323) | NFE Forward 62(61.9) | NFE Backward 75(77.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1710 | Time 7.530(7.261) | Loss -44.646(-44.276) | NFE Forward 62(61.9) | NFE Backward 81(76.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1720 | Time 7.186(7.250) | Loss -44.071(-44.344) | NFE Forward 62(62.0) | NFE Backward 75(76.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1730 | Time 7.180(7.248) | Loss -44.581(-44.300) | NFE Forward 62(62.0) | NFE Backward 75(76.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1740 | Time 7.149(7.260) | Loss -43.983(-44.270) | NFE Forward 62(62.0) | NFE Backward 75(76.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1750 | Time 7.183(7.257) | Loss -45.627(-44.324) | NFE Forward 62(62.0) | NFE Backward 75(76.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1760 | Time 7.197(7.270) | Loss -44.309(-44.481) | NFE Forward 62(62.0) | NFE Backward 75(76.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1770 | Time 7.591(7.282) | Loss -45.602(-44.754) | NFE Forward 62(62.0) | NFE Backward 81(76.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1780 | Time 7.488(7.308) | Loss -45.338(-44.971) | NFE Forward 62(62.0) | NFE Backward 81(77.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1790 | Time 7.103(7.299) | Loss -44.567(-44.900) | NFE Forward 62(62.0) | NFE Backward 75(77.5) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -44.924 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 1800 | Time 7.132(7.985) | Loss -45.160(-45.040) | NFE Forward 62(62.0) | NFE Backward 75(77.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1810 | Time 7.572(7.774) | Loss -44.205(-45.006) | NFE Forward 62(62.0) | NFE Backward 81(77.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1820 | Time 7.185(7.633) | Loss -45.393(-44.998) | NFE Forward 62(62.0) | NFE Backward 75(77.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1830 | Time 7.162(7.525) | Loss -45.086(-45.083) | NFE Forward 62(62.0) | NFE Backward 75(77.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1840 | Time 7.596(7.492) | Loss -45.174(-45.220) | NFE Forward 62(62.0) | NFE Backward 81(78.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1850 | Time 7.503(7.476) | Loss -45.805(-45.171) | NFE Forward 62(62.0) | NFE Backward 81(78.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1860 | Time 7.570(7.436) | Loss -46.677(-45.384) | NFE Forward 62(62.0) | NFE Backward 81(78.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1870 | Time 7.582(7.409) | Loss -45.746(-45.437) | NFE Forward 62(62.0) | NFE Backward 81(78.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1880 | Time 7.578(7.428) | Loss -45.355(-45.409) | NFE Forward 62(62.0) | NFE Backward 81(78.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1890 | Time 7.178(7.435) | Loss -46.494(-45.641) | NFE Forward 62(62.0) | NFE Backward 75(78.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1900 | Time 7.590(7.432) | Loss -45.716(-45.638) | NFE Forward 62(62.0) | NFE Backward 81(78.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1910 | Time 7.200(7.417) | Loss -45.874(-45.584) | NFE Forward 62(62.0) | NFE Backward 75(78.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1920 | Time 7.595(7.429) | Loss -44.819(-45.614) | NFE Forward 62(62.0) | NFE Backward 81(78.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1930 | Time 7.485(7.461) | Loss -46.664(-45.577) | NFE Forward 62(62.0) | NFE Backward 81(79.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1940 | Time 7.510(7.440) | Loss -45.866(-45.557) | NFE Forward 62(62.0) | NFE Backward 81(79.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1950 | Time 7.164(7.419) | Loss -45.563(-45.652) | NFE Forward 62(62.0) | NFE Backward 75(79.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1960 | Time 7.601(7.461) | Loss -46.265(-45.628) | NFE Forward 62(62.0) | NFE Backward 81(79.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1970 | Time 7.055(7.447) | Loss -45.066(-45.698) | NFE Forward 62(62.0) | NFE Backward 75(79.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1980 | Time 7.059(7.387) | Loss -46.342(-45.773) | NFE Forward 62(62.0) | NFE Backward 75(78.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1990 | Time 7.635(7.412) | Loss -46.490(-45.828) | NFE Forward 62(62.0) | NFE Backward 81(79.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2000 | Time 7.202(7.412) | Loss -45.072(-45.796) | NFE Forward 62(62.0) | NFE Backward 75(78.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2010 | Time 7.624(7.456) | Loss -46.563(-45.883) | NFE Forward 62(62.0) | NFE Backward 81(79.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2020 | Time 7.610(7.426) | Loss -45.525(-45.838) | NFE Forward 62(62.0) | NFE Backward 81(78.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2030 | Time 7.597(7.408) | Loss -46.838(-46.017) | NFE Forward 62(62.0) | NFE Backward 81(78.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2040 | Time 7.185(7.418) | Loss -46.153(-46.157) | NFE Forward 62(62.0) | NFE Backward 75(78.3) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -45.719 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 2050 | Time 7.607(8.302) | Loss -46.627(-46.207) | NFE Forward 62(62.0) | NFE Backward 81(79.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2060 | Time 7.565(8.047) | Loss -47.549(-46.420) | NFE Forward 62(62.0) | NFE Backward 81(79.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2070 | Time 7.585(7.876) | Loss -45.867(-46.298) | NFE Forward 62(62.0) | NFE Backward 81(79.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2080 | Time 7.603(7.775) | Loss -46.474(-46.231) | NFE Forward 62(62.0) | NFE Backward 81(80.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2090 | Time 7.184(7.603) | Loss -45.543(-46.178) | NFE Forward 62(61.6) | NFE Backward 75(79.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2100 | Time 7.572(7.543) | Loss -47.501(-46.321) | NFE Forward 62(61.7) | NFE Backward 81(79.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2110 | Time 7.594(7.521) | Loss -47.199(-46.402) | NFE Forward 62(61.4) | NFE Backward 81(79.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2120 | Time 7.591(7.505) | Loss -46.627(-46.439) | NFE Forward 62(61.6) | NFE Backward 81(79.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2130 | Time 7.208(7.491) | Loss -47.345(-46.596) | NFE Forward 50(61.3) | NFE Backward 81(79.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2140 | Time 7.555(7.482) | Loss -47.943(-46.867) | NFE Forward 62(61.1) | NFE Backward 81(79.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2150 | Time 7.563(7.488) | Loss -46.860(-46.937) | NFE Forward 62(61.4) | NFE Backward 81(79.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2160 | Time 7.206(7.493) | Loss -45.649(-46.890) | NFE Forward 62(61.6) | NFE Backward 75(79.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2170 | Time 7.593(7.518) | Loss -46.453(-46.635) | NFE Forward 62(61.7) | NFE Backward 81(80.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2180 | Time 7.193(7.498) | Loss -46.403(-46.654) | NFE Forward 62(61.8) | NFE Backward 75(79.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2190 | Time 7.620(7.483) | Loss -47.877(-46.753) | NFE Forward 62(61.3) | NFE Backward 81(79.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2200 | Time 7.587(7.511) | Loss -47.637(-46.881) | NFE Forward 62(61.5) | NFE Backward 81(80.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2210 | Time 7.210(7.512) | Loss -47.149(-47.122) | NFE Forward 62(61.3) | NFE Backward 75(80.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2220 | Time 7.589(7.539) | Loss -47.547(-47.124) | NFE Forward 62(61.5) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2230 | Time 7.624(7.561) | Loss -48.898(-47.399) | NFE Forward 62(61.7) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2240 | Time 7.577(7.573) | Loss -47.178(-47.391) | NFE Forward 62(61.8) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2250 | Time 7.626(7.525) | Loss -47.973(-47.442) | NFE Forward 62(61.2) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2260 | Time 7.107(7.463) | Loss -47.030(-47.469) | NFE Forward 50(60.8) | NFE Backward 81(80.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2270 | Time 7.526(7.487) | Loss -48.310(-47.677) | NFE Forward 62(61.2) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2280 | Time 7.614(7.502) | Loss -48.783(-47.671) | NFE Forward 62(61.5) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2290 | Time 7.542(7.518) | Loss -47.031(-47.581) | NFE Forward 62(61.6) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2300 | Time 7.579(7.507) | Loss -48.185(-47.651) | NFE Forward 62(61.4) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -47.644 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 2310 | Time 7.385(8.237) | Loss -47.704(-47.756) | NFE Forward 56(60.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2320 | Time 7.594(8.023) | Loss -48.574(-47.883) | NFE Forward 62(61.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2330 | Time 7.525(7.858) | Loss -48.068(-48.032) | NFE Forward 62(61.5) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2340 | Time 7.288(7.726) | Loss -47.205(-47.919) | NFE Forward 56(61.2) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2350 | Time 7.502(7.655) | Loss -47.587(-47.829) | NFE Forward 62(61.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2360 | Time 7.717(7.631) | Loss -47.792(-47.799) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2370 | Time 7.606(7.602) | Loss -48.691(-48.013) | NFE Forward 62(61.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2380 | Time 7.569(7.599) | Loss -47.469(-48.135) | NFE Forward 62(61.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2390 | Time 7.482(7.569) | Loss -48.288(-48.145) | NFE Forward 62(61.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2400 | Time 7.467(7.539) | Loss -48.031(-48.244) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2410 | Time 7.488(7.519) | Loss -48.678(-48.219) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2420 | Time 7.487(7.490) | Loss -47.663(-48.074) | NFE Forward 62(61.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2430 | Time 7.596(7.503) | Loss -48.662(-48.302) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2440 | Time 7.563(7.512) | Loss -48.671(-48.449) | NFE Forward 62(61.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2450 | Time 7.567(7.532) | Loss -47.848(-48.366) | NFE Forward 62(61.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2460 | Time 7.583(7.528) | Loss -48.799(-48.444) | NFE Forward 62(61.5) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2470 | Time 7.584(7.530) | Loss -47.019(-48.358) | NFE Forward 62(61.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2480 | Time 7.485(7.508) | Loss -48.171(-48.367) | NFE Forward 62(61.1) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2490 | Time 7.489(7.495) | Loss -48.381(-48.342) | NFE Forward 62(61.2) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2500 | Time 7.527(7.501) | Loss -48.849(-48.399) | NFE Forward 62(61.5) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2510 | Time 7.457(7.513) | Loss -49.410(-48.546) | NFE Forward 62(61.4) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2520 | Time 7.463(7.502) | Loss -48.928(-48.691) | NFE Forward 62(61.6) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2530 | Time 7.473(7.490) | Loss -48.417(-48.815) | NFE Forward 62(61.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2540 | Time 7.626(7.522) | Loss -48.833(-48.888) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2550 | Time 7.619(7.553) | Loss -49.223(-49.087) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2560 | Time 7.501(7.565) | Loss -49.984(-49.174) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -47.809 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 2570 | Time 7.545(8.183) | Loss -48.682(-49.054) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2580 | Time 7.636(7.990) | Loss -48.922(-49.123) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2590 | Time 7.620(7.846) | Loss -48.901(-48.871) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2600 | Time 7.587(7.744) | Loss -50.546(-49.116) | NFE Forward 62(61.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2610 | Time 7.612(7.676) | Loss -50.150(-49.319) | NFE Forward 62(61.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 2.911(2.911) | Loss 37.774(37.774) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
REDUCING LEARNING RATE BY 0.001
[VAL] Epoch 0 | Val Loss 37.080 | NFE 20 | NoImproveEpochs 00/16
Epoch 0 | Iter 10 | Time 2.627(3.000) | Loss 35.546(37.164) | NFE Forward 20(20.0) | NFE Backward 27(22.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 2.863(2.929) | Loss 34.693(36.468) | NFE Forward 26(21.5) | NFE Backward 27(24.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 2.817(2.910) | Loss 32.687(35.538) | NFE Forward 26(23.0) | NFE Backward 27(25.3) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.103(3.103) | Loss 37.552(37.552) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
REDUCING LEARNING RATE BY 0.001
[VAL] Epoch 0 | Val Loss 37.031 | NFE 20 | NoImproveEpochs 00/16
Epoch 0 | Iter 10 | Time 2.863(3.202) | Loss 35.487(37.016) | NFE Forward 20(20.0) | NFE Backward 27(22.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 3.097(3.155) | Loss 34.605(36.355) | NFE Forward 26(21.7) | NFE Backward 27(24.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 3.086(3.169) | Loss 32.141(35.349) | NFE Forward 26(23.1) | NFE Backward 27(25.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 4.273(3.225) | Loss 26.970(33.327) | NFE Forward 32(24.6) | NFE Backward 39(26.7) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 2.903(2.903) | Loss 37.464(37.464) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 2.913(2.913) | Loss 37.341(37.341) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
REDUCING LEARNING RATE TO 0.001
[VAL] Epoch 0 | Val Loss 36.937 | NFE 20 | NoImproveEpochs 00/16
Epoch 0 | Iter 10 | Time 2.722(3.044) | Loss 35.616(36.885) | NFE Forward 20(20.0) | NFE Backward 27(22.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 2.934(2.984) | Loss 34.780(36.295) | NFE Forward 26(21.5) | NFE Backward 27(24.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 3.340(3.103) | Loss 32.476(35.389) | NFE Forward 26(23.0) | NFE Backward 33(27.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 4.055(3.185) | Loss 27.512(33.473) | NFE Forward 32(24.7) | NFE Backward 39(28.5) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 2.845(2.845) | Loss 37.223(37.223) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss 36.848 | NFE 20 | NoImproveEpochs 00/16
Epoch 0 | Iter 10 | Time 2.531(2.916) | Loss 35.521(36.773) | NFE Forward 20(20.0) | NFE Backward 27(22.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 2.763(2.824) | Loss 34.718(36.210) | NFE Forward 26(20.9) | NFE Backward 27(24.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 2.740(2.805) | Loss 32.617(35.360) | NFE Forward 26(22.6) | NFE Backward 27(25.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 2.757(2.748) | Loss 27.915(33.587) | NFE Forward 26(23.7) | NFE Backward 27(25.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 50 | Time 3.723(2.986) | Loss 21.870(30.502) | NFE Forward 32(26.2) | NFE Backward 39(28.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 60 | Time 4.601(3.284) | Loss 15.167(26.336) | NFE Forward 32(28.1) | NFE Backward 51(32.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 70 | Time 4.805(3.723) | Loss 8.609(21.302) | NFE Forward 38(30.9) | NFE Backward 51(37.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 80 | Time 5.429(4.253) | Loss 3.235(16.088) | NFE Forward 44(34.7) | NFE Backward 57(44.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 90 | Time 5.407(4.570) | Loss -0.812(11.096) | NFE Forward 44(36.1) | NFE Backward 57(48.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 100 | Time 5.625(4.898) | Loss -3.942(6.563) | NFE Forward 50(39.8) | NFE Backward 57(51.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 110 | Time 5.654(5.145) | Loss -7.008(2.465) | NFE Forward 50(43.2) | NFE Backward 57(53.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 120 | Time 6.050(5.387) | Loss -10.113(-1.376) | NFE Forward 50(45.5) | NFE Backward 63(55.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 130 | Time 6.063(5.608) | Loss -11.806(-4.565) | NFE Forward 50(47.0) | NFE Backward 63(58.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 140 | Time 6.039(5.755) | Loss -13.819(-7.324) | NFE Forward 50(48.0) | NFE Backward 63(59.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 150 | Time 6.011(5.838) | Loss -15.229(-9.840) | NFE Forward 50(48.7) | NFE Backward 63(60.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 160 | Time 5.991(5.888) | Loss -16.213(-12.002) | NFE Forward 50(49.1) | NFE Backward 63(61.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 170 | Time 5.992(5.922) | Loss -18.080(-13.861) | NFE Forward 50(49.4) | NFE Backward 63(62.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 180 | Time 5.984(5.956) | Loss -19.064(-15.406) | NFE Forward 50(50.0) | NFE Backward 63(62.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 190 | Time 5.903(5.963) | Loss -20.672(-16.905) | NFE Forward 50(50.0) | NFE Backward 63(62.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 200 | Time 5.969(5.941) | Loss -20.831(-18.190) | NFE Forward 50(50.0) | NFE Backward 63(62.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 210 | Time 5.983(5.952) | Loss -21.354(-19.114) | NFE Forward 50(50.0) | NFE Backward 63(62.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 220 | Time 5.896(5.951) | Loss -22.424(-20.180) | NFE Forward 50(50.0) | NFE Backward 63(62.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 230 | Time 6.414(6.007) | Loss -23.538(-21.143) | NFE Forward 62(51.4) | NFE Backward 63(62.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 240 | Time 5.960(6.012) | Loss -25.035(-22.153) | NFE Forward 50(51.3) | NFE Backward 63(62.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 250 | Time 6.387(5.999) | Loss -25.447(-22.930) | NFE Forward 62(51.4) | NFE Backward 63(63.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -24.412 | NFE 50 | NoImproveEpochs 00/16
Epoch 0 | Iter 260 | Time 5.948(6.681) | Loss -26.049(-23.577) | NFE Forward 50(52.4) | NFE Backward 63(63.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 270 | Time 6.315(6.466) | Loss -26.660(-24.454) | NFE Forward 62(52.9) | NFE Backward 63(63.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 280 | Time 7.001(6.521) | Loss -24.611(-24.663) | NFE Forward 56(55.0) | NFE Backward 75(64.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 290 | Time 5.965(6.355) | Loss -26.254(-25.205) | NFE Forward 50(54.0) | NFE Backward 63(64.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 300 | Time 5.968(6.324) | Loss -26.601(-25.617) | NFE Forward 50(54.0) | NFE Backward 63(64.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 310 | Time 6.415(6.238) | Loss -29.252(-26.404) | NFE Forward 62(53.3) | NFE Backward 63(64.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 320 | Time 6.394(6.282) | Loss -28.000(-27.172) | NFE Forward 62(55.0) | NFE Backward 63(64.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 330 | Time 6.399(6.361) | Loss -29.927(-27.725) | NFE Forward 62(56.7) | NFE Backward 63(64.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 340 | Time 6.792(6.462) | Loss -30.024(-28.321) | NFE Forward 62(58.5) | NFE Backward 69(65.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 350 | Time 6.791(6.566) | Loss -29.832(-28.775) | NFE Forward 62(59.7) | NFE Backward 69(66.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 360 | Time 6.801(6.590) | Loss -31.104(-29.380) | NFE Forward 62(59.1) | NFE Backward 69(67.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 370 | Time 6.796(6.637) | Loss -31.192(-30.028) | NFE Forward 62(59.9) | NFE Backward 69(67.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 380 | Time 6.817(6.690) | Loss -30.898(-30.527) | NFE Forward 62(60.6) | NFE Backward 69(68.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 390 | Time 6.665(6.717) | Loss -30.814(-30.800) | NFE Forward 62(61.1) | NFE Backward 69(68.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 400 | Time 6.662(6.691) | Loss -31.833(-31.184) | NFE Forward 62(60.8) | NFE Backward 69(68.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 410 | Time 6.811(6.727) | Loss -32.547(-31.590) | NFE Forward 62(61.2) | NFE Backward 69(68.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 420 | Time 6.791(6.749) | Loss -32.591(-31.830) | NFE Forward 62(61.5) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 430 | Time 6.833(6.769) | Loss -32.482(-32.238) | NFE Forward 62(61.6) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 440 | Time 6.804(6.782) | Loss -32.410(-32.504) | NFE Forward 62(61.8) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 450 | Time 6.755(6.784) | Loss -32.309(-32.857) | NFE Forward 62(61.8) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 460 | Time 6.816(6.773) | Loss -33.344(-33.021) | NFE Forward 62(61.9) | NFE Backward 69(69.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 470 | Time 6.775(6.775) | Loss -33.534(-33.226) | NFE Forward 62(61.9) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 480 | Time 6.758(6.768) | Loss -34.092(-33.471) | NFE Forward 62(62.0) | NFE Backward 69(69.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 490 | Time 7.171(6.784) | Loss -32.585(-33.555) | NFE Forward 62(62.0) | NFE Backward 75(69.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 500 | Time 6.776(6.793) | Loss -34.719(-33.696) | NFE Forward 62(62.0) | NFE Backward 69(69.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 510 | Time 6.791(6.774) | Loss -34.431(-33.914) | NFE Forward 62(62.0) | NFE Backward 69(69.3) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -34.069 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 520 | Time 6.800(7.438) | Loss -34.650(-34.117) | NFE Forward 62(62.0) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 530 | Time 6.791(7.222) | Loss -34.248(-34.284) | NFE Forward 62(62.0) | NFE Backward 69(69.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 540 | Time 7.188(7.088) | Loss -34.547(-34.454) | NFE Forward 62(62.0) | NFE Backward 75(69.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 550 | Time 6.767(6.983) | Loss -34.084(-34.512) | NFE Forward 62(62.0) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 560 | Time 6.805(6.919) | Loss -35.166(-34.630) | NFE Forward 62(62.0) | NFE Backward 69(69.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 570 | Time 6.823(6.852) | Loss -35.601(-34.799) | NFE Forward 62(62.0) | NFE Backward 69(69.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 580 | Time 7.161(6.853) | Loss -34.682(-34.915) | NFE Forward 62(62.0) | NFE Backward 75(69.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 590 | Time 6.780(6.873) | Loss -35.320(-35.001) | NFE Forward 62(62.0) | NFE Backward 69(70.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 600 | Time 6.796(6.907) | Loss -34.869(-34.888) | NFE Forward 62(62.0) | NFE Backward 69(70.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 610 | Time 6.760(6.871) | Loss -35.750(-35.104) | NFE Forward 62(62.0) | NFE Backward 69(70.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 620 | Time 7.172(6.879) | Loss -34.772(-35.101) | NFE Forward 62(62.0) | NFE Backward 75(70.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 630 | Time 6.793(6.911) | Loss -34.951(-35.167) | NFE Forward 62(62.0) | NFE Backward 69(71.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 640 | Time 6.779(6.870) | Loss -36.543(-35.567) | NFE Forward 62(62.0) | NFE Backward 69(70.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 650 | Time 6.701(6.840) | Loss -35.933(-35.858) | NFE Forward 62(62.0) | NFE Backward 69(70.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 660 | Time 6.811(6.840) | Loss -35.894(-35.980) | NFE Forward 62(62.0) | NFE Backward 69(70.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 670 | Time 7.182(6.925) | Loss -36.524(-35.971) | NFE Forward 62(62.0) | NFE Backward 75(71.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 680 | Time 6.779(6.889) | Loss -36.381(-36.072) | NFE Forward 62(62.0) | NFE Backward 69(70.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 690 | Time 6.671(6.872) | Loss -36.759(-36.381) | NFE Forward 62(62.0) | NFE Backward 69(70.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 700 | Time 7.159(6.883) | Loss -35.385(-36.521) | NFE Forward 62(62.0) | NFE Backward 75(70.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 710 | Time 7.083(6.890) | Loss -36.293(-36.650) | NFE Forward 62(62.0) | NFE Backward 75(70.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 720 | Time 6.775(6.931) | Loss -36.041(-36.564) | NFE Forward 62(62.0) | NFE Backward 69(71.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 730 | Time 7.164(6.947) | Loss -37.575(-36.795) | NFE Forward 62(62.0) | NFE Backward 75(71.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 740 | Time 6.759(6.933) | Loss -37.536(-36.799) | NFE Forward 62(62.0) | NFE Backward 69(71.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 750 | Time 6.664(6.875) | Loss -37.424(-37.014) | NFE Forward 62(62.0) | NFE Backward 69(70.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 760 | Time 7.171(6.870) | Loss -36.381(-37.219) | NFE Forward 62(61.8) | NFE Backward 75(70.9) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -37.536 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 770 | Time 7.217(7.755) | Loss -37.887(-37.289) | NFE Forward 62(61.9) | NFE Backward 75(71.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 780 | Time 7.217(7.461) | Loss -37.821(-37.428) | NFE Forward 62(61.9) | NFE Backward 75(71.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 790 | Time 7.227(7.306) | Loss -36.976(-37.474) | NFE Forward 62(61.7) | NFE Backward 75(71.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 800 | Time 7.085(7.190) | Loss -37.979(-37.538) | NFE Forward 62(61.8) | NFE Backward 75(71.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 810 | Time 7.171(7.121) | Loss -36.634(-37.572) | NFE Forward 62(61.9) | NFE Backward 75(71.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 820 | Time 6.801(7.059) | Loss -38.706(-37.698) | NFE Forward 62(61.9) | NFE Backward 69(71.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 830 | Time 6.830(6.969) | Loss -39.072(-38.143) | NFE Forward 62(61.9) | NFE Backward 69(70.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 840 | Time 7.186(6.977) | Loss -38.764(-38.307) | NFE Forward 62(62.0) | NFE Backward 75(71.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 850 | Time 7.187(7.018) | Loss -37.858(-38.273) | NFE Forward 62(62.0) | NFE Backward 75(72.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 860 | Time 7.189(7.013) | Loss -38.107(-38.291) | NFE Forward 62(62.0) | NFE Backward 75(72.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 870 | Time 7.185(7.051) | Loss -38.445(-38.392) | NFE Forward 62(62.0) | NFE Backward 75(72.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 880 | Time 7.180(7.084) | Loss -38.608(-38.606) | NFE Forward 62(62.0) | NFE Backward 75(73.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 890 | Time 7.228(7.083) | Loss -38.475(-38.606) | NFE Forward 62(62.0) | NFE Backward 75(73.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 900 | Time 7.190(7.111) | Loss -38.979(-38.728) | NFE Forward 62(62.0) | NFE Backward 75(74.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 910 | Time 7.173(7.096) | Loss -38.494(-38.863) | NFE Forward 62(62.0) | NFE Backward 75(73.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 920 | Time 7.093(7.110) | Loss -38.373(-38.786) | NFE Forward 62(62.0) | NFE Backward 75(74.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 930 | Time 7.203(7.096) | Loss -39.818(-38.946) | NFE Forward 62(62.0) | NFE Backward 75(74.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 940 | Time 6.681(7.047) | Loss -40.163(-39.156) | NFE Forward 62(62.0) | NFE Backward 69(73.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 950 | Time 7.150(7.066) | Loss -39.193(-39.210) | NFE Forward 62(62.0) | NFE Backward 75(73.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 960 | Time 7.234(7.107) | Loss -40.219(-39.268) | NFE Forward 62(62.0) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 970 | Time 7.078(7.108) | Loss -39.251(-39.414) | NFE Forward 62(62.0) | NFE Backward 75(74.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 980 | Time 6.683(7.090) | Loss -39.275(-39.452) | NFE Forward 62(62.0) | NFE Backward 69(74.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 990 | Time 6.832(7.073) | Loss -41.065(-39.604) | NFE Forward 62(62.0) | NFE Backward 69(73.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1000 | Time 7.179(7.091) | Loss -39.099(-39.599) | NFE Forward 62(62.0) | NFE Backward 75(73.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1010 | Time 7.100(7.112) | Loss -39.536(-39.516) | NFE Forward 62(62.0) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1020 | Time 7.220(7.145) | Loss -39.791(-39.604) | NFE Forward 62(62.0) | NFE Backward 75(74.4) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -39.016 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 1030 | Time 7.209(7.884) | Loss -39.282(-39.620) | NFE Forward 62(62.0) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1040 | Time 7.190(7.638) | Loss -40.097(-39.741) | NFE Forward 62(62.0) | NFE Backward 75(74.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1050 | Time 7.186(7.461) | Loss -39.803(-39.822) | NFE Forward 62(62.0) | NFE Backward 75(74.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1060 | Time 7.189(7.349) | Loss -39.119(-39.814) | NFE Forward 62(62.0) | NFE Backward 75(74.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1070 | Time 7.193(7.298) | Loss -41.133(-40.061) | NFE Forward 62(62.0) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1080 | Time 7.054(7.239) | Loss -40.897(-40.246) | NFE Forward 62(62.0) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1090 | Time 7.106(7.222) | Loss -39.558(-40.160) | NFE Forward 62(62.2) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1100 | Time 7.197(7.209) | Loss -39.683(-40.056) | NFE Forward 62(62.2) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1110 | Time 7.125(7.193) | Loss -41.880(-40.243) | NFE Forward 62(61.7) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1120 | Time 6.980(7.189) | Loss -39.747(-40.368) | NFE Forward 56(61.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1130 | Time 7.209(7.183) | Loss -41.109(-40.559) | NFE Forward 62(61.7) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1140 | Time 7.092(7.202) | Loss -38.706(-40.414) | NFE Forward 62(62.0) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1150 | Time 7.084(7.189) | Loss -40.500(-40.259) | NFE Forward 62(62.8) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1160 | Time 6.992(7.142) | Loss -40.626(-40.465) | NFE Forward 56(61.9) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1170 | Time 7.179(7.141) | Loss -41.596(-40.801) | NFE Forward 62(61.7) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1180 | Time 7.194(7.150) | Loss -41.614(-40.942) | NFE Forward 62(61.6) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1190 | Time 7.268(7.199) | Loss -40.237(-40.885) | NFE Forward 68(62.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1200 | Time 7.194(7.200) | Loss -40.630(-40.718) | NFE Forward 62(62.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1210 | Time 7.179(7.191) | Loss -41.245(-40.761) | NFE Forward 62(62.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1220 | Time 7.191(7.180) | Loss -41.478(-41.012) | NFE Forward 62(61.9) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1230 | Time 7.234(7.202) | Loss -40.206(-41.014) | NFE Forward 62(62.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1240 | Time 7.163(7.208) | Loss -41.464(-40.993) | NFE Forward 62(62.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1250 | Time 7.222(7.167) | Loss -41.816(-41.261) | NFE Forward 62(61.6) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1260 | Time 7.175(7.165) | Loss -42.378(-41.521) | NFE Forward 62(61.9) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1270 | Time 7.185(7.212) | Loss -41.672(-41.457) | NFE Forward 62(62.9) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1280 | Time 7.212(7.207) | Loss -41.930(-41.475) | NFE Forward 62(62.7) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -41.897 | NFE 60 | NoImproveEpochs 00/16
Epoch 0 | Iter 1290 | Time 6.986(7.791) | Loss -42.086(-41.647) | NFE Forward 56(62.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1300 | Time 6.980(7.605) | Loss -42.371(-41.808) | NFE Forward 56(62.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1310 | Time 7.231(7.486) | Loss -41.135(-41.876) | NFE Forward 62(62.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1320 | Time 7.380(7.439) | Loss -42.020(-41.925) | NFE Forward 56(63.0) | NFE Backward 81(75.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1330 | Time 7.223(7.396) | Loss -41.595(-41.939) | NFE Forward 62(63.7) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1340 | Time 7.403(7.417) | Loss -41.789(-41.977) | NFE Forward 68(64.3) | NFE Backward 75(75.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1350 | Time 7.379(7.392) | Loss -41.617(-42.025) | NFE Forward 68(64.6) | NFE Backward 75(75.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1360 | Time 7.435(7.375) | Loss -41.558(-42.047) | NFE Forward 68(64.8) | NFE Backward 75(75.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1370 | Time 7.018(7.338) | Loss -41.350(-41.988) | NFE Forward 56(64.5) | NFE Backward 75(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1380 | Time 7.407(7.338) | Loss -42.137(-42.099) | NFE Forward 68(64.5) | NFE Backward 75(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1390 | Time 7.191(7.344) | Loss -42.320(-42.207) | NFE Forward 62(64.7) | NFE Backward 75(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1400 | Time 7.438(7.331) | Loss -42.032(-42.256) | NFE Forward 68(64.6) | NFE Backward 75(75.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1410 | Time 7.842(7.304) | Loss -42.235(-42.118) | NFE Forward 68(64.6) | NFE Backward 81(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1420 | Time 7.208(7.321) | Loss -43.114(-42.193) | NFE Forward 62(64.7) | NFE Backward 75(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1430 | Time 7.830(7.303) | Loss -43.269(-42.338) | NFE Forward 68(63.8) | NFE Backward 81(75.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1440 | Time 7.835(7.320) | Loss -42.724(-42.326) | NFE Forward 68(64.4) | NFE Backward 81(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1450 | Time 7.228(7.359) | Loss -43.876(-42.412) | NFE Forward 62(65.4) | NFE Backward 75(75.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1460 | Time 7.188(7.295) | Loss -43.678(-42.726) | NFE Forward 62(63.9) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1470 | Time 7.401(7.277) | Loss -43.462(-42.862) | NFE Forward 68(63.9) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1480 | Time 7.005(7.272) | Loss -43.459(-43.083) | NFE Forward 56(63.1) | NFE Backward 75(75.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1490 | Time 7.376(7.360) | Loss -42.362(-43.181) | NFE Forward 68(64.2) | NFE Backward 75(76.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1500 | Time 7.371(7.431) | Loss -42.209(-43.170) | NFE Forward 68(65.1) | NFE Backward 75(77.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1510 | Time 7.806(7.417) | Loss -43.542(-43.214) | NFE Forward 68(64.8) | NFE Backward 81(77.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1520 | Time 7.798(7.455) | Loss -43.171(-43.332) | NFE Forward 68(65.1) | NFE Backward 81(77.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1530 | Time 7.802(7.463) | Loss -41.854(-43.168) | NFE Forward 68(65.3) | NFE Backward 81(77.4) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -42.503 | NFE 68 | NoImproveEpochs 00/16
Epoch 0 | Iter 1540 | Time 6.956(8.340) | Loss -42.984(-43.085) | NFE Forward 56(65.7) | NFE Backward 75(77.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1550 | Time 6.952(7.958) | Loss -43.950(-43.312) | NFE Forward 56(64.2) | NFE Backward 75(76.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1560 | Time 7.394(7.686) | Loss -43.144(-43.405) | NFE Forward 68(63.2) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1570 | Time 7.401(7.592) | Loss -44.545(-43.470) | NFE Forward 68(63.2) | NFE Backward 75(76.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1580 | Time 7.391(7.546) | Loss -43.672(-43.491) | NFE Forward 68(63.6) | NFE Backward 75(77.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1590 | Time 6.971(7.485) | Loss -42.783(-43.358) | NFE Forward 56(63.4) | NFE Backward 75(77.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1600 | Time 7.425(7.442) | Loss -43.356(-43.467) | NFE Forward 56(63.2) | NFE Backward 81(76.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1610 | Time 6.968(7.359) | Loss -43.325(-43.564) | NFE Forward 56(62.5) | NFE Backward 75(76.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1620 | Time 7.388(7.389) | Loss -41.588(-43.529) | NFE Forward 68(63.4) | NFE Backward 75(76.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1630 | Time 6.868(7.424) | Loss -44.480(-43.557) | NFE Forward 56(64.5) | NFE Backward 75(77.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1640 | Time 6.976(7.296) | Loss -44.164(-43.850) | NFE Forward 56(62.2) | NFE Backward 75(76.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1650 | Time 7.803(7.321) | Loss -43.742(-43.990) | NFE Forward 68(62.2) | NFE Backward 81(76.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1660 | Time 7.825(7.425) | Loss -44.119(-44.087) | NFE Forward 68(63.5) | NFE Backward 81(77.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1670 | Time 7.796(7.514) | Loss -43.949(-43.952) | NFE Forward 68(64.3) | NFE Backward 81(78.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1680 | Time 7.381(7.536) | Loss -44.767(-44.018) | NFE Forward 56(63.9) | NFE Backward 81(79.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1690 | Time 6.988(7.460) | Loss -44.772(-44.253) | NFE Forward 56(63.3) | NFE Backward 75(78.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1700 | Time 7.789(7.523) | Loss -43.380(-44.131) | NFE Forward 68(64.4) | NFE Backward 81(78.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1710 | Time 7.784(7.554) | Loss -43.323(-44.111) | NFE Forward 68(65.1) | NFE Backward 81(78.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1720 | Time 7.796(7.576) | Loss -44.616(-44.188) | NFE Forward 68(65.4) | NFE Backward 81(78.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1730 | Time 6.970(7.441) | Loss -44.392(-44.372) | NFE Forward 56(63.1) | NFE Backward 75(78.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1740 | Time 7.827(7.536) | Loss -44.401(-44.342) | NFE Forward 68(63.9) | NFE Backward 81(79.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1750 | Time 7.392(7.524) | Loss -44.126(-44.251) | NFE Forward 68(63.6) | NFE Backward 75(79.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1760 | Time 7.767(7.480) | Loss -44.785(-44.356) | NFE Forward 68(63.1) | NFE Backward 81(78.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1770 | Time 7.791(7.463) | Loss -44.513(-44.408) | NFE Forward 68(62.2) | NFE Backward 81(78.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1780 | Time 7.026(7.387) | Loss -44.740(-44.554) | NFE Forward 56(60.6) | NFE Backward 75(78.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1790 | Time 7.384(7.443) | Loss -42.996(-44.410) | NFE Forward 56(60.7) | NFE Backward 81(79.4) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -42.888 | NFE 68 | NoImproveEpochs 00/16
Epoch 0 | Iter 1800 | Time 7.383(8.166) | Loss -44.637(-44.350) | NFE Forward 56(60.5) | NFE Backward 81(79.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1810 | Time 6.979(7.852) | Loss -45.671(-44.551) | NFE Forward 56(59.7) | NFE Backward 75(79.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1820 | Time 6.951(7.675) | Loss -44.745(-44.651) | NFE Forward 56(60.1) | NFE Backward 75(78.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1830 | Time 7.790(7.637) | Loss -44.344(-44.704) | NFE Forward 68(60.8) | NFE Backward 81(79.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1840 | Time 7.371(7.564) | Loss -44.939(-44.772) | NFE Forward 56(60.1) | NFE Backward 81(79.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1850 | Time 7.365(7.486) | Loss -45.559(-44.959) | NFE Forward 56(59.1) | NFE Backward 81(79.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1860 | Time 7.375(7.502) | Loss -44.491(-44.946) | NFE Forward 56(59.5) | NFE Backward 81(80.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1870 | Time 7.388(7.503) | Loss -45.894(-45.205) | NFE Forward 56(59.5) | NFE Backward 81(80.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1880 | Time 7.821(7.506) | Loss -45.584(-45.323) | NFE Forward 68(59.7) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1890 | Time 7.596(7.527) | Loss -44.424(-45.217) | NFE Forward 62(60.1) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1900 | Time 7.400(7.524) | Loss -45.695(-45.390) | NFE Forward 56(59.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1910 | Time 6.970(7.512) | Loss -46.571(-45.309) | NFE Forward 56(60.2) | NFE Backward 75(80.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1920 | Time 7.397(7.514) | Loss -46.210(-45.513) | NFE Forward 56(60.1) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1930 | Time 7.004(7.455) | Loss -45.647(-45.591) | NFE Forward 56(59.4) | NFE Backward 75(80.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1940 | Time 7.396(7.425) | Loss -47.168(-45.777) | NFE Forward 56(58.2) | NFE Backward 81(80.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1950 | Time 7.619(7.459) | Loss -45.761(-45.925) | NFE Forward 62(58.7) | NFE Backward 81(80.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1960 | Time 7.379(7.493) | Loss -45.828(-45.892) | NFE Forward 56(59.4) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1970 | Time 7.270(7.488) | Loss -46.323(-45.812) | NFE Forward 56(59.4) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1980 | Time 7.613(7.533) | Loss -45.820(-45.627) | NFE Forward 62(60.5) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1990 | Time 7.368(7.506) | Loss -46.245(-45.674) | NFE Forward 56(59.7) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2000 | Time 6.985(7.476) | Loss -45.434(-45.769) | NFE Forward 56(59.3) | NFE Backward 75(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2010 | Time 7.821(7.512) | Loss -45.381(-45.828) | NFE Forward 68(59.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2020 | Time 7.404(7.502) | Loss -45.930(-45.910) | NFE Forward 56(59.4) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2030 | Time 7.368(7.498) | Loss -47.555(-46.081) | NFE Forward 56(59.2) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2040 | Time 7.600(7.489) | Loss -46.224(-46.096) | NFE Forward 62(58.8) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -45.192 | NFE 56 | NoImproveEpochs 00/16
Epoch 0 | Iter 2050 | Time 7.811(8.296) | Loss -45.647(-46.162) | NFE Forward 68(59.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2060 | Time 7.617(8.035) | Loss -45.978(-46.100) | NFE Forward 62(59.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2070 | Time 7.811(7.896) | Loss -46.737(-46.073) | NFE Forward 68(60.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2080 | Time 7.588(7.771) | Loss -46.008(-46.172) | NFE Forward 62(60.5) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2090 | Time 7.791(7.704) | Loss -47.080(-46.295) | NFE Forward 68(60.6) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2100 | Time 7.614(7.648) | Loss -47.123(-46.466) | NFE Forward 62(60.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2110 | Time 7.493(7.610) | Loss -45.063(-46.475) | NFE Forward 62(60.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2120 | Time 7.585(7.603) | Loss -45.818(-46.286) | NFE Forward 62(60.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2130 | Time 7.388(7.587) | Loss -46.736(-46.357) | NFE Forward 56(60.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2140 | Time 7.357(7.577) | Loss -47.666(-46.508) | NFE Forward 56(61.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2150 | Time 7.404(7.548) | Loss -47.152(-46.730) | NFE Forward 56(60.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2160 | Time 7.615(7.529) | Loss -47.734(-46.903) | NFE Forward 62(59.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2170 | Time 7.595(7.534) | Loss -46.037(-46.827) | NFE Forward 62(59.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2180 | Time 7.609(7.557) | Loss -47.113(-46.749) | NFE Forward 62(60.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2190 | Time 7.442(7.540) | Loss -48.007(-47.060) | NFE Forward 56(60.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2200 | Time 7.591(7.535) | Loss -47.790(-47.202) | NFE Forward 62(60.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2210 | Time 7.591(7.559) | Loss -48.119(-47.106) | NFE Forward 62(60.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2220 | Time 7.572(7.564) | Loss -46.649(-47.122) | NFE Forward 62(60.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2230 | Time 7.620(7.545) | Loss -47.396(-47.274) | NFE Forward 62(60.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2240 | Time 7.602(7.567) | Loss -47.490(-47.260) | NFE Forward 62(61.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2250 | Time 7.568(7.562) | Loss -47.399(-47.368) | NFE Forward 62(61.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2260 | Time 7.386(7.544) | Loss -47.745(-47.451) | NFE Forward 56(60.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2270 | Time 7.598(7.564) | Loss -46.970(-47.482) | NFE Forward 62(61.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2280 | Time 7.771(7.579) | Loss -47.529(-47.327) | NFE Forward 68(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2290 | Time 7.574(7.596) | Loss -47.074(-47.264) | NFE Forward 62(62.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2300 | Time 7.571(7.593) | Loss -47.968(-47.465) | NFE Forward 62(62.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -47.484 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 2310 | Time 7.486(8.311) | Loss -47.440(-47.695) | NFE Forward 62(62.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2320 | Time 7.624(8.072) | Loss -48.278(-47.500) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2330 | Time 7.586(7.914) | Loss -46.893(-47.339) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2340 | Time 7.585(7.801) | Loss -47.627(-47.406) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2350 | Time 7.567(7.734) | Loss -47.758(-47.605) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2360 | Time 7.589(7.664) | Loss -47.788(-47.666) | NFE Forward 62(61.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2370 | Time 7.421(7.628) | Loss -48.180(-47.811) | NFE Forward 56(61.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2380 | Time 7.599(7.616) | Loss -46.775(-47.892) | NFE Forward 62(61.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2390 | Time 7.598(7.611) | Loss -47.708(-47.795) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2400 | Time 7.601(7.609) | Loss -49.291(-47.867) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2410 | Time 7.592(7.601) | Loss -46.688(-47.720) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2420 | Time 7.581(7.588) | Loss -49.053(-47.885) | NFE Forward 62(61.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2430 | Time 7.585(7.592) | Loss -49.373(-48.190) | NFE Forward 62(61.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2440 | Time 7.605(7.596) | Loss -48.813(-48.272) | NFE Forward 62(61.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2450 | Time 7.603(7.597) | Loss -48.564(-48.350) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2460 | Time 7.597(7.594) | Loss -49.669(-48.488) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2470 | Time 7.589(7.593) | Loss -48.181(-48.538) | NFE Forward 62(61.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2480 | Time 7.597(7.595) | Loss -48.265(-48.610) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2490 | Time 7.685(7.600) | Loss -47.721(-48.458) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2500 | Time 7.580(7.600) | Loss -47.978(-48.470) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2510 | Time 7.570(7.599) | Loss -49.336(-48.556) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2520 | Time 7.601(7.582) | Loss -48.922(-48.782) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2530 | Time 7.606(7.587) | Loss -49.616(-48.879) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2540 | Time 7.612(7.588) | Loss -49.646(-48.991) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2550 | Time 7.596(7.589) | Loss -48.493(-48.872) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2560 | Time 7.619(7.599) | Loss -48.155(-48.859) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -48.346 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 2570 | Time 7.598(8.224) | Loss -49.241(-49.080) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2580 | Time 7.640(8.011) | Loss -49.304(-48.988) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2590 | Time 7.617(7.881) | Loss -49.452(-49.131) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2600 | Time 7.589(7.784) | Loss -48.620(-49.131) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2610 | Time 7.580(7.720) | Loss -49.032(-49.049) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2620 | Time 7.604(7.680) | Loss -49.191(-48.876) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2630 | Time 7.551(7.643) | Loss -49.295(-48.925) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2640 | Time 7.571(7.615) | Loss -50.079(-49.082) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2650 | Time 7.603(7.610) | Loss -49.170(-49.177) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2660 | Time 7.609(7.601) | Loss -49.467(-49.389) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2670 | Time 7.587(7.601) | Loss -48.776(-49.140) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2680 | Time 7.534(7.600) | Loss -49.002(-49.209) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2690 | Time 7.614(7.599) | Loss -48.516(-49.319) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2700 | Time 7.605(7.590) | Loss -50.109(-49.276) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2710 | Time 7.590(7.596) | Loss -48.651(-49.139) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2720 | Time 7.628(7.602) | Loss -50.362(-49.471) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2730 | Time 7.612(7.602) | Loss -50.512(-49.670) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2740 | Time 7.615(7.604) | Loss -50.336(-49.788) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2750 | Time 7.588(7.603) | Loss -49.652(-49.713) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2760 | Time 7.605(7.604) | Loss -50.554(-49.754) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2770 | Time 7.626(7.598) | Loss -48.063(-49.637) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2780 | Time 7.619(7.598) | Loss -49.358(-49.595) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2790 | Time 7.599(7.600) | Loss -49.386(-49.726) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2800 | Time 7.638(7.604) | Loss -50.016(-49.891) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2810 | Time 7.604(7.602) | Loss -50.732(-49.916) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -48.852 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 2820 | Time 7.620(8.398) | Loss -51.129(-49.941) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2830 | Time 7.487(8.122) | Loss -50.659(-50.187) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2840 | Time 7.648(7.941) | Loss -48.826(-50.227) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2850 | Time 7.615(7.823) | Loss -49.050(-49.845) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2860 | Time 7.596(7.747) | Loss -49.299(-49.551) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2870 | Time 7.509(7.685) | Loss -50.040(-49.427) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2880 | Time 7.453(7.631) | Loss -50.030(-49.417) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2890 | Time 7.538(7.607) | Loss -51.242(-49.558) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2900 | Time 7.578(7.611) | Loss -51.439(-49.801) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2910 | Time 7.619(7.614) | Loss -49.805(-50.122) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2920 | Time 7.606(7.613) | Loss -51.063(-50.299) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2930 | Time 7.557(7.613) | Loss -49.309(-50.341) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2940 | Time 7.587(7.599) | Loss -50.771(-50.244) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2950 | Time 7.599(7.593) | Loss -50.243(-50.332) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2960 | Time 7.635(7.596) | Loss -50.188(-50.388) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2970 | Time 7.575(7.600) | Loss -50.504(-50.544) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2980 | Time 7.613(7.604) | Loss -51.255(-50.790) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 2990 | Time 7.592(7.605) | Loss -50.784(-50.651) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3000 | Time 7.591(7.605) | Loss -50.026(-50.510) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3010 | Time 7.576(7.592) | Loss -50.776(-50.595) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3020 | Time 7.601(7.594) | Loss -50.639(-50.698) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3030 | Time 7.587(7.593) | Loss -50.508(-50.630) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3040 | Time 7.581(7.593) | Loss -52.183(-50.695) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3050 | Time 7.602(7.592) | Loss -50.780(-50.690) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3060 | Time 7.600(7.595) | Loss -50.366(-50.804) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3070 | Time 7.591(7.595) | Loss -51.353(-50.933) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -50.796 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 3080 | Time 7.609(8.272) | Loss -50.648(-51.052) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3090 | Time 7.637(8.045) | Loss -51.497(-51.068) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3100 | Time 7.601(7.901) | Loss -49.944(-50.939) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3110 | Time 7.574(7.801) | Loss -52.114(-51.020) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3120 | Time 7.583(7.714) | Loss -48.876(-50.658) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3130 | Time 7.612(7.663) | Loss -50.623(-50.559) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3140 | Time 7.630(7.647) | Loss -51.923(-50.797) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3150 | Time 7.626(7.635) | Loss -49.250(-50.859) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3160 | Time 7.630(7.625) | Loss -50.596(-50.862) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3170 | Time 7.606(7.620) | Loss -51.569(-51.127) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3180 | Time 7.581(7.614) | Loss -51.630(-51.286) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3190 | Time 7.589(7.610) | Loss -50.628(-51.164) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3200 | Time 7.627(7.608) | Loss -50.462(-51.102) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3210 | Time 7.519(7.579) | Loss -51.690(-51.224) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3220 | Time 7.483(7.583) | Loss -52.401(-51.363) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3230 | Time 7.603(7.589) | Loss -50.912(-51.442) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3240 | Time 7.472(7.587) | Loss -51.992(-51.623) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3250 | Time 7.579(7.583) | Loss -52.425(-51.729) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3260 | Time 7.609(7.591) | Loss -50.475(-51.655) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3270 | Time 7.440(7.573) | Loss -50.699(-51.578) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3280 | Time 7.609(7.570) | Loss -51.072(-51.606) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3290 | Time 7.600(7.585) | Loss -52.785(-51.824) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3300 | Time 7.614(7.591) | Loss -50.991(-51.545) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3310 | Time 7.621(7.596) | Loss -52.653(-51.496) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3320 | Time 7.612(7.602) | Loss -51.179(-51.625) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -50.545 | NFE 62 | NoImproveEpochs 01/16
Epoch 0 | Iter 3330 | Time 7.664(8.476) | Loss -51.761(-51.639) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3340 | Time 7.574(8.178) | Loss -51.813(-51.734) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3350 | Time 7.592(7.982) | Loss -51.562(-51.792) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3360 | Time 7.568(7.848) | Loss -51.492(-51.814) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3370 | Time 7.531(7.751) | Loss -51.593(-51.818) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3380 | Time 7.582(7.688) | Loss -51.571(-51.760) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3390 | Time 7.639(7.650) | Loss -52.739(-51.873) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3400 | Time 7.572(7.631) | Loss -51.907(-51.987) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3410 | Time 7.625(7.613) | Loss -51.969(-52.022) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3420 | Time 7.598(7.609) | Loss -52.525(-52.119) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3430 | Time 7.618(7.595) | Loss -51.838(-52.314) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3440 | Time 7.585(7.591) | Loss -51.561(-52.082) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3450 | Time 7.559(7.587) | Loss -51.350(-51.981) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3460 | Time 7.610(7.581) | Loss -52.525(-52.123) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3470 | Time 7.603(7.586) | Loss -51.000(-52.077) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3480 | Time 7.462(7.577) | Loss -52.702(-52.066) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3490 | Time 7.596(7.578) | Loss -50.459(-52.129) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3500 | Time 7.622(7.590) | Loss -54.571(-52.354) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3510 | Time 7.626(7.589) | Loss -53.990(-52.574) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3520 | Time 7.618(7.590) | Loss -53.914(-52.761) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3530 | Time 7.598(7.591) | Loss -51.728(-52.790) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3540 | Time 7.604(7.591) | Loss -52.777(-52.553) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3550 | Time 7.595(7.595) | Loss -51.824(-52.461) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3560 | Time 7.582(7.592) | Loss -52.868(-52.447) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3570 | Time 7.592(7.592) | Loss -51.660(-52.488) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3580 | Time 7.598(7.593) | Loss -52.311(-52.532) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -52.478 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 3590 | Time 7.622(8.314) | Loss -52.534(-52.518) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3600 | Time 7.599(8.071) | Loss -53.193(-52.651) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3610 | Time 7.593(7.908) | Loss -52.319(-52.646) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3620 | Time 7.565(7.793) | Loss -52.716(-52.497) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3630 | Time 7.569(7.718) | Loss -52.652(-52.374) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3640 | Time 7.619(7.682) | Loss -51.373(-52.439) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3650 | Time 7.577(7.655) | Loss -53.990(-52.663) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3660 | Time 7.608(7.636) | Loss -53.546(-52.870) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3670 | Time 7.640(7.621) | Loss -53.376(-52.815) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3680 | Time 7.597(7.605) | Loss -54.356(-52.878) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3690 | Time 7.574(7.593) | Loss -52.905(-53.098) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3700 | Time 7.608(7.592) | Loss -53.545(-53.064) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3710 | Time 7.604(7.593) | Loss -50.820(-52.836) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3720 | Time 7.603(7.591) | Loss -53.349(-52.579) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3730 | Time 7.584(7.589) | Loss -52.083(-52.594) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3740 | Time 7.589(7.591) | Loss -53.637(-52.799) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3750 | Time 7.581(7.580) | Loss -54.459(-52.999) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3760 | Time 7.585(7.586) | Loss -51.296(-53.119) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3770 | Time 7.452(7.562) | Loss -52.366(-52.857) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3780 | Time 7.556(7.562) | Loss -53.547(-52.820) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3790 | Time 7.566(7.557) | Loss -52.925(-52.845) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3800 | Time 7.661(7.571) | Loss -51.902(-52.966) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3810 | Time 7.596(7.579) | Loss -52.412(-52.808) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3820 | Time 7.469(7.572) | Loss -52.763(-52.746) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3830 | Time 7.459(7.540) | Loss -54.307(-53.057) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3840 | Time 7.593(7.562) | Loss -53.364(-53.270) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -52.030 | NFE 62 | NoImproveEpochs 01/16
Epoch 0 | Iter 3850 | Time 7.558(8.204) | Loss -53.223(-53.339) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3860 | Time 7.623(8.004) | Loss -52.363(-53.481) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3870 | Time 7.581(7.862) | Loss -53.540(-53.317) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3880 | Time 7.568(7.770) | Loss -54.326(-53.246) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3890 | Time 7.457(7.672) | Loss -54.096(-53.596) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3900 | Time 7.504(7.623) | Loss -53.028(-53.296) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3910 | Time 7.586(7.606) | Loss -53.715(-53.229) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3920 | Time 7.613(7.579) | Loss -52.596(-53.352) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3930 | Time 7.579(7.582) | Loss -54.274(-53.574) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3940 | Time 7.473(7.548) | Loss -54.170(-53.979) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3950 | Time 7.611(7.540) | Loss -54.740(-54.028) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3960 | Time 7.595(7.559) | Loss -53.192(-53.882) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3970 | Time 7.574(7.571) | Loss -54.377(-53.889) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3980 | Time 7.557(7.567) | Loss -54.002(-53.633) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 3990 | Time 7.529(7.565) | Loss -53.447(-53.607) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4000 | Time 7.449(7.552) | Loss -52.996(-53.544) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4010 | Time 7.454(7.529) | Loss -53.413(-53.586) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4020 | Time 7.463(7.535) | Loss -54.274(-53.812) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4030 | Time 7.577(7.538) | Loss -52.414(-53.658) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4040 | Time 7.596(7.542) | Loss -53.499(-53.671) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4050 | Time 7.589(7.562) | Loss -53.876(-53.719) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4060 | Time 7.589(7.574) | Loss -54.267(-53.850) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4070 | Time 7.581(7.572) | Loss -52.579(-53.871) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4080 | Time 7.577(7.584) | Loss -53.671(-54.001) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4090 | Time 7.569(7.589) | Loss -53.492(-53.964) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -52.372 | NFE 62 | NoImproveEpochs 02/16
Epoch 0 | Iter 4100 | Time 7.593(8.400) | Loss -53.485(-53.717) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4110 | Time 7.483(8.122) | Loss -53.396(-53.760) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4120 | Time 7.616(7.936) | Loss -53.647(-53.797) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4130 | Time 7.632(7.813) | Loss -52.909(-53.888) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4140 | Time 7.471(7.739) | Loss -54.835(-54.053) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4150 | Time 7.585(7.687) | Loss -53.826(-54.265) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4160 | Time 7.649(7.667) | Loss -54.150(-54.331) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4170 | Time 7.595(7.647) | Loss -54.002(-54.227) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4180 | Time 7.600(7.633) | Loss -52.283(-53.986) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4190 | Time 7.590(7.625) | Loss -54.196(-53.880) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4200 | Time 7.612(7.620) | Loss -55.200(-53.975) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4210 | Time 7.592(7.610) | Loss -54.409(-54.075) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4220 | Time 7.609(7.609) | Loss -54.474(-54.346) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4230 | Time 7.605(7.609) | Loss -53.846(-54.345) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4240 | Time 7.622(7.609) | Loss -55.879(-54.499) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4250 | Time 7.590(7.622) | Loss -54.053(-54.249) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4260 | Time 7.610(7.629) | Loss -55.233(-54.443) | NFE Forward 62(62.0) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4270 | Time 7.623(7.603) | Loss -55.329(-54.719) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4280 | Time 7.572(7.600) | Loss -55.659(-54.847) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4290 | Time 7.589(7.598) | Loss -53.290(-54.570) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4300 | Time 7.592(7.593) | Loss -56.289(-54.603) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4310 | Time 7.566(7.588) | Loss -53.782(-54.655) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4320 | Time 7.598(7.577) | Loss -55.546(-54.733) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4330 | Time 7.552(7.582) | Loss -54.407(-54.539) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4340 | Time 7.585(7.579) | Loss -55.105(-54.624) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4350 | Time 7.579(7.570) | Loss -54.512(-54.582) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -54.779 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 4360 | Time 7.608(8.254) | Loss -55.749(-54.714) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4370 | Time 7.624(8.034) | Loss -54.458(-54.606) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4380 | Time 7.611(7.887) | Loss -55.454(-54.512) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4390 | Time 7.462(7.779) | Loss -53.109(-54.225) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4400 | Time 7.514(7.692) | Loss -55.317(-54.262) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4410 | Time 7.521(7.659) | Loss -55.657(-54.479) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4420 | Time 7.528(7.599) | Loss -53.325(-54.778) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4430 | Time 7.453(7.562) | Loss -55.166(-54.931) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4440 | Time 7.482(7.536) | Loss -55.789(-55.184) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4450 | Time 7.475(7.520) | Loss -55.667(-55.040) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4460 | Time 7.560(7.525) | Loss -54.074(-54.853) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4470 | Time 7.577(7.544) | Loss -54.616(-54.966) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4480 | Time 7.539(7.546) | Loss -54.280(-55.008) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4490 | Time 7.571(7.559) | Loss -54.683(-55.074) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4500 | Time 7.571(7.566) | Loss -54.117(-55.020) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4510 | Time 7.592(7.569) | Loss -56.599(-55.066) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4520 | Time 7.571(7.571) | Loss -55.939(-55.272) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4530 | Time 7.499(7.565) | Loss -55.442(-55.292) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4540 | Time 7.453(7.559) | Loss -55.247(-55.346) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4550 | Time 7.605(7.564) | Loss -56.480(-55.523) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4560 | Time 7.608(7.572) | Loss -53.923(-55.355) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4570 | Time 7.562(7.571) | Loss -54.527(-54.944) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4580 | Time 7.581(7.575) | Loss -55.464(-55.158) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4590 | Time 7.607(7.576) | Loss -54.936(-55.290) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4600 | Time 7.604(7.584) | Loss -54.735(-55.116) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -54.386 | NFE 62 | NoImproveEpochs 01/16
Epoch 0 | Iter 4610 | Time 7.478(8.449) | Loss -54.926(-55.078) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4620 | Time 7.593(8.152) | Loss -55.689(-55.205) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4630 | Time 7.583(7.957) | Loss -54.829(-55.360) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4640 | Time 7.588(7.834) | Loss -55.052(-55.376) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4650 | Time 7.467(7.747) | Loss -55.361(-55.484) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4660 | Time 7.461(7.683) | Loss -54.377(-55.313) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4670 | Time 7.614(7.648) | Loss -55.323(-55.396) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4680 | Time 7.464(7.627) | Loss -56.103(-55.462) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4690 | Time 7.584(7.618) | Loss -54.978(-55.268) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4700 | Time 7.587(7.611) | Loss -54.739(-55.139) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4710 | Time 7.602(7.614) | Loss -54.628(-55.025) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4720 | Time 7.607(7.611) | Loss -56.592(-55.208) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4730 | Time 7.649(7.610) | Loss -53.768(-55.083) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4740 | Time 7.530(7.603) | Loss -56.735(-55.468) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4750 | Time 7.599(7.589) | Loss -55.233(-55.639) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4760 | Time 7.603(7.593) | Loss -54.626(-55.567) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4770 | Time 7.579(7.594) | Loss -55.598(-55.553) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4780 | Time 7.602(7.595) | Loss -56.694(-55.727) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4790 | Time 7.594(7.580) | Loss -56.334(-55.698) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4800 | Time 7.459(7.567) | Loss -55.282(-55.668) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4810 | Time 7.577(7.573) | Loss -54.616(-55.474) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4820 | Time 7.594(7.578) | Loss -55.398(-55.420) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4830 | Time 7.644(7.585) | Loss -56.509(-55.331) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4840 | Time 7.491(7.576) | Loss -55.407(-55.445) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4850 | Time 7.614(7.575) | Loss -55.956(-55.766) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4860 | Time 7.587(7.582) | Loss -56.093(-55.949) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -55.060 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 4870 | Time 7.611(8.329) | Loss -57.657(-56.031) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4880 | Time 7.591(8.082) | Loss -56.615(-56.099) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4890 | Time 7.611(7.904) | Loss -54.778(-56.111) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4900 | Time 7.477(7.769) | Loss -55.861(-56.151) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4910 | Time 7.531(7.685) | Loss -55.524(-55.882) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4920 | Time 7.584(7.637) | Loss -54.616(-55.768) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4930 | Time 7.471(7.631) | Loss -54.299(-55.590) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4940 | Time 7.598(7.609) | Loss -56.258(-55.633) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4950 | Time 7.471(7.599) | Loss -54.950(-55.917) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4960 | Time 7.595(7.574) | Loss -55.466(-55.924) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4970 | Time 7.472(7.564) | Loss -55.984(-56.035) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4980 | Time 7.508(7.561) | Loss -55.290(-56.054) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 4990 | Time 7.596(7.558) | Loss -55.410(-56.121) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5000 | Time 7.584(7.570) | Loss -54.712(-55.938) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5010 | Time 7.598(7.580) | Loss -57.576(-56.177) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5020 | Time 7.614(7.579) | Loss -54.991(-56.181) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5030 | Time 7.589(7.573) | Loss -57.248(-56.383) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5040 | Time 7.601(7.573) | Loss -57.312(-56.531) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5050 | Time 7.594(7.586) | Loss -55.334(-56.447) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5060 | Time 7.473(7.569) | Loss -56.035(-56.277) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5070 | Time 7.616(7.561) | Loss -56.430(-56.275) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5080 | Time 7.591(7.577) | Loss -56.306(-56.191) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5090 | Time 7.461(7.566) | Loss -56.316(-56.367) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5100 | Time 7.540(7.541) | Loss -57.566(-56.730) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5110 | Time 7.601(7.536) | Loss -56.768(-56.843) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5120 | Time 7.607(7.547) | Loss -56.226(-56.510) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -54.959 | NFE 62 | NoImproveEpochs 01/16
Epoch 0 | Iter 5130 | Time 7.615(8.176) | Loss -56.895(-56.417) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5140 | Time 7.497(7.954) | Loss -55.324(-56.153) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5150 | Time 7.496(7.804) | Loss -55.367(-56.211) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5160 | Time 7.572(7.739) | Loss -57.440(-56.331) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5170 | Time 7.616(7.691) | Loss -56.701(-56.467) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5180 | Time 7.612(7.663) | Loss -56.279(-56.690) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5190 | Time 7.575(7.639) | Loss -55.259(-56.669) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5200 | Time 7.595(7.637) | Loss -56.598(-56.401) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5210 | Time 7.597(7.622) | Loss -56.912(-56.580) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5220 | Time 7.643(7.618) | Loss -56.624(-56.706) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5230 | Time 7.509(7.594) | Loss -57.434(-56.674) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5240 | Time 7.585(7.604) | Loss -56.140(-56.428) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5250 | Time 7.611(7.600) | Loss -56.675(-56.312) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5260 | Time 7.594(7.598) | Loss -54.963(-56.185) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5270 | Time 7.597(7.599) | Loss -56.607(-56.280) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5280 | Time 7.597(7.603) | Loss -55.823(-56.533) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5290 | Time 7.581(7.599) | Loss -55.432(-56.425) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5300 | Time 7.608(7.600) | Loss -56.027(-56.420) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5310 | Time 7.585(7.595) | Loss -56.891(-56.454) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5320 | Time 7.600(7.599) | Loss -55.536(-56.545) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5330 | Time 7.612(7.603) | Loss -56.950(-56.630) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5340 | Time 7.628(7.605) | Loss -57.367(-56.824) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5350 | Time 7.611(7.600) | Loss -56.617(-56.797) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5360 | Time 7.603(7.600) | Loss -56.663(-56.707) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5370 | Time 7.476(7.579) | Loss -56.499(-56.820) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -56.731 | NFE 62 | NoImproveEpochs 00/16
Epoch 0 | Iter 5380 | Time 7.578(8.389) | Loss -56.893(-57.072) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5390 | Time 7.535(8.110) | Loss -58.728(-57.421) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5400 | Time 7.880(7.966) | Loss -56.568(-57.253) | NFE Forward 62(62.2) | NFE Backward 87(81.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5410 | Time 7.592(7.835) | Loss -57.088(-57.148) | NFE Forward 62(62.1) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5420 | Time 7.547(7.742) | Loss -58.119(-57.324) | NFE Forward 62(62.1) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5430 | Time 7.585(7.691) | Loss -58.074(-57.425) | NFE Forward 62(62.1) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5440 | Time 7.612(7.661) | Loss -57.237(-57.436) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5450 | Time 7.576(7.641) | Loss -58.001(-57.298) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5460 | Time 7.557(7.615) | Loss -58.795(-57.266) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5470 | Time 7.503(7.600) | Loss -56.868(-57.283) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5480 | Time 7.571(7.590) | Loss -57.037(-57.331) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5490 | Time 7.571(7.573) | Loss -55.483(-57.212) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5500 | Time 7.577(7.556) | Loss -57.079(-57.008) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5510 | Time 7.601(7.570) | Loss -57.277(-57.127) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5520 | Time 7.636(7.548) | Loss -57.793(-57.356) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5530 | Time 7.487(7.529) | Loss -58.079(-57.400) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5540 | Time 7.544(7.523) | Loss -58.616(-57.443) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5550 | Time 7.555(7.539) | Loss -57.333(-57.480) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5560 | Time 7.615(7.541) | Loss -56.210(-57.481) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5570 | Time 7.548(7.560) | Loss -57.304(-57.240) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5580 | Time 7.604(7.550) | Loss -57.132(-57.204) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5590 | Time 7.484(7.549) | Loss -58.372(-57.330) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5600 | Time 7.654(7.536) | Loss -57.647(-57.301) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5610 | Time 7.522(7.533) | Loss -58.250(-57.413) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5620 | Time 7.486(7.562) | Loss -57.479(-57.441) | NFE Forward 62(62.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5630 | Time 7.500(7.562) | Loss -57.560(-57.519) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -56.333 | NFE 62 | NoImproveEpochs 01/16
Epoch 0 | Iter 5640 | Time 7.680(8.256) | Loss -57.589(-57.468) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5650 | Time 7.644(8.041) | Loss -56.793(-57.377) | NFE Forward 62(62.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5660 | Time 7.610(7.900) | Loss -58.551(-57.507) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5670 | Time 7.565(7.802) | Loss -58.752(-57.767) | NFE Forward 62(62.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5680 | Time 7.578(7.733) | Loss -57.695(-57.730) | NFE Forward 62(62.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5690 | Time 7.628(7.695) | Loss -58.308(-57.689) | NFE Forward 62(62.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5700 | Time 7.614(7.658) | Loss -57.793(-57.657) | NFE Forward 62(62.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5710 | Time 7.613(7.638) | Loss -58.029(-57.542) | NFE Forward 62(62.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5720 | Time 7.502(7.597) | Loss -57.774(-57.640) | NFE Forward 62(62.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5730 | Time 7.514(7.583) | Loss -56.825(-57.427) | NFE Forward 62(62.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5740 | Time 7.612(7.588) | Loss -58.233(-57.469) | NFE Forward 62(62.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5750 | Time 7.479(7.579) | Loss -58.091(-57.816) | NFE Forward 62(62.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5760 | Time 7.424(7.557) | Loss -58.430(-57.997) | NFE Forward 56(61.8) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5770 | Time 7.588(7.575) | Loss -57.367(-57.865) | NFE Forward 62(61.9) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5780 | Time 7.617(7.582) | Loss -57.828(-57.770) | NFE Forward 62(61.9) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5790 | Time 7.631(7.609) | Loss -58.377(-57.918) | NFE Forward 62(62.5) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5800 | Time 7.658(7.604) | Loss -57.574(-58.147) | NFE Forward 62(62.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5810 | Time 7.636(7.606) | Loss -58.415(-58.130) | NFE Forward 62(62.2) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5820 | Time 7.589(7.644) | Loss -56.900(-57.844) | NFE Forward 62(62.7) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5830 | Time 7.589(7.635) | Loss -58.529(-57.843) | NFE Forward 62(62.7) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5840 | Time 7.614(7.636) | Loss -57.370(-57.829) | NFE Forward 62(62.9) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5850 | Time 7.463(7.607) | Loss -57.903(-57.870) | NFE Forward 62(62.6) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5860 | Time 7.599(7.601) | Loss -58.032(-57.769) | NFE Forward 62(62.7) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5870 | Time 7.553(7.609) | Loss -57.835(-57.850) | NFE Forward 62(62.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5880 | Time 7.606(7.616) | Loss -58.358(-58.004) | NFE Forward 62(62.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -56.211 | NFE 62 | NoImproveEpochs 02/16
Epoch 0 | Iter 5890 | Time 7.559(8.495) | Loss -58.123(-57.989) | NFE Forward 62(62.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5900 | Time 7.574(8.195) | Loss -58.125(-58.026) | NFE Forward 62(62.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5910 | Time 7.615(8.015) | Loss -58.871(-58.136) | NFE Forward 62(62.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5920 | Time 7.575(7.895) | Loss -57.963(-58.063) | NFE Forward 62(62.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5930 | Time 7.637(7.841) | Loss -57.480(-57.897) | NFE Forward 62(63.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5940 | Time 7.609(7.777) | Loss -57.811(-58.001) | NFE Forward 62(63.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5950 | Time 7.589(7.716) | Loss -58.907(-58.160) | NFE Forward 62(62.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5960 | Time 7.832(7.701) | Loss -57.763(-58.260) | NFE Forward 68(63.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5970 | Time 7.656(7.661) | Loss -58.308(-58.352) | NFE Forward 62(63.1) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5980 | Time 7.766(7.668) | Loss -58.286(-58.380) | NFE Forward 68(63.7) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 5990 | Time 7.827(7.700) | Loss -58.186(-58.187) | NFE Forward 68(64.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6000 | Time 7.854(7.720) | Loss -58.393(-58.142) | NFE Forward 68(64.6) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6010 | Time 7.647(7.686) | Loss -58.247(-58.179) | NFE Forward 62(63.9) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6020 | Time 7.659(7.665) | Loss -58.913(-58.436) | NFE Forward 62(63.2) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6030 | Time 7.611(7.656) | Loss -58.758(-58.657) | NFE Forward 62(63.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6040 | Time 7.837(7.664) | Loss -58.321(-58.613) | NFE Forward 68(63.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6050 | Time 7.560(7.662) | Loss -58.952(-58.472) | NFE Forward 62(63.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6060 | Time 7.591(7.653) | Loss -59.167(-58.329) | NFE Forward 62(63.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6070 | Time 7.598(7.637) | Loss -58.987(-58.201) | NFE Forward 62(63.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6080 | Time 7.554(7.632) | Loss -56.995(-58.090) | NFE Forward 62(63.3) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6090 | Time 7.581(7.627) | Loss -59.429(-58.224) | NFE Forward 62(63.1) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6100 | Time 7.836(7.660) | Loss -57.400(-58.006) | NFE Forward 68(64.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6110 | Time 7.606(7.623) | Loss -59.671(-58.270) | NFE Forward 62(63.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6120 | Time 7.607(7.603) | Loss -57.774(-58.306) | NFE Forward 62(63.4) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6130 | Time 7.886(7.640) | Loss -55.915(-58.207) | NFE Forward 68(64.0) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6140 | Time 7.561(7.671) | Loss -58.342(-58.218) | NFE Forward 62(64.7) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -56.509 | NFE 63 | NoImproveEpochs 03/16
Epoch 0 | Iter 6150 | Time 7.797(8.415) | Loss -58.757(-58.274) | NFE Forward 68(64.4) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 2.961(2.961) | Loss 37.427(37.427) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6160 | Time 7.820(8.166) | Loss -56.306(-58.219) | NFE Forward 68(64.5) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6170 | Time 7.844(8.050) | Loss -57.125(-58.101) | NFE Forward 68(65.0) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 2.868(2.868) | Loss 37.344(37.344) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6180 | Time 7.572(7.891) | Loss -59.078(-58.341) | NFE Forward 62(64.0) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6190 | Time 7.612(7.790) | Loss -58.712(-58.417) | NFE Forward 62(63.3) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6200 | Time 7.813(7.764) | Loss -58.958(-58.433) | NFE Forward 68(64.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6210 | Time 7.591(7.750) | Loss -59.550(-58.442) | NFE Forward 62(64.5) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6220 | Time 7.604(7.751) | Loss -58.748(-58.552) | NFE Forward 62(65.0) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 2.911(2.911) | Loss 37.499(37.499) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
Epoch 0 | Iter 6230 | Time 7.837(7.752) | Loss -59.604(-58.728) | NFE Forward 68(65.4) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.022(3.022) | Loss 37.739(37.739) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.051(3.051) | Loss 37.443(37.443) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6240 | Time 7.794(7.712) | Loss -59.217(-58.987) | NFE Forward 68(64.7) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.021(3.021) | Loss 37.961(37.961) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6250 | Time 7.796(7.707) | Loss -58.152(-59.190) | NFE Forward 68(64.6) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.018(3.018) | Loss 37.683(37.683) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6260 | Time 7.797(7.715) | Loss -58.969(-59.107) | NFE Forward 68(65.0) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
Epoch 0 | Iter 6270 | Time 7.815(7.748) | Loss -57.759(-58.736) | NFE Forward 68(65.8) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.014(3.014) | Loss 37.687(37.687) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6280 | Time 7.599(7.769) | Loss -58.836(-58.575) | NFE Forward 62(65.7) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6290 | Time 7.812(7.759) | Loss -58.972(-58.552) | NFE Forward 68(65.7) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6300 | Time 7.845(7.812) | Loss -57.809(-58.184) | NFE Forward 68(66.1) | NFE Backward 81(81.9) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.497(3.497) | Loss 37.344(37.344) | NFE Forward 20(20.0) | NFE Backward 27(27.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss 36.872 | NFE 20 | NoImproveEpochs 00/16 [*]
Epoch 0 | Iter 6310 | Time 7.462(7.763) | Loss -58.273(-58.337) | NFE Forward 62(65.9) | NFE Backward 81(81.6) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.014(3.014) | Loss 37.347(37.347) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss 36.869 | NFE 20 | NoImproveEpochs 00/16 [*]
Epoch 0 | Iter 6320 | Time 7.604(7.727) | Loss -59.291(-58.532) | NFE Forward 62(65.2) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 10 | Time 2.617(3.058) | Loss 35.453(36.858) | NFE Forward 20(20.0) | NFE Backward 27(22.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 2.839(2.966) | Loss 34.504(36.224) | NFE Forward 26(21.5) | NFE Backward 27(24.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 2.838(2.931) | Loss 31.872(35.192) | NFE Forward 26(23.0) | NFE Backward 27(25.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6330 | Time 7.799(7.724) | Loss -59.339(-58.736) | NFE Forward 68(65.3) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 3.057(2.907) | Loss 26.450(33.051) | NFE Forward 32(24.5) | NFE Backward 27(25.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 50 | Time 3.913(3.257) | Loss 20.070(29.624) | NFE Forward 32(27.0) | NFE Backward 39(30.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6340 | Time 7.793(7.754) | Loss -58.262(-58.761) | NFE Forward 68(65.8) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 60 | Time 4.878(3.624) | Loss 13.913(25.236) | NFE Forward 38(29.1) | NFE Backward 51(35.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 70 | Time 4.768(4.030) | Loss 8.264(20.321) | NFE Forward 44(33.0) | NFE Backward 45(39.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 6350 | Time 7.863(7.750) | Loss -58.308(-58.669) | NFE Forward 68(65.8) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 80 | Time 4.479(4.438) | Loss 3.325(15.328) | NFE Forward 38(36.4) | NFE Backward 45(44.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 0 | Time 7.923(7.759) | Loss -59.358(-58.797) | NFE Forward 68(65.8) | NFE Backward 81(81.6) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -58.371 | NFE 66 | NoImproveEpochs 00/16
Epoch 0 | Iter 90 | Time 5.516(4.782) | Loss 0.393(10.674) | NFE Forward 44(38.5) | NFE Backward 57(48.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 100 | Time 5.708(5.077) | Loss -3.314(6.358) | NFE Forward 50(41.2) | NFE Backward 57(51.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 10 | Time 7.774(8.420) | Loss -58.097(-58.714) | NFE Forward 68(65.7) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 110 | Time 6.194(5.375) | Loss -5.887(2.489) | NFE Forward 50(44.1) | NFE Backward 63(54.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 20 | Time 7.771(8.192) | Loss -59.308(-58.792) | NFE Forward 68(66.1) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 120 | Time 5.720(5.632) | Loss -8.605(-0.846) | NFE Forward 50(46.1) | NFE Backward 57(56.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 30 | Time 7.844(8.020) | Loss -59.615(-59.036) | NFE Forward 68(65.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 130 | Time 6.145(5.829) | Loss -10.696(-3.809) | NFE Forward 50(47.6) | NFE Backward 63(58.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 140 | Time 6.245(5.960) | Loss -12.984(-6.610) | NFE Forward 50(48.4) | NFE Backward 63(60.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 40 | Time 7.821(7.970) | Loss -58.914(-59.263) | NFE Forward 68(66.2) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 150 | Time 6.175(6.060) | Loss -14.425(-8.984) | NFE Forward 50(49.2) | NFE Backward 63(61.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 50 | Time 7.809(7.909) | Loss -57.853(-59.142) | NFE Forward 68(66.6) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.017(3.017) | Loss 37.279(37.279) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss 36.863 | NFE 20 | NoImproveEpochs 00/16 [*]
Epoch 0 | Iter 10 | Time 2.642(3.057) | Loss 35.524(36.817) | NFE Forward 20(20.0) | NFE Backward 27(22.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 60 | Time 7.589(7.874) | Loss -58.813(-58.964) | NFE Forward 62(66.6) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 2.881(2.958) | Loss 34.629(36.219) | NFE Forward 26(21.1) | NFE Backward 27(24.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 2.839(2.913) | Loss 32.281(35.296) | NFE Forward 26(22.7) | NFE Backward 27(25.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 70 | Time 7.619(7.845) | Loss -58.002(-58.943) | NFE Forward 62(66.7) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 2.855(2.891) | Loss 26.842(33.344) | NFE Forward 26(23.8) | NFE Backward 27(25.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 50 | Time 3.880(3.135) | Loss 19.808(29.786) | NFE Forward 32(26.2) | NFE Backward 39(29.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 80 | Time 7.845(7.850) | Loss -58.893(-58.966) | NFE Forward 68(66.9) | NFE Backward 81(81.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 60 | Time 4.960(3.569) | Loss 12.902(25.113) | NFE Forward 38(28.6) | NFE Backward 51(34.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 70 | Time 5.190(4.040) | Loss 6.321(19.765) | NFE Forward 44(32.0) | NFE Backward 51(40.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 90 | Time 7.867(7.867) | Loss -59.187(-58.748) | NFE Forward 68(67.1) | NFE Backward 81(81.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 80 | Time 5.662(4.513) | Loss 1.753(14.320) | NFE Forward 44(35.5) | NFE Backward 57(45.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 100 | Time 7.804(7.806) | Loss -59.400(-58.772) | NFE Forward 68(66.4) | NFE Backward 81(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 90 | Time 5.773(4.886) | Loss -2.431(9.262) | NFE Forward 50(38.6) | NFE Backward 57(49.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 100 | Time 5.922(5.210) | Loss -6.020(4.756) | NFE Forward 50(42.0) | NFE Backward 57(51.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 110 | Time 7.821(7.768) | Loss -59.985(-58.971) | NFE Forward 68(65.9) | NFE Backward 81(81.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 110 | Time 5.904(5.458) | Loss -8.229(0.765) | NFE Forward 50(44.7) | NFE Backward 57(53.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 120 | Time 7.827(7.735) | Loss -59.255(-59.197) | NFE Forward 68(66.3) | NFE Backward 81(80.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 120 | Time 5.865(5.717) | Loss -10.403(-2.629) | NFE Forward 50(46.5) | NFE Backward 57(56.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 130 | Time 7.851(7.757) | Loss -57.669(-59.018) | NFE Forward 68(66.5) | NFE Backward 81(80.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 130 | Time 5.804(5.757) | Loss -13.157(-5.768) | NFE Forward 50(47.7) | NFE Backward 57(56.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 140 | Time 6.273(5.893) | Loss -15.408(-8.732) | NFE Forward 50(48.4) | NFE Backward 63(58.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 140 | Time 7.827(7.774) | Loss -59.551(-58.851) | NFE Forward 68(66.8) | NFE Backward 81(80.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 150 | Time 6.262(6.036) | Loss -16.349(-10.994) | NFE Forward 50(49.5) | NFE Backward 63(60.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 150 | Time 7.859(7.782) | Loss -57.918(-58.843) | NFE Forward 68(67.2) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 160 | Time 6.198(6.100) | Loss -18.427(-13.006) | NFE Forward 50(49.7) | NFE Backward 63(61.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 160 | Time 7.825(7.788) | Loss -58.728(-59.009) | NFE Forward 68(67.3) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 170 | Time 6.254(6.155) | Loss -18.821(-14.612) | NFE Forward 50(49.8) | NFE Backward 63(61.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 170 | Time 7.612(7.778) | Loss -60.458(-59.275) | NFE Forward 62(66.9) | NFE Backward 81(80.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 180 | Time 6.256(6.199) | Loss -19.829(-16.247) | NFE Forward 50(50.1) | NFE Backward 63(62.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 180 | Time 7.686(7.770) | Loss -58.930(-59.410) | NFE Forward 68(66.9) | NFE Backward 81(81.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 190 | Time 6.156(6.195) | Loss -19.630(-17.601) | NFE Forward 50(50.3) | NFE Backward 63(62.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 200 | Time 6.117(6.210) | Loss -21.241(-18.658) | NFE Forward 50(50.9) | NFE Backward 63(62.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 190 | Time 7.819(7.775) | Loss -57.959(-59.106) | NFE Forward 68(66.6) | NFE Backward 81(81.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 210 | Time 6.599(6.241) | Loss -20.349(-19.652) | NFE Forward 62(51.7) | NFE Backward 63(62.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 200 | Time 8.213(7.818) | Loss -57.626(-58.933) | NFE Forward 68(67.1) | NFE Backward 87(81.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 220 | Time 6.131(6.235) | Loss -22.068(-20.436) | NFE Forward 50(51.9) | NFE Backward 63(62.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 210 | Time 7.573(7.810) | Loss -59.552(-59.003) | NFE Forward 62(67.1) | NFE Backward 81(81.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 230 | Time 6.281(6.278) | Loss -23.307(-21.173) | NFE Forward 50(52.5) | NFE Backward 63(62.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 220 | Time 7.687(7.749) | Loss -60.568(-59.385) | NFE Forward 68(66.8) | NFE Backward 81(81.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 240 | Time 6.290(6.261) | Loss -24.464(-22.195) | NFE Forward 50(51.7) | NFE Backward 63(62.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 250 | Time 6.607(6.351) | Loss -24.656(-23.016) | NFE Forward 62(52.9) | NFE Backward 63(63.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 230 | Time 7.818(7.760) | Loss -58.121(-59.287) | NFE Forward 68(67.2) | NFE Backward 81(81.3) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -24.439 | NFE 58 | NoImproveEpochs 00/16 [*]
Epoch 1 | Iter 240 | Time 7.809(7.753) | Loss -60.554(-59.463) | NFE Forward 68(67.0) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 260 | Time 6.266(7.238) | Loss -24.496(-23.324) | NFE Forward 50(53.5) | NFE Backward 63(64.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 270 | Time 6.115(6.968) | Loss -25.409(-23.567) | NFE Forward 50(52.9) | NFE Backward 63(64.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 250 | Time 7.802(7.793) | Loss -59.135(-59.570) | NFE Forward 68(67.4) | NFE Backward 81(81.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 280 | Time 6.234(6.708) | Loss -26.516(-24.326) | NFE Forward 50(51.9) | NFE Backward 63(64.2) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -58.251 | NFE 67 | NoImproveEpochs 01/16
Epoch 1 | Iter 260 | Time 7.407(8.680) | Loss -59.931(-59.505) | NFE Forward 68(67.6) | NFE Backward 75(81.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 290 | Time 6.258(6.548) | Loss -27.912(-25.190) | NFE Forward 50(51.3) | NFE Backward 63(63.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 300 | Time 6.643(6.548) | Loss -26.893(-25.737) | NFE Forward 50(51.7) | NFE Backward 69(64.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 270 | Time 8.225(8.403) | Loss -60.362(-59.590) | NFE Forward 68(67.7) | NFE Backward 87(81.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 310 | Time 6.233(6.549) | Loss -27.801(-26.365) | NFE Forward 50(53.3) | NFE Backward 63(64.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 280 | Time 8.191(8.218) | Loss -58.273(-59.286) | NFE Forward 68(67.8) | NFE Backward 87(81.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 320 | Time 6.222(6.440) | Loss -29.017(-27.185) | NFE Forward 50(52.2) | NFE Backward 63(64.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 290 | Time 7.825(8.072) | Loss -59.444(-59.325) | NFE Forward 68(67.7) | NFE Backward 81(81.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 330 | Time 7.063(6.581) | Loss -29.463(-27.970) | NFE Forward 62(54.0) | NFE Backward 69(65.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 300 | Time 7.805(8.010) | Loss -58.822(-59.240) | NFE Forward 68(67.8) | NFE Backward 81(81.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 340 | Time 6.768(6.662) | Loss -30.442(-28.648) | NFE Forward 56(55.7) | NFE Backward 69(66.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 310 | Time 7.773(7.958) | Loss -58.699(-59.064) | NFE Forward 68(67.9) | NFE Backward 81(81.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 350 | Time 6.785(6.689) | Loss -30.149(-29.230) | NFE Forward 56(57.0) | NFE Backward 69(66.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 320 | Time 7.587(7.895) | Loss -61.045(-59.190) | NFE Forward 62(67.2) | NFE Backward 81(81.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 360 | Time 7.395(6.788) | Loss -29.828(-29.719) | NFE Forward 62(57.3) | NFE Backward 75(67.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 370 | Time 6.389(6.776) | Loss -30.957(-30.106) | NFE Forward 56(57.6) | NFE Backward 63(68.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 330 | Time 7.781(7.814) | Loss -57.808(-59.211) | NFE Forward 68(66.4) | NFE Backward 81(81.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 380 | Time 6.776(6.771) | Loss -31.594(-30.610) | NFE Forward 56(57.3) | NFE Backward 69(68.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 340 | Time 7.795(7.828) | Loss -58.753(-59.177) | NFE Forward 68(66.8) | NFE Backward 81(81.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 390 | Time 6.941(6.789) | Loss -33.570(-31.111) | NFE Forward 62(57.7) | NFE Backward 69(68.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 350 | Time 7.796(7.816) | Loss -59.604(-59.367) | NFE Forward 68(66.8) | NFE Backward 81(81.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 400 | Time 7.005(6.855) | Loss -32.807(-31.393) | NFE Forward 62(58.9) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 360 | Time 8.208(7.836) | Loss -60.422(-59.451) | NFE Forward 68(66.9) | NFE Backward 87(81.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 410 | Time 6.829(6.846) | Loss -32.094(-31.539) | NFE Forward 62(59.1) | NFE Backward 69(69.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 370 | Time 7.798(7.844) | Loss -59.747(-59.537) | NFE Forward 68(67.3) | NFE Backward 81(82.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 420 | Time 6.966(6.837) | Loss -32.182(-31.827) | NFE Forward 62(59.3) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 380 | Time 7.794(7.843) | Loss -60.099(-59.580) | NFE Forward 68(67.5) | NFE Backward 81(82.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 430 | Time 7.023(6.860) | Loss -33.131(-32.158) | NFE Forward 62(59.6) | NFE Backward 69(69.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 390 | Time 8.641(7.889) | Loss -58.728(-59.427) | NFE Forward 68(67.7) | NFE Backward 93(82.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 440 | Time 7.039(6.894) | Loss -33.444(-32.463) | NFE Forward 62(60.0) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 450 | Time 7.246(6.901) | Loss -32.772(-32.644) | NFE Forward 62(59.7) | NFE Backward 75(69.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 400 | Time 7.673(7.805) | Loss -61.236(-59.538) | NFE Forward 68(67.1) | NFE Backward 81(81.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 460 | Time 6.625(6.842) | Loss -33.899(-32.807) | NFE Forward 56(59.0) | NFE Backward 69(69.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 410 | Time 7.688(7.766) | Loss -58.721(-59.620) | NFE Forward 68(67.0) | NFE Backward 81(81.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 470 | Time 6.992(6.829) | Loss -33.669(-33.072) | NFE Forward 62(58.8) | NFE Backward 69(69.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 420 | Time 7.692(7.792) | Loss -59.746(-59.610) | NFE Forward 68(66.9) | NFE Backward 81(82.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 480 | Time 6.845(6.814) | Loss -33.264(-33.305) | NFE Forward 62(59.1) | NFE Backward 69(69.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 430 | Time 7.810(7.792) | Loss -59.746(-59.666) | NFE Forward 68(66.5) | NFE Backward 81(82.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 490 | Time 6.678(6.811) | Loss -34.772(-33.614) | NFE Forward 56(58.6) | NFE Backward 69(69.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 440 | Time 7.809(7.832) | Loss -58.527(-59.574) | NFE Forward 68(66.8) | NFE Backward 81(82.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 500 | Time 6.779(6.826) | Loss -33.540(-33.732) | NFE Forward 56(58.4) | NFE Backward 69(69.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 450 | Time 8.132(7.857) | Loss -59.423(-59.530) | NFE Forward 68(66.5) | NFE Backward 87(83.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 510 | Time 6.690(6.872) | Loss -34.543(-33.899) | NFE Forward 56(58.2) | NFE Backward 69(69.9) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -34.319 | NFE 56 | NoImproveEpochs 00/16 [*]
Epoch 1 | Iter 460 | Time 7.791(7.831) | Loss -60.069(-59.540) | NFE Forward 68(66.1) | NFE Backward 81(82.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 520 | Time 6.642(7.445) | Loss -34.422(-34.095) | NFE Forward 56(57.6) | NFE Backward 69(69.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 470 | Time 7.808(7.835) | Loss -60.124(-59.607) | NFE Forward 68(66.7) | NFE Backward 81(82.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 530 | Time 6.695(7.271) | Loss -34.132(-34.085) | NFE Forward 56(57.3) | NFE Backward 69(70.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 480 | Time 7.834(7.809) | Loss -59.889(-59.648) | NFE Forward 68(67.2) | NFE Backward 81(81.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 540 | Time 6.642(7.061) | Loss -35.652(-34.420) | NFE Forward 56(56.8) | NFE Backward 69(69.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 550 | Time 6.667(6.975) | Loss -35.627(-34.724) | NFE Forward 56(56.6) | NFE Backward 69(69.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 490 | Time 8.163(7.834) | Loss -58.925(-59.434) | NFE Forward 68(67.4) | NFE Backward 87(82.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 560 | Time 6.754(6.907) | Loss -35.781(-34.916) | NFE Forward 56(56.4) | NFE Backward 69(69.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 500 | Time 7.823(7.850) | Loss -59.009(-59.296) | NFE Forward 68(67.5) | NFE Backward 81(82.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 570 | Time 6.654(6.819) | Loss -35.765(-35.183) | NFE Forward 56(56.2) | NFE Backward 69(69.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 510 | Time 7.820(7.893) | Loss -60.358(-59.379) | NFE Forward 68(67.6) | NFE Backward 81(82.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 580 | Time 6.654(6.865) | Loss -35.325(-35.094) | NFE Forward 56(56.2) | NFE Backward 69(70.8) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -57.981 | NFE 68 | NoImproveEpochs 02/16
Epoch 1 | Iter 520 | Time 8.227(8.721) | Loss -60.035(-59.490) | NFE Forward 68(67.8) | NFE Backward 87(83.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 590 | Time 7.158(6.924) | Loss -35.259(-35.222) | NFE Forward 56(56.1) | NFE Backward 75(71.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 600 | Time 6.649(6.910) | Loss -36.531(-35.370) | NFE Forward 56(56.1) | NFE Backward 69(71.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 530 | Time 7.810(8.444) | Loss -60.850(-59.639) | NFE Forward 68(67.8) | NFE Backward 81(82.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 610 | Time 6.772(6.825) | Loss -36.481(-35.649) | NFE Forward 56(56.0) | NFE Backward 69(70.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 540 | Time 7.802(8.258) | Loss -60.755(-59.749) | NFE Forward 68(67.9) | NFE Backward 81(82.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 620 | Time 6.707(6.780) | Loss -36.396(-36.032) | NFE Forward 56(56.0) | NFE Backward 69(70.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 550 | Time 7.781(8.148) | Loss -59.080(-59.743) | NFE Forward 68(67.9) | NFE Backward 81(82.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 630 | Time 6.813(6.855) | Loss -36.527(-36.172) | NFE Forward 56(56.0) | NFE Backward 69(70.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 560 | Time 8.228(8.080) | Loss -58.548(-59.751) | NFE Forward 68(68.0) | NFE Backward 87(82.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 640 | Time 6.679(6.852) | Loss -36.794(-36.402) | NFE Forward 56(56.0) | NFE Backward 69(70.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 570 | Time 8.630(8.073) | Loss -58.126(-59.513) | NFE Forward 68(68.0) | NFE Backward 93(83.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 650 | Time 7.182(6.903) | Loss -36.097(-36.512) | NFE Forward 56(56.0) | NFE Backward 75(71.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 580 | Time 8.169(8.040) | Loss -60.935(-59.486) | NFE Forward 68(67.5) | NFE Backward 87(83.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 660 | Time 7.062(6.930) | Loss -36.266(-36.371) | NFE Forward 56(56.0) | NFE Backward 75(72.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 670 | Time 7.166(6.945) | Loss -37.113(-36.560) | NFE Forward 56(56.0) | NFE Backward 75(72.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 590 | Time 7.852(7.997) | Loss -60.999(-59.867) | NFE Forward 68(67.7) | NFE Backward 81(83.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 680 | Time 6.793(6.904) | Loss -37.066(-36.743) | NFE Forward 56(56.0) | NFE Backward 69(71.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 600 | Time 7.811(7.912) | Loss -61.428(-60.028) | NFE Forward 68(67.1) | NFE Backward 81(82.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 690 | Time 7.039(6.910) | Loss -37.120(-36.793) | NFE Forward 56(56.0) | NFE Backward 75(72.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 610 | Time 8.253(7.899) | Loss -60.042(-60.103) | NFE Forward 68(67.0) | NFE Backward 87(82.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 700 | Time 7.076(6.907) | Loss -36.157(-36.843) | NFE Forward 56(56.0) | NFE Backward 75(72.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 620 | Time 7.813(7.944) | Loss -59.038(-59.955) | NFE Forward 68(67.2) | NFE Backward 81(83.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 710 | Time 7.056(6.926) | Loss -37.897(-36.976) | NFE Forward 56(56.0) | NFE Backward 75(72.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 630 | Time 7.785(7.957) | Loss -59.337(-59.750) | NFE Forward 68(67.4) | NFE Backward 81(83.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 720 | Time 7.012(6.978) | Loss -37.501(-37.075) | NFE Forward 56(56.0) | NFE Backward 75(73.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 640 | Time 7.809(7.958) | Loss -59.299(-59.733) | NFE Forward 68(67.3) | NFE Backward 81(83.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 730 | Time 6.630(6.982) | Loss -38.052(-37.115) | NFE Forward 56(56.0) | NFE Backward 69(73.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 650 | Time 8.219(7.973) | Loss -60.107(-59.807) | NFE Forward 68(67.5) | NFE Backward 87(83.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 740 | Time 6.793(6.989) | Loss -37.111(-37.167) | NFE Forward 56(56.0) | NFE Backward 69(73.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 750 | Time 7.051(7.005) | Loss -37.185(-37.246) | NFE Forward 56(56.0) | NFE Backward 75(73.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 660 | Time 7.390(7.952) | Loss -60.684(-59.943) | NFE Forward 56(66.9) | NFE Backward 81(83.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 760 | Time 7.147(7.039) | Loss -36.542(-37.239) | NFE Forward 56(56.0) | NFE Backward 75(73.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 670 | Time 8.219(7.942) | Loss -60.491(-59.814) | NFE Forward 68(66.5) | NFE Backward 87(83.5) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -37.424 | NFE 56 | NoImproveEpochs 00/16 [*]
Epoch 1 | Iter 680 | Time 8.235(7.976) | Loss -60.548(-59.749) | NFE Forward 68(67.0) | NFE Backward 87(83.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 770 | Time 7.076(7.826) | Loss -38.170(-37.408) | NFE Forward 56(56.0) | NFE Backward 75(74.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 780 | Time 6.778(7.523) | Loss -38.633(-37.608) | NFE Forward 56(56.0) | NFE Backward 69(73.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 690 | Time 8.181(7.997) | Loss -59.175(-59.609) | NFE Forward 68(67.0) | NFE Backward 87(84.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 790 | Time 7.184(7.373) | Loss -38.188(-37.768) | NFE Forward 56(56.0) | NFE Backward 75(73.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 700 | Time 7.850(7.915) | Loss -59.582(-59.821) | NFE Forward 68(66.7) | NFE Backward 81(83.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 800 | Time 7.040(7.269) | Loss -37.815(-37.843) | NFE Forward 56(56.0) | NFE Backward 75(73.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 710 | Time 7.813(7.880) | Loss -61.859(-59.992) | NFE Forward 68(67.1) | NFE Backward 81(82.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 810 | Time 7.025(7.213) | Loss -38.242(-37.549) | NFE Forward 56(56.0) | NFE Backward 75(73.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 720 | Time 8.198(7.917) | Loss -60.173(-60.035) | NFE Forward 68(67.4) | NFE Backward 87(83.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 820 | Time 6.787(7.170) | Loss -38.456(-37.490) | NFE Forward 56(56.0) | NFE Backward 69(74.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 730 | Time 7.776(7.960) | Loss -59.142(-60.025) | NFE Forward 68(67.6) | NFE Backward 81(83.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 830 | Time 7.052(7.146) | Loss -38.392(-37.494) | NFE Forward 56(56.0) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 740 | Time 8.197(7.958) | Loss -60.166(-60.152) | NFE Forward 68(67.3) | NFE Backward 87(83.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 840 | Time 7.214(7.102) | Loss -39.294(-37.806) | NFE Forward 56(56.0) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 750 | Time 7.825(7.924) | Loss -61.487(-60.294) | NFE Forward 68(67.1) | NFE Backward 81(83.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 850 | Time 7.186(7.113) | Loss -39.142(-38.045) | NFE Forward 56(56.0) | NFE Backward 75(74.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 760 | Time 7.794(7.918) | Loss -59.823(-60.292) | NFE Forward 68(66.7) | NFE Backward 81(83.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 860 | Time 6.733(7.093) | Loss -38.845(-38.169) | NFE Forward 56(56.0) | NFE Backward 69(74.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 870 | Time 7.045(7.066) | Loss -37.686(-38.257) | NFE Forward 56(56.0) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -57.540 | NFE 68 | NoImproveEpochs 03/16
Epoch 1 | Iter 770 | Time 7.791(8.935) | Loss -58.772(-60.150) | NFE Forward 68(67.1) | NFE Backward 81(83.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 880 | Time 7.171(7.090) | Loss -37.611(-38.254) | NFE Forward 56(56.0) | NFE Backward 75(74.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 780 | Time 7.819(8.634) | Loss -60.217(-59.992) | NFE Forward 68(67.4) | NFE Backward 81(84.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 890 | Time 7.047(7.090) | Loss -38.509(-38.307) | NFE Forward 56(56.0) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 790 | Time 7.785(8.336) | Loss -60.091(-59.986) | NFE Forward 68(66.8) | NFE Backward 81(83.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 900 | Time 7.082(7.097) | Loss -39.051(-38.260) | NFE Forward 56(56.0) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 800 | Time 8.213(8.179) | Loss -59.583(-59.984) | NFE Forward 68(66.8) | NFE Backward 87(83.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 910 | Time 7.141(7.066) | Loss -38.873(-38.422) | NFE Forward 56(56.0) | NFE Backward 75(74.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 810 | Time 8.210(8.127) | Loss -61.589(-60.392) | NFE Forward 68(67.2) | NFE Backward 87(83.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 920 | Time 7.174(7.103) | Loss -39.306(-38.516) | NFE Forward 56(56.0) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 930 | Time 6.617(7.029) | Loss -39.986(-38.771) | NFE Forward 56(56.0) | NFE Backward 69(73.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 820 | Time 8.239(8.072) | Loss -61.037(-60.708) | NFE Forward 68(67.2) | NFE Backward 87(83.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 940 | Time 7.172(7.052) | Loss -37.544(-38.808) | NFE Forward 56(56.0) | NFE Backward 75(74.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 830 | Time 8.164(8.082) | Loss -60.382(-60.536) | NFE Forward 68(67.5) | NFE Backward 87(84.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 950 | Time 7.038(7.057) | Loss -39.213(-38.909) | NFE Forward 56(56.0) | NFE Backward 75(74.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 840 | Time 8.187(8.081) | Loss -60.783(-60.423) | NFE Forward 68(67.2) | NFE Backward 87(84.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 960 | Time 7.010(7.089) | Loss -38.526(-38.847) | NFE Forward 56(56.0) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 850 | Time 8.227(8.041) | Loss -60.300(-60.337) | NFE Forward 68(67.1) | NFE Backward 87(84.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 970 | Time 7.171(7.080) | Loss -39.571(-38.993) | NFE Forward 56(56.0) | NFE Backward 75(74.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 860 | Time 7.814(8.047) | Loss -60.108(-60.390) | NFE Forward 68(67.0) | NFE Backward 81(84.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 980 | Time 7.141(7.098) | Loss -39.670(-39.106) | NFE Forward 56(56.0) | NFE Backward 75(74.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 870 | Time 8.139(8.053) | Loss -60.206(-60.196) | NFE Forward 68(67.4) | NFE Backward 87(84.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 990 | Time 7.177(7.125) | Loss -39.041(-39.226) | NFE Forward 56(56.0) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 880 | Time 7.776(7.983) | Loss -61.547(-60.233) | NFE Forward 68(67.6) | NFE Backward 81(84.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1000 | Time 7.185(7.143) | Loss -39.120(-39.208) | NFE Forward 56(56.0) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 890 | Time 7.846(7.905) | Loss -60.193(-60.116) | NFE Forward 68(67.0) | NFE Backward 81(83.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1010 | Time 7.162(7.149) | Loss -40.264(-39.285) | NFE Forward 56(56.0) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1020 | Time 7.207(7.158) | Loss -39.560(-39.257) | NFE Forward 56(56.0) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 900 | Time 8.195(7.910) | Loss -60.244(-60.129) | NFE Forward 68(66.6) | NFE Backward 87(83.4) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -38.086 | NFE 56 | NoImproveEpochs 00/16 [*]
Epoch 1 | Iter 910 | Time 8.207(7.934) | Loss -60.453(-60.390) | NFE Forward 68(66.4) | NFE Backward 87(83.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1030 | Time 7.000(7.809) | Loss -38.148(-39.010) | NFE Forward 56(56.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 920 | Time 8.201(7.935) | Loss -60.599(-60.182) | NFE Forward 68(66.6) | NFE Backward 87(83.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1040 | Time 7.039(7.553) | Loss -39.484(-39.002) | NFE Forward 56(56.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1050 | Time 7.052(7.379) | Loss -38.964(-39.089) | NFE Forward 56(56.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 930 | Time 7.834(7.931) | Loss -60.490(-60.320) | NFE Forward 68(67.0) | NFE Backward 81(83.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1060 | Time 7.083(7.292) | Loss -39.920(-39.232) | NFE Forward 56(56.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 940 | Time 8.184(7.967) | Loss -59.296(-60.354) | NFE Forward 68(67.0) | NFE Backward 87(83.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1070 | Time 7.067(7.223) | Loss -40.656(-39.460) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 950 | Time 7.805(7.933) | Loss -60.646(-60.450) | NFE Forward 68(67.4) | NFE Backward 81(83.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1080 | Time 7.043(7.173) | Loss -39.370(-39.479) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 960 | Time 7.807(7.901) | Loss -59.872(-60.522) | NFE Forward 68(67.0) | NFE Backward 81(82.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1090 | Time 7.185(7.181) | Loss -40.081(-39.705) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 970 | Time 7.778(7.938) | Loss -59.441(-60.120) | NFE Forward 56(66.5) | NFE Backward 87(83.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1100 | Time 7.231(7.185) | Loss -39.031(-39.794) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 980 | Time 8.253(7.948) | Loss -60.172(-60.035) | NFE Forward 68(66.4) | NFE Backward 87(83.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1110 | Time 7.148(7.162) | Loss -39.959(-39.965) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 990 | Time 7.800(7.880) | Loss -60.582(-60.095) | NFE Forward 68(66.1) | NFE Backward 81(83.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1120 | Time 7.229(7.173) | Loss -41.423(-40.168) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1000 | Time 7.801(7.850) | Loss -60.682(-60.323) | NFE Forward 68(66.3) | NFE Backward 81(82.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1130 | Time 7.225(7.159) | Loss -41.143(-40.312) | NFE Forward 56(56.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1010 | Time 7.760(7.952) | Loss -59.251(-60.546) | NFE Forward 68(66.9) | NFE Backward 81(83.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1140 | Time 7.154(7.164) | Loss -40.169(-40.302) | NFE Forward 56(56.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1150 | Time 7.217(7.174) | Loss -39.651(-40.293) | NFE Forward 56(56.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1020 | Time 8.221(7.989) | Loss -60.478(-60.410) | NFE Forward 68(67.3) | NFE Backward 87(84.3) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -58.996 | NFE 68 | NoImproveEpochs 00/16
Epoch 0 | Iter 1160 | Time 7.014(7.158) | Loss -41.052(-40.455) | NFE Forward 56(56.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1030 | Time 7.732(8.780) | Loss -60.253(-60.417) | NFE Forward 68(67.5) | NFE Backward 81(83.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1170 | Time 7.188(7.120) | Loss -41.540(-40.680) | NFE Forward 56(56.1) | NFE Backward 75(74.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1040 | Time 8.198(8.535) | Loss -61.631(-60.595) | NFE Forward 68(67.2) | NFE Backward 87(84.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1180 | Time 7.022(7.137) | Loss -39.856(-40.576) | NFE Forward 56(56.2) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1050 | Time 8.230(8.402) | Loss -60.579(-60.689) | NFE Forward 68(67.5) | NFE Backward 87(84.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1190 | Time 7.159(7.150) | Loss -39.623(-40.317) | NFE Forward 56(56.3) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1060 | Time 7.831(8.312) | Loss -60.001(-60.540) | NFE Forward 68(67.7) | NFE Backward 81(85.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1200 | Time 7.136(7.145) | Loss -40.702(-40.385) | NFE Forward 56(56.4) | NFE Backward 75(74.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1210 | Time 7.081(7.129) | Loss -40.573(-40.511) | NFE Forward 56(56.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1070 | Time 7.825(8.248) | Loss -61.594(-60.768) | NFE Forward 68(67.8) | NFE Backward 81(85.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1220 | Time 7.233(7.138) | Loss -40.278(-40.551) | NFE Forward 62(56.6) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1080 | Time 8.237(8.238) | Loss -60.868(-60.811) | NFE Forward 68(67.9) | NFE Backward 87(85.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1230 | Time 7.040(7.135) | Loss -40.605(-40.554) | NFE Forward 56(56.8) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1090 | Time 7.863(8.166) | Loss -60.442(-60.682) | NFE Forward 68(67.9) | NFE Backward 81(85.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1240 | Time 7.027(7.104) | Loss -41.068(-40.686) | NFE Forward 56(56.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1100 | Time 8.104(8.149) | Loss -60.000(-60.534) | NFE Forward 68(67.9) | NFE Backward 87(85.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1250 | Time 7.035(7.110) | Loss -41.141(-40.903) | NFE Forward 56(56.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1110 | Time 7.663(8.064) | Loss -60.317(-60.681) | NFE Forward 68(67.8) | NFE Backward 81(84.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1260 | Time 7.352(7.143) | Loss -40.823(-40.960) | NFE Forward 62(57.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1120 | Time 8.190(8.047) | Loss -59.966(-60.657) | NFE Forward 68(67.8) | NFE Backward 87(84.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1270 | Time 7.148(7.173) | Loss -39.173(-40.697) | NFE Forward 56(57.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1130 | Time 8.187(8.031) | Loss -60.466(-60.542) | NFE Forward 68(67.4) | NFE Backward 87(84.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1280 | Time 7.408(7.174) | Loss -39.951(-40.796) | NFE Forward 62(57.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -40.162 | NFE 61 | NoImproveEpochs 00/16 [*]
Epoch 1 | Iter 1140 | Time 8.213(8.046) | Loss -60.838(-60.545) | NFE Forward 68(67.2) | NFE Backward 87(85.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1290 | Time 7.148(7.789) | Loss -41.001(-40.943) | NFE Forward 56(57.2) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1150 | Time 8.244(8.087) | Loss -60.594(-60.613) | NFE Forward 68(67.1) | NFE Backward 87(85.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1300 | Time 7.025(7.577) | Loss -40.463(-40.996) | NFE Forward 56(56.8) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1160 | Time 8.227(8.058) | Loss -59.878(-60.612) | NFE Forward 68(66.7) | NFE Backward 87(85.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1310 | Time 7.411(7.432) | Loss -41.678(-41.245) | NFE Forward 62(57.0) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1320 | Time 7.134(7.350) | Loss -42.486(-41.365) | NFE Forward 56(56.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1170 | Time 8.246(8.062) | Loss -60.521(-60.571) | NFE Forward 68(66.3) | NFE Backward 87(85.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1330 | Time 7.167(7.292) | Loss -41.180(-41.381) | NFE Forward 56(57.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1180 | Time 8.203(8.057) | Loss -60.298(-60.707) | NFE Forward 68(66.1) | NFE Backward 87(85.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1340 | Time 7.166(7.274) | Loss -41.838(-41.445) | NFE Forward 56(57.5) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1190 | Time 8.206(8.012) | Loss -60.942(-60.618) | NFE Forward 68(65.5) | NFE Backward 87(85.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1350 | Time 7.104(7.269) | Loss -42.263(-41.456) | NFE Forward 56(58.0) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1200 | Time 8.212(8.042) | Loss -61.206(-60.740) | NFE Forward 68(66.4) | NFE Backward 87(85.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1360 | Time 7.187(7.223) | Loss -41.628(-41.562) | NFE Forward 56(57.9) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1210 | Time 7.798(8.054) | Loss -59.936(-60.543) | NFE Forward 68(66.9) | NFE Backward 81(85.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1370 | Time 7.043(7.182) | Loss -41.685(-41.651) | NFE Forward 56(57.5) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1220 | Time 8.606(8.095) | Loss -61.190(-60.501) | NFE Forward 68(66.8) | NFE Backward 93(86.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1380 | Time 7.157(7.187) | Loss -41.276(-41.517) | NFE Forward 56(57.4) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1230 | Time 8.168(8.098) | Loss -61.219(-60.654) | NFE Forward 68(66.9) | NFE Backward 87(85.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1390 | Time 7.034(7.162) | Loss -42.308(-41.670) | NFE Forward 56(57.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1240 | Time 7.790(8.090) | Loss -60.382(-60.861) | NFE Forward 56(66.8) | NFE Backward 87(85.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1400 | Time 7.045(7.144) | Loss -41.523(-41.815) | NFE Forward 56(57.3) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1410 | Time 7.024(7.120) | Loss -42.194(-41.957) | NFE Forward 56(57.1) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1250 | Time 8.220(8.090) | Loss -60.903(-60.815) | NFE Forward 68(66.5) | NFE Backward 87(86.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1420 | Time 7.066(7.160) | Loss -42.263(-42.075) | NFE Forward 56(57.7) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1260 | Time 8.089(8.096) | Loss -61.858(-60.915) | NFE Forward 68(67.0) | NFE Backward 87(86.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1430 | Time 7.271(7.181) | Loss -41.924(-42.152) | NFE Forward 62(58.4) | NFE Backward 75(75.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1270 | Time 8.213(8.099) | Loss -60.690(-60.830) | NFE Forward 68(66.9) | NFE Backward 87(86.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1440 | Time 7.168(7.218) | Loss -42.963(-42.079) | NFE Forward 56(58.8) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1280 | Time 8.203(8.119) | Loss -61.199(-60.919) | NFE Forward 68(67.3) | NFE Backward 87(86.2) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -60.375 | NFE 68 | NoImproveEpochs 00/16
Epoch 0 | Iter 1450 | Time 7.403(7.232) | Loss -42.806(-42.183) | NFE Forward 62(58.6) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1290 | Time 8.111(8.855) | Loss -59.435(-60.975) | NFE Forward 68(67.5) | NFE Backward 87(86.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1460 | Time 7.305(7.265) | Loss -42.950(-42.322) | NFE Forward 62(59.4) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1300 | Time 6.962(8.534) | Loss -59.138(-60.702) | NFE Forward 56(66.8) | NFE Backward 75(85.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1470 | Time 7.272(7.257) | Loss -42.168(-42.364) | NFE Forward 62(59.7) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1480 | Time 7.382(7.260) | Loss -41.600(-42.423) | NFE Forward 62(59.5) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1310 | Time 7.776(8.370) | Loss -59.324(-60.700) | NFE Forward 68(67.2) | NFE Backward 81(85.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1490 | Time 7.415(7.288) | Loss -42.976(-42.326) | NFE Forward 62(60.0) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1320 | Time 7.760(8.228) | Loss -60.172(-60.379) | NFE Forward 56(65.9) | NFE Backward 87(85.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1500 | Time 7.335(7.285) | Loss -42.249(-42.198) | NFE Forward 62(60.0) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1330 | Time 7.834(8.158) | Loss -59.934(-60.272) | NFE Forward 68(65.4) | NFE Backward 81(85.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1510 | Time 7.279(7.259) | Loss -42.616(-42.473) | NFE Forward 62(59.7) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1340 | Time 8.219(8.107) | Loss -60.077(-60.309) | NFE Forward 68(65.4) | NFE Backward 87(85.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1520 | Time 7.169(7.227) | Loss -43.993(-42.749) | NFE Forward 56(58.8) | NFE Backward 75(75.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1350 | Time 7.361(7.944) | Loss -61.285(-60.490) | NFE Forward 56(63.9) | NFE Backward 81(84.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1530 | Time 7.226(7.231) | Loss -42.648(-42.737) | NFE Forward 62(59.1) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1360 | Time 8.206(7.967) | Loss -61.846(-60.764) | NFE Forward 68(64.5) | NFE Backward 87(84.6) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -42.153 | NFE 62 | NoImproveEpochs 00/16 [*]
Epoch 0 | Iter 1540 | Time 7.225(8.030) | Loss -41.055(-42.597) | NFE Forward 62(59.9) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1370 | Time 8.174(8.029) | Loss -62.657(-61.022) | NFE Forward 68(65.7) | NFE Backward 87(85.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1550 | Time 7.314(7.820) | Loss -42.343(-42.654) | NFE Forward 62(60.6) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1380 | Time 8.201(8.087) | Loss -60.548(-60.966) | NFE Forward 68(66.4) | NFE Backward 87(85.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1560 | Time 7.049(7.584) | Loss -42.264(-42.780) | NFE Forward 56(59.9) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1390 | Time 7.824(8.046) | Loss -61.021(-60.959) | NFE Forward 68(66.2) | NFE Backward 81(85.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1570 | Time 7.756(7.506) | Loss -42.818(-42.739) | NFE Forward 62(60.1) | NFE Backward 81(75.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1400 | Time 8.227(8.031) | Loss -61.076(-60.953) | NFE Forward 68(65.7) | NFE Backward 87(85.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1580 | Time 7.239(7.457) | Loss -41.960(-42.664) | NFE Forward 62(60.7) | NFE Backward 75(75.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1410 | Time 8.210(8.074) | Loss -60.657(-61.017) | NFE Forward 68(66.5) | NFE Backward 87(85.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1590 | Time 7.200(7.402) | Loss -43.213(-42.754) | NFE Forward 56(60.7) | NFE Backward 75(75.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1420 | Time 8.252(8.065) | Loss -59.669(-60.947) | NFE Forward 68(65.8) | NFE Backward 87(85.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1600 | Time 7.018(7.367) | Loss -44.461(-42.870) | NFE Forward 56(60.5) | NFE Backward 75(75.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1430 | Time 8.163(8.052) | Loss -61.650(-60.836) | NFE Forward 68(66.6) | NFE Backward 87(85.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1610 | Time 7.288(7.386) | Loss -42.450(-42.951) | NFE Forward 62(60.7) | NFE Backward 75(75.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1620 | Time 7.390(7.420) | Loss -42.609(-42.956) | NFE Forward 62(61.1) | NFE Backward 75(75.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1440 | Time 8.223(8.102) | Loss -60.503(-60.900) | NFE Forward 68(67.0) | NFE Backward 87(85.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1630 | Time 7.284(7.371) | Loss -42.358(-43.009) | NFE Forward 62(61.2) | NFE Backward 75(75.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1450 | Time 8.111(8.114) | Loss -61.097(-60.814) | NFE Forward 68(67.0) | NFE Backward 87(86.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1640 | Time 7.345(7.339) | Loss -43.950(-43.174) | NFE Forward 62(60.9) | NFE Backward 75(75.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1460 | Time 8.071(8.110) | Loss -61.845(-61.022) | NFE Forward 68(66.9) | NFE Backward 87(86.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1650 | Time 7.234(7.354) | Loss -42.094(-43.253) | NFE Forward 62(60.8) | NFE Backward 75(75.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1470 | Time 7.842(8.059) | Loss -59.618(-61.109) | NFE Forward 68(66.9) | NFE Backward 81(86.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1660 | Time 7.653(7.349) | Loss -44.638(-43.390) | NFE Forward 62(60.9) | NFE Backward 81(75.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1480 | Time 7.783(7.962) | Loss -61.626(-61.016) | NFE Forward 56(65.2) | NFE Backward 87(85.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1670 | Time 7.270(7.318) | Loss -43.978(-43.480) | NFE Forward 62(60.9) | NFE Backward 75(75.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1490 | Time 7.809(7.952) | Loss -61.283(-61.004) | NFE Forward 56(65.3) | NFE Backward 87(85.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1680 | Time 7.245(7.330) | Loss -44.104(-43.586) | NFE Forward 62(61.3) | NFE Backward 75(75.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1500 | Time 8.257(8.039) | Loss -62.544(-61.098) | NFE Forward 68(65.8) | NFE Backward 87(85.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1690 | Time 7.092(7.289) | Loss -44.293(-43.694) | NFE Forward 56(61.1) | NFE Backward 75(75.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1510 | Time 8.179(8.067) | Loss -61.113(-61.117) | NFE Forward 68(66.1) | NFE Backward 87(86.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1700 | Time 7.255(7.312) | Loss -44.213(-43.725) | NFE Forward 62(61.2) | NFE Backward 75(75.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1520 | Time 8.215(8.099) | Loss -61.871(-61.316) | NFE Forward 68(66.7) | NFE Backward 87(86.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1710 | Time 7.278(7.336) | Loss -44.142(-43.956) | NFE Forward 62(61.5) | NFE Backward 75(76.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1530 | Time 8.223(8.105) | Loss -61.272(-61.467) | NFE Forward 68(66.4) | NFE Backward 87(86.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1720 | Time 7.273(7.349) | Loss -42.990(-43.899) | NFE Forward 62(61.6) | NFE Backward 75(76.1) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -59.122 | NFE 66 | NoImproveEpochs 01/16
Epoch 0 | Iter 1730 | Time 7.374(7.368) | Loss -43.486(-43.802) | NFE Forward 62(61.8) | NFE Backward 75(75.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1540 | Time 8.524(8.990) | Loss -58.801(-61.033) | NFE Forward 68(66.4) | NFE Backward 93(86.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1740 | Time 7.665(7.381) | Loss -44.712(-43.935) | NFE Forward 62(61.8) | NFE Backward 81(76.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1550 | Time 8.231(8.701) | Loss -61.577(-61.070) | NFE Forward 68(66.9) | NFE Backward 87(86.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1750 | Time 7.701(7.404) | Loss -45.084(-43.990) | NFE Forward 62(61.9) | NFE Backward 81(76.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1560 | Time 8.209(8.530) | Loss -61.770(-61.290) | NFE Forward 68(67.3) | NFE Backward 87(86.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1760 | Time 7.065(7.376) | Loss -44.784(-44.150) | NFE Forward 56(61.5) | NFE Backward 75(76.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1570 | Time 8.267(8.401) | Loss -61.781(-61.380) | NFE Forward 68(67.1) | NFE Backward 87(86.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1770 | Time 7.837(7.408) | Loss -45.130(-44.245) | NFE Forward 62(61.7) | NFE Backward 81(76.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1580 | Time 7.791(8.316) | Loss -61.046(-61.267) | NFE Forward 68(67.2) | NFE Backward 81(86.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1780 | Time 7.637(7.451) | Loss -44.507(-44.375) | NFE Forward 62(61.8) | NFE Backward 81(77.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1590 | Time 8.572(8.281) | Loss -60.736(-61.093) | NFE Forward 68(67.1) | NFE Backward 93(86.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1790 | Time 7.370(7.448) | Loss -43.595(-44.378) | NFE Forward 62(61.9) | NFE Backward 75(77.0) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss -43.749 | NFE 62 | NoImproveEpochs 00/16 [*]
Epoch 1 | Iter 1600 | Time 8.166(8.246) | Loss -60.531(-61.078) | NFE Forward 68(67.2) | NFE Backward 87(86.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1800 | Time 7.785(8.150) | Loss -43.869(-44.375) | NFE Forward 62(61.9) | NFE Backward 81(77.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1610 | Time 8.095(8.227) | Loss -61.317(-61.212) | NFE Forward 68(67.5) | NFE Backward 87(87.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1810 | Time 7.422(7.906) | Loss -45.251(-44.515) | NFE Forward 62(61.9) | NFE Backward 75(76.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1620 | Time 7.659(8.175) | Loss -61.106(-61.172) | NFE Forward 56(67.2) | NFE Backward 87(87.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1820 | Time 7.312(7.782) | Loss -43.853(-44.403) | NFE Forward 62(62.0) | NFE Backward 75(76.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1630 | Time 8.207(8.127) | Loss -61.871(-61.373) | NFE Forward 68(66.6) | NFE Backward 87(86.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1830 | Time 7.290(7.633) | Loss -44.322(-44.484) | NFE Forward 62(62.0) | NFE Backward 75(76.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1840 | Time 7.686(7.545) | Loss -45.815(-44.536) | NFE Forward 62(62.0) | NFE Backward 81(76.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1640 | Time 8.032(8.162) | Loss -61.653(-61.244) | NFE Forward 62(66.8) | NFE Backward 87(87.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1850 | Time 7.862(7.540) | Loss -45.438(-44.662) | NFE Forward 62(62.0) | NFE Backward 81(76.6) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1650 | Time 8.215(8.110) | Loss -61.674(-61.352) | NFE Forward 68(66.1) | NFE Backward 87(86.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1860 | Time 7.666(7.557) | Loss -45.152(-44.717) | NFE Forward 62(62.0) | NFE Backward 81(77.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1660 | Time 8.186(8.118) | Loss -61.530(-61.588) | NFE Forward 68(66.3) | NFE Backward 87(86.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1870 | Time 7.245(7.482) | Loss -45.245(-44.869) | NFE Forward 62(62.0) | NFE Backward 75(76.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1670 | Time 8.063(8.132) | Loss -61.825(-61.395) | NFE Forward 68(66.5) | NFE Backward 87(86.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1880 | Time 7.251(7.430) | Loss -43.234(-44.561) | NFE Forward 62(62.0) | NFE Backward 75(76.7) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1680 | Time 8.218(8.145) | Loss -61.366(-61.159) | NFE Forward 68(66.8) | NFE Backward 87(87.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1890 | Time 7.355(7.472) | Loss -44.125(-44.461) | NFE Forward 62(62.0) | NFE Backward 75(77.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1690 | Time 7.815(8.085) | Loss -61.508(-61.259) | NFE Forward 56(66.0) | NFE Backward 87(86.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1900 | Time 7.657(7.450) | Loss -44.835(-44.500) | NFE Forward 62(62.0) | NFE Backward 81(76.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1700 | Time 7.776(7.961) | Loss -61.619(-61.520) | NFE Forward 56(64.6) | NFE Backward 87(85.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1910 | Time 7.384(7.459) | Loss -45.076(-44.521) | NFE Forward 62(62.0) | NFE Backward 75(76.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1710 | Time 8.218(8.065) | Loss -61.565(-61.383) | NFE Forward 68(65.7) | NFE Backward 87(86.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 1920 | Time 7.378(7.477) | Loss -45.405(-44.654) | NFE Forward 62(62.0) | NFE Backward 75(76.8) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=256, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
Epoch 1 | Iter 1720 | Time 7.767(8.072) | Loss -60.822(-61.311) | NFE Forward 56(65.6) | NFE Backward 87(86.2) | CNF Time 1.000(1.000)
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 4.156(4.156) | Loss 37.495(37.495) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1730 | Time 7.803(8.031) | Loss -60.928(-61.289) | NFE Forward 68(65.2) | NFE Backward 81(85.8) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss 37.073 | NFE 20 | NoImproveEpochs 00/16 [*]
Epoch 0 | Iter 10 | Time 2.629(6.453) | Loss 35.601(37.016) | NFE Forward 20(20.0) | NFE Backward 27(22.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1740 | Time 7.783(7.980) | Loss -61.164(-61.069) | NFE Forward 56(64.5) | NFE Backward 87(85.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 3.261(5.263) | Loss 34.664(36.375) | NFE Forward 26(21.7) | NFE Backward 33(24.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 3.282(4.597) | Loss 32.471(35.443) | NFE Forward 26(23.1) | NFE Backward 33(27.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 2.862(4.053) | Loss 27.294(33.508) | NFE Forward 26(24.1) | NFE Backward 27(27.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1750 | Time 8.220(7.954) | Loss -62.600(-61.371) | NFE Forward 68(63.7) | NFE Backward 87(85.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 50 | Time 4.663(4.013) | Loss 21.456(30.209) | NFE Forward 32(26.7) | NFE Backward 51(31.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 60 | Time 4.672(4.033) | Loss 15.530(26.017) | NFE Forward 32(28.5) | NFE Backward 51(35.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1760 | Time 8.019(7.979) | Loss -61.413(-61.512) | NFE Forward 62(63.8) | NFE Backward 87(85.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 70 | Time 5.093(4.300) | Loss 10.542(21.420) | NFE Forward 44(31.6) | NFE Backward 51(40.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1770 | Time 8.192(8.034) | Loss -62.526(-61.592) | NFE Forward 68(64.6) | NFE Backward 87(86.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 80 | Time 4.860(4.533) | Loss 6.111(16.891) | NFE Forward 38(34.3) | NFE Backward 51(44.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 90 | Time 5.277(4.769) | Loss 2.381(12.581) | NFE Forward 38(36.0) | NFE Backward 57(48.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1780 | Time 8.283(8.103) | Loss -62.491(-61.684) | NFE Forward 68(65.8) | NFE Backward 87(86.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 100 | Time 5.603(5.040) | Loss -0.186(8.571) | NFE Forward 50(39.3) | NFE Backward 57(51.1) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1790 | Time 8.250(8.129) | Loss -62.428(-61.331) | NFE Forward 68(66.1) | NFE Backward 87(86.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 110 | Time 5.196(5.163) | Loss -2.934(5.017) | NFE Forward 38(40.9) | NFE Backward 57(53.1) | CNF Time 1.000(1.000)
[VAL] Epoch 1 | Val Loss -57.752 | NFE 67 | NoImproveEpochs 02/16
Epoch 0 | Iter 120 | Time 5.613(5.284) | Loss -5.821(1.699) | NFE Forward 50(43.0) | NFE Backward 57(54.4) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1800 | Time 8.203(8.857) | Loss -61.853(-61.314) | NFE Forward 68(65.3) | NFE Backward 87(86.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 130 | Time 5.711(5.421) | Loss -8.268(-1.135) | NFE Forward 50(45.3) | NFE Backward 57(55.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 140 | Time 6.143(5.584) | Loss -9.510(-3.711) | NFE Forward 50(46.9) | NFE Backward 63(56.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1810 | Time 7.843(8.614) | Loss -60.883(-61.239) | NFE Forward 56(65.4) | NFE Backward 87(86.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 150 | Time 6.155(5.768) | Loss -11.015(-5.840) | NFE Forward 50(47.9) | NFE Backward 63(58.9) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1820 | Time 8.014(8.469) | Loss -61.953(-61.506) | NFE Forward 62(65.8) | NFE Backward 87(86.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 160 | Time 6.066(5.872) | Loss -12.869(-7.873) | NFE Forward 50(48.6) | NFE Backward 63(60.3) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1830 | Time 8.005(8.332) | Loss -61.970(-61.764) | NFE Forward 62(65.2) | NFE Backward 87(86.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 170 | Time 6.062(5.937) | Loss -14.110(-9.847) | NFE Forward 50(49.1) | NFE Backward 63(61.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 180 | Time 5.971(5.968) | Loss -16.701(-11.767) | NFE Forward 50(49.4) | NFE Backward 63(61.8) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1840 | Time 7.816(8.247) | Loss -61.027(-61.635) | NFE Forward 56(65.3) | NFE Backward 87(86.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 190 | Time 5.979(5.982) | Loss -16.500(-13.530) | NFE Forward 50(49.6) | NFE Backward 63(62.2) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1850 | Time 8.630(8.238) | Loss -59.929(-61.362) | NFE Forward 68(65.8) | NFE Backward 93(87.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 200 | Time 6.305(6.012) | Loss -18.153(-15.102) | NFE Forward 56(50.0) | NFE Backward 63(62.5) | CNF Time 1.000(1.000)
Epoch 1 | Iter 1860 | Time 7.765(8.216) | Loss -62.651(-61.565) | NFE Forward 56(66.1) | NFE Backward 87(87.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 210 | Time 6.099(6.034) | Loss -19.024(-16.415) | NFE Forward 50(50.0) | NFE Backward 63(62.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 220 | Time 6.063(6.048) | Loss -20.313(-17.479) | NFE Forward 50(50.0) | NFE Backward 63(62.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 230 | Time 6.067(6.054) | Loss -21.022(-18.513) | NFE Forward 50(50.0) | NFE Backward 63(62.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 240 | Time 5.958(6.098) | Loss -20.942(-19.261) | NFE Forward 50(50.4) | NFE Backward 63(63.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 250 | Time 6.087(6.087) | Loss -22.060(-20.052) | NFE Forward 50(50.3) | NFE Backward 63(63.4) | CNF Time 1.000(1.000)
/data/cephfs/punim0011/jtan/github/ffjord/cnf_flow.py
Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, atol=1e-05, batch_norm=False, batch_size=512, bn_lag=0, dataset='custom', dims='64-64-64', divergence_fn='brute_force', dl2int=None, early_stopping=16, evaluate=False, gpu=0, hdim_factor=10, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.001, multigpu=False, n_epochs=32, nhidden=1, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, resume=None, rtol=1e-05, save='experiments/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=512, test_rtol=None, test_solver=None, time_length=1.0, train_T=True, val_freq=250, viz_freq=100, weight_decay=1e-05)
Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
[VAL] Epoch 0 | Val Loss -22.615 | NFE 50 | NoImproveEpochs 00/16 [*]
chain.0.sqrt_end_time
chain.0.odefunc.odefunc._num_evals
chain.0.odefunc.odefunc.diffeq.layers.0._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.0._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.0._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.1._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.1._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.1._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.2._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.2._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.2._hyper_gate.bias
chain.0.odefunc.odefunc.diffeq.layers.3._layer.weight
chain.0.odefunc.odefunc.diffeq.layers.3._layer.bias
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_bias.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.weight
chain.0.odefunc.odefunc.diffeq.layers.3._hyper_gate.bias
SequentialFlow(
  (chain): ModuleList(
    (0): CNF(
      (odefunc): RegularizedODEfunc(
        (odefunc): ODEfunc(
          (diffeq): ODEnet(
            (layers): ModuleList(
              (0): ConcatSquashLinear(
                (_layer): Linear(in_features=36, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (1): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (2): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=256, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=256, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=256, bias=True)
              )
              (3): ConcatSquashLinear(
                (_layer): Linear(in_features=256, out_features=36, bias=True)
                (_hyper_bias): Linear(in_features=1, out_features=36, bias=False)
                (_hyper_gate): Linear(in_features=1, out_features=36, bias=True)
              )
            )
            (activation_fns): ModuleList(
              (0): Tanh()
              (1): Tanh()
              (2): Tanh()
            )
          )
        )
      )
    )
  )
)
Using 4 GPUs.
Number of trainable parameters: 152721
Epoch 0 | Iter 0 | Time 3.541(3.541) | Loss 37.159(37.159) | NFE Forward 20(20.0) | NFE Backward 21(21.0) | CNF Time 1.000(1.000)
Epoch 0 | Iter 260 | Time 6.064(10.135) | Loss -22.901(-20.962) | NFE Forward 50(50.2) | NFE Backward 63(63.3) | CNF Time 1.000(1.000)
[VAL] Epoch 0 | Val Loss 36.682 | NFE 20 | NoImproveEpochs 00/16 [*]
Epoch 0 | Iter 10 | Time 2.738(3.461) | Loss 35.481(36.709) | NFE Forward 20(20.0) | NFE Backward 27(22.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 270 | Time 6.538(8.800) | Loss -22.721(-21.541) | NFE Forward 62(50.6) | NFE Backward 63(63.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 20 | Time 2.937(3.269) | Loss 34.490(36.126) | NFE Forward 26(21.5) | NFE Backward 27(24.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 30 | Time 2.938(3.158) | Loss 32.079(35.163) | NFE Forward 26(23.0) | NFE Backward 27(25.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 40 | Time 4.043(3.139) | Loss 26.634(33.120) | NFE Forward 32(24.7) | NFE Backward 39(26.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 280 | Time 6.058(7.882) | Loss -23.937(-22.134) | NFE Forward 50(50.4) | NFE Backward 63(63.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 50 | Time 4.537(3.489) | Loss 20.527(29.768) | NFE Forward 32(27.1) | NFE Backward 45(30.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 290 | Time 6.040(7.265) | Loss -25.232(-23.009) | NFE Forward 50(50.3) | NFE Backward 63(63.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 60 | Time 5.173(3.909) | Loss 14.074(25.443) | NFE Forward 38(29.0) | NFE Backward 51(36.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 300 | Time 6.041(6.910) | Loss -25.775(-23.640) | NFE Forward 50(51.8) | NFE Backward 63(63.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 70 | Time 5.656(4.378) | Loss 8.220(20.388) | NFE Forward 38(32.0) | NFE Backward 57(41.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 310 | Time 6.002(6.651) | Loss -26.290(-24.256) | NFE Forward 50(51.8) | NFE Backward 63(63.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 80 | Time 5.631(4.759) | Loss 3.091(15.188) | NFE Forward 38(34.0) | NFE Backward 57(46.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 320 | Time 6.007(6.451) | Loss -27.216(-25.025) | NFE Forward 50(51.5) | NFE Backward 63(63.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 90 | Time 5.695(5.047) | Loss -1.654(10.226) | NFE Forward 44(35.8) | NFE Backward 57(49.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 330 | Time 6.443(6.348) | Loss -27.210(-25.575) | NFE Forward 62(52.2) | NFE Backward 63(63.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 100 | Time 5.968(5.326) | Loss -4.797(5.639) | NFE Forward 50(39.9) | NFE Backward 57(52.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 340 | Time 5.916(6.334) | Loss -28.213(-26.197) | NFE Forward 50(53.3) | NFE Backward 63(64.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 110 | Time 5.975(5.553) | Loss -7.239(1.804) | NFE Forward 50(43.3) | NFE Backward 57(54.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 350 | Time 6.022(6.233) | Loss -28.217(-26.865) | NFE Forward 50(52.7) | NFE Backward 63(63.7) | CNF Time 1.000(1.000)
Epoch 0 | Iter 120 | Time 5.960(5.682) | Loss -9.292(-1.668) | NFE Forward 50(45.5) | NFE Backward 57(55.2) | CNF Time 1.000(1.000)
Epoch 0 | Iter 360 | Time 6.129(6.180) | Loss -28.764(-27.492) | NFE Forward 56(53.2) | NFE Backward 63(63.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 130 | Time 6.335(5.941) | Loss -10.520(-4.339) | NFE Forward 50(47.0) | NFE Backward 63(58.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 140 | Time 5.928(6.016) | Loss -12.035(-6.745) | NFE Forward 50(48.0) | NFE Backward 57(58.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 370 | Time 7.256(6.403) | Loss -28.244(-27.855) | NFE Forward 62(55.5) | NFE Backward 75(65.6) | CNF Time 1.000(1.000)
Epoch 0 | Iter 150 | Time 6.345(6.097) | Loss -14.242(-8.962) | NFE Forward 50(48.7) | NFE Backward 63(59.9) | CNF Time 1.000(1.000)
Epoch 0 | Iter 380 | Time 6.233(6.457) | Loss -30.142(-28.274) | NFE Forward 56(55.6) | NFE Backward 63(66.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 160 | Time 6.325(6.203) | Loss -14.625(-10.638) | NFE Forward 50(49.1) | NFE Backward 63(61.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 390 | Time 6.250(6.371) | Loss -30.432(-28.746) | NFE Forward 56(55.3) | NFE Backward 63(65.3) | CNF Time 1.000(1.000)
Epoch 0 | Iter 170 | Time 6.414(6.262) | Loss -15.973(-12.245) | NFE Forward 50(49.4) | NFE Backward 63(62.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 400 | Time 6.865(6.324) | Loss -31.398(-29.360) | NFE Forward 62(55.0) | NFE Backward 69(64.8) | CNF Time 1.000(1.000)
Epoch 0 | Iter 180 | Time 6.740(6.375) | Loss -16.427(-13.555) | NFE Forward 50(49.6) | NFE Backward 69(63.4) | CNF Time 1.000(1.000)
Epoch 0 | Iter 410 | Time 7.064(6.518) | Loss -28.879(-29.227) | NFE Forward 56(56.0) | NFE Backward 75(67.1) | CNF Time 1.000(1.000)
Epoch 0 | Iter 190 | Time 6.298(6.360) | Loss -18.756(-14.993) | NFE Forward 50(49.7) | NFE Backward 63(63.5) | CNF Time 1.000(1.000)
Epoch 0 | Iter 420 | Time 6.253(6.577) | Loss -29.947(-29.473) | NFE Forward 56(56.2) | NFE Backward 63(67.8) | CNF Time 1.000(1.000)
